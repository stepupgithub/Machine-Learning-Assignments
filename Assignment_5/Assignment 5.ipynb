{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment 5.ipynb","provenance":[],"collapsed_sections":["UTyB-3McWOFa","6_guuzaKXGfr","9QaURe3mc4CB","n2bi4E5YfkzP","MMk82luBgPLW","ebqIYd1-gaPO","EcqgshmAgixU"],"authorship_tag":"ABX9TyNtPxJZFf7o7kunKkA2W3Z8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"UTyB-3McWOFa"},"source":["\n","\n","#***Shortest Path Using Reinforcement Learning***\n"]},{"cell_type":"code","metadata":{"id":"a8sDrabXgvro"},"source":["import numpy as np\n","import pylab as plt\n","\n","# map cell to cell, add circular cell to goal point\n","points_list = [(0,1), (1,5), (5,6), (5,4), (1,2), (2,3), (2,7)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"id":"nKUfdnkJg6hO","executionInfo":{"status":"ok","timestamp":1636388587654,"user_tz":-330,"elapsed":734,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}},"outputId":"8b3e2a94-54b1-419c-dab7-ceb70bcaed5b"},"source":["import matplotlib.pyplot as plt\n","\n","goal = 7\n","\n","import networkx as nx\n","G=nx.Graph()\n","G.add_edges_from(points_list)\n","pos = nx.spring_layout(G)\n","nx.draw_networkx_nodes(G,pos)\n","nx.draw_networkx_edges(G,pos)\n","nx.draw_networkx_labels(G,pos)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de1xUdf4/8NeZGZhBroIoBComX0VJLKEkWBUviWJrfhXKVkxti4guZtl2oe/3UevSZVcrd1ej8vHL/YaVQaXpkorGpRXR5SLrBSS8Ba4ooDigzDCX8/vDhaQZbsrMmRlez8fDx2Odc2Z42+LLw/t8zvsjiKIIIiKyDpnUBRARDSQMXSIiK2LoEhFZEUOXiMiKGLpERFak6O7gkCFDxKCgICuVQkTkGEpKShpEUfQ1d6zb0A0KCkJxcbFlqiIiclCCIJzt6hjbC0REVsTQJSKyIoYuEZEVMXSJiKyIoUtEZEUMXSIiK2LoEhFZEUOXiMiKun04gkgqDS1aZJXUorJODbVGDw+VAiF+HkgID4SPm1Lq8ohuGkOXbEp5TRM25FUjv6oeAKDVGzuOqRR1eG9vFWLG+iJlWjAmDveSqkyim8bQJZuRUXQGadmV0OgNMLehieY/Abzn+AUUVDUgNS4EiZFB1i2S6BYxdMkmXA/cCrTqjD2eK4pAq86AtOwKAGDwkl3hjTSSXHlNE9KyK3sVuDdq1RmRll2Jf9U2Wagyov7HK12S3Ia8amj0BpPXf1oX3+n3or4N7nfFwXt2csdrGr0BG/OqkZ4YYfE6ifoDQ5ck1dCiRX5Vvdke7ogXsjr+t7GtFbV/WYpBIb/qdI4oArkn6tHYouWqBrILbC+QpLJKant13rUThZAP8oRyeKjJMQFAVmnvPodIagxdklRlnbrTsrCutBzZB9c7ZkAQBJNjGr0RleebLVEeUb9j6JKk1Bp9j+for1yEtuYoXCfM7OZzdP1ZFpHFMHRJUh6qnm8rtBz9HsrA8XDy8uvmc5z6sywii2HokqRC/DygVHT/bXj16Pdwu2NGl8dVChlC/N37uzQii2DokqTiwwO7Pa6prYChpdFk1cKNRADxk7r/HCJbwdAlSQ1xU2LaGF+YuT8GALh6dB8GjYmCTDnI7HFBAKaP9eVyMbIbXKdLknsqJhg//NiAVp3pAxI+c57u9r1KhQwpMcGWKo2o3zF0SXITh3shNS6k17MX2smMOnie/AeCvadZsDqyR7Y8GpShSzahfWhNd1PG2gkCoFLI8XLsOOz78GvMmTMHO3fuhIeHh3WKJZtlD6NBBbGb7+6IiAixuLjYiuXQQPev2iZszKtG7ol6CPh5nCNwfZWCiOs93JSYYIQFesFoNOKZZ57BoUOHsGvXLvj4+EhWO0mrp9Gg7dr/0bbkaFBBEEpEUTQ7EIShSzapsUWLrNJaVJ5vhlqjg4fKCSH+7oifZPrjoSiKePXVV7Fjxw7k5OTA399foqpJKn0ZDdrOxUmG1LhxFgne7kKX7QWyST5uSjwxdXSvzhUEAW+99RY8PDwwZcoU7N27F0FBQZYtkGzGrY4GDQv0Qlig9VoNDF1yGK+88grc3d0xdepU7NmzByEhIVKXRFbQ1WjQhh1roTlTDqNOA7nrYHhELoL7xNhO50gxGpShSw7l6aefhru7O6ZPn47s7GzcddddUpdEFtTdaFCPyAT4zF0JQeEEXWMN6j57Bc7DRkPp9/MSQylGg/LhCHI4y5Ytw1//+lfExsaisLBQ6nLIgrobDersOxKCon0mhwABAvSXz5ucZ+3RoLzSJYe0aNEiuLq64oEHHsDnn3+OWbNmSV0SWUBPo0Ebd2/E1SP7IOq1cB42Gi6jTdsI1h4Nyitdclhz5szB119/jd/85jf49ttvpS6HLKCn0aA+sSkY/vyXGLbkHbiMuReC3Pw0OmuOBmXokkObMmUKsrOzkZSUhM8++0zqcqgfGY1GGDVXezxPkMmhGh4KQ3MDmsuyzZ5jzdGgbC+Qw4uIiMC+ffsQGxuLlpYWJCUlSV0S3YSrV6/i4MGDKCwsRGFhIQ4cOIDBUQkQ7pgHUdaLKDMazfZ0rT0alKFLA0JoaCjy8/Nx3333Qa1WY/Xq1VKXRD2oqanB/v37UVhYiP3796OyshJ33nknoqKikJSUhE8++QRyVy9Ev/O9SV/XcLUJmrPlcAm+B4LCGZozh3G1Ih9D5v/O5OtYezQoQ5cGjNGjR6OgoACzZs2CWq3GG2+8YXbPNbI+nU6H8vLyjoAtLCxEW1sboqOjERUVhcWLFyM8PBxKpemyrmljfJFTcaHzsjFBQHPZd2jcvREQjVB4DsXgmY9j0H9N7vReKUaDMnRpQAkMDERBQQFiY2OhVqvx7rvvQibjrQ1ru3TpEoqKijoCtri4GEFBQYiOjsa8efPw5ptv4vbbb+/VP4rmRoPKB3nCb8nbPb5XpZBbfTQoZy/QgNTU1IS4uDiMGzcOH330EeRyudQlOSxRFPHjjz92ahXU1tbinnvuQVRUFKKjozF58mR4ed38o7j2NHuBoUsDVktLCxYsWABvb29kZGTA2dlZ6pIcQmtrK4qLizsC9sCBA3B1de0I2KioKEyYMAEKRf/+oM0pY0R2QKPRYPHixdDpdMjKyoKLi4vUJdmd8+fPd+rFHjlyBKGhoR0BGxUVhYCAAKvU0tfRoJbC0CXqhk6nw/Lly3Hu3Dns2LED7u7cWbgrBoMBR48e7QjYwsJCXLlypSNco6OjERERgUGDzO9pZy19GQ1qCQxdoh4YjUakpKSgrKwM3333Hby9vaUuySao1WoUFRV1BOzBgwdx2223dWoVjB07lqtAfoGhS9QLoijipZdewnfffYecnBz4+flJXZJViaKI06dPdwTs/v37cfLkSYSHh3cE7L333svdOXqBQ8yJekEQBLzzzjvw9PTsGIY+cuRIqcuyGK1Wi7Kysk6tAplM1hGwy5cvx5133skbjP2MoUt0A0EQkJqa2jEMPScnB2PGjJG6rH5RX1/fEa6FhYUoKyvDmDFjEBUVhfj4eLz77rsYMWIEWwUWxtAlMuPZZ5+Fm5sbYmJisGvXLoSFhUldUp8YjUZUVFR0ahVcvHgRkZGRiI6Oxuuvv4577rmHNw0lwNAl6sKjjz4KNzc33Hffffj2228xeXLnR0gbWrTIKqlFZZ0aao0eHioFQvw8kBBunTvkN7p69SoOHTrUaW2sj49PR6vg+eefx/jx4/kQiA3gjTSiHmRnZ2P58uXYunUrpk+fjvKaJmzIq0Z+VT0AdBq20r4WNGasL1KmBWPicMusBa2pqem0NrayshITJ07sWLoVFRWFYcOGWeRrU8+4eoHoFuXn5yMhIQEr0v4fvq1RWPWppxuHwbQHrVar7biKjY6OxqRJk6BSqW7p61D/YegS9YM/fJGPj4sbITj1vnVwM8/3X758GQcOHOgI2PZhMDeujR09ejRveNkwLhkjukXlNU3Ycry1U+CKeh0a92yE5sxhGDUtUHj5YfC0ZZ324WrVGZGWXYmwQC+zj522D4O5sVVQU1PTMQzmpZdeQmRk5C0NgyHbwtAl6oUNedXQ6A2dXhONBijch8DvN29D7umL1pPFqN/+Dm579K9QeP3cT9XoDdiYV430xAi0traipKSk09rY9mEwUVFRSElJscgwGLId/H+WqAcNLVrkV9Wb9HBlzip4TVnS8ftBwfdA4TkM2rrqTqErisCeo//GPVNm4FjpQYSGhiIqKgqJiYnYsGEDAgOtt2sBSY+hS9SDrJLaXp1nuHoZukvn4Ow7wuSYIAiY/ttXkLc7WvJhMCQtjswn6kFlndpkD65fEg16NHy7Fm4TZsLJZ7jJcQNkaHPxZeASQ5eoJ2qNvtvjomhEw851gFwB7/uSu/kcXX+XRnaIoUvUAw9V1104URTRmP1nGK42wfe/X4Ug7/pcD5WTJcojO8PQJepBiJ8HlArzf1Uu7d4AXWMNhsb/L2TdrN9VKWQI8eecA+KNNKIexYcH4r29VSav669cRMvhXYDcCbV/Wdrxuvecp+AWOr3TuSKA+ElcpUAMXaIeDXFTYtoYX+RUXOi0bEzhORQjX97Z4/sF4fq+XNYegkO2ie0Fol54KiYYCvR+e+8bqRRypMQE93NFZK8YukS9ULDtU7Qd3AqlvG/zDq7PXgix6M6zZF/YXiDqwTvvvIOPPvoI+fv24R91QFp2pVWnjJFjYegSdUEURbz++uv48ssvUVBQgICAAAQFAWGBXtiYV43cE/UQAGjMzNOdPtYXKTHBvMIlEwxdIjNEUcSLL76InJwc5OfnY+jQoR3HwgK9kJ4YgcYWLbJKa1F5vhlqjQ4eKieE+LsjfpL1d44g+8HQJfoFo9GIp59+GsXFxcjNzYW3t7fZ83zclHhi6mgrV0f2jqFLdAODwYDHHnsM1dXV2Lt3Lzw8PKQuiRwMQ5foP3Q6HZYuXYrGxkbs2rULrq6uUpdEDoihSwRAo9HgoYcegtFoxI4dO7jfGFkM1+nSgHft2jXMnz8fSqUSX331FQOXLIqhSwNac3Mz5s6dCz8/P3z22WdwdnaWuiRycAxdGrAuX76MWbNmYdy4cdi8eTP3JSOrYOjSgFRfX48ZM2YgOjoaH3zwAWQy/lUg6+B3Gg04//73vzFt2jTcf//9WLduHQShb/MUiG4FQ5cGlLNnz2Lq1KlYunQp1qxZw8Alq2MTiwaM6upqzJo1C6tWrcLKlSulLocGKF7p0oBw/PhxxMTEIDU1lYFLkuKVLjm8srIyxMXF4U9/+hMSExOlLocGOIYuObSDBw9i/vz52LhxIxYtWiR1OUQMXXJc+fn5SEhIwObNmxEXFyd1OUQA2NMlB7V7927Ex8fj888/Z+CSTWHoksPZvn07li5dim3btmHmzJlSl0PUCUOXHMrWrVvxxBNPIDs7G9HR0VKXQ2SCoUsOY/PmzVi1ahVycnIQEREhdTlEZvFGGjmEjRs34q233kJubi7Gjh0rdTlEXWLokt1bu3YtNm7ciIKCAowaNUrqcoi6xdAluyWKItasWYMtW7agoKAAgYGBUpdE1COGLtklURTx8ssvIzs7GwUFBRg2bJjUJRH1CkOX7I7RaMTKlStx4MAB5OXlwcfHR+qSiHqNoUt2xWAwICkpCZWVldi3bx88PT2lLomoTxi6ZDd0Oh2WLVuGCxcuYPfu3XBzc5O6JKI+Y+iSXdBqtVi8eDHa2tqwc+dOuLi4SF0S0U3hwxFk865du4YFCxZAJpPhm2++YeCSXWPokk1rbm7GvHnz4OPjg61bt3KLdLJ7NtFeaGjRIqukFpV1aqg1enioFAjx80BCeCB83JRSl0cSaWpqwty5c3HHHXcgPT0dcrlc6pKIbpmkoVte04QNedXIr6oHAGj1xo5jKkUd3ttbhZixvkiZFoyJw72kKpMk0NDQgNmzZ2PKlCl4//33uYEkOQzJ2gsZRWew+OMi5FRcgFZv7BS4AKD5z2t7jl/A4o+LkFF0RppCyerOnz+PmJgYzJkzh4FLDkeSK92MojNIy65Aq87Y47miCLTqDEjLrgAAJEYGWbg66m99aR/V1NRg5syZWLZsGVJTUyWqmMhyrB665TVNSMuuNAlcQ2szGrPXQ3OmDDIXDwyetgyuoTEdx1t1RqRlVyIs0AthgWw12IO+to9OnTqFmTNn4tlnn8WqVaukKpvIoqweuhvyqqHRG0xev7TnAwhyJwQ+k4G2C6dwMesNOA0dBWffkR3naPQGbMyrRnoiZ6Xauus/zVRCozdAFE2Pa/4TwHuOX0BBVQN+O2kw1j8Tj9TUVCQnJ1u5WiLrsWpPt6FFi/yqepO/hMY2Da6dKITX1ETInF2gGh6KQcGTcfVYbqfzRBHIPVGPxhatFaumvvq5fWQ+cG/U3j76y/5zeGD1WgYuOTyrhm5WSa3Z1/WXzkGQyeHkHdDxmtPQUdDVnzU5VwCQVWr+c0h6XbWPeiIolNjX6Il/1TZZqDIi22DV9kJlndpklQIAGHWtEJSdnzKSKQfB2NZqcq5Gb8Q3uYcgHs+BUqmESqUy+8vcMaVSybWeFtZV+0hdsgNXj+xDW/0ZuI6bhiH3m/Zs2T6igcCqoavW6M2+LnNygajtHLCi9hpkzuYf97x8VYPDhw9Do9F0/NJqtZ1+39Xrcrm81yF9M6/39B6lUumwS6C6ah8BgMLNB55RD6H1dClEXZvZ99/YPuJDMeSorBq6HirzX07hHQDRaIDu0rmOFkPbxdNwuuEm2o2iwu/Cew+t6PPXF0UROp2u25DuTYCr1eqbCnyNRoO2tjaTUO7vYO/pdYVCYZHg76p9BACDxkYBALR11TDoGro8r7199MTU0f1dHpFNsGrohvh5QKmoM2kxyJxVGDT2XjT9sAU+c59F28VTuFZ9EH6JfzL5DJVChhB/95v6+oIgwNnZWdLn941GI9ra2m468DUaDVpaWtDQ0NDnwG//JYqiRQI/p3YQtPpba99o9EZUnm/up//aRLbHqqEbHx6I9/ZWmT3mPTsFjdnrUfuXJZC5eMBndkqn5WLtRADxk+x3LyyZTNYRUlLR6/VmQ7kvAX758mWT138cMhVwN//TSV+oNbp++FMS2Sarhu4QNyWmjfFFTsUFk76f3MUdQxe91u37BQGYPtaX/b5bpFAooFAo4Orq2q+f+9zWMmw7/O9b/hwPlVM/VENkm6w+e+GpmGCoFDf3I6hKIUdKTHA/V0T95Xr76Na+pW6lfURkD6weuhOHeyE1LgQuTn370i5OMqTGhfARYBsWH95120c0GiDq2wCjARCNEPVtEI2mS8vsvX1E1BNJBt60D63p7jHRdoJw/Qo3NS6Ew25sXHftoyv7v8CV/Z93/P7qsVx4Rj8MrylLOl5j+4gGAsnm6SZGBiEs0Asb86qRe6IeAn5+Hh+4/mOmiOt/CVNignmFayeeignGDz82oFXX+SrWa8qSTgFrDttHNBBIOsQ8LNAL6YkRaGzRIqu0FpXnm6HW6OChckKIvzviJ3HnCHvT3j7q7ejOdmwf0UBhE9v1+LgpuRjegbB9RNQ1mwhdcjy9aR9ptFqE3+aC/42fzCtcGjAYumQxPbWPLpVk48ihAwh7LlbqUomsRhC7+dkvIiJCLC4utmI5NJBcvnwZo0aNQlVVFYYOHSp1OUT9RhCEElEUzY7Lk2xjSqLBgwdj4cKF+OSTT6QuhchqGLokqSeffBIffvghjMa+DT0nslcMXZJUREQEBg8ejN27d0tdCpFVMHRJUoIg4Mknn0R6errUpRBZBUOXJPfwww/jhx9+wE8//SR1KUQWx9Alybm6umLJkiXYtGmT1KUQWRxDl2xCcnIyNm3aBJ2OA8zJsTF0ySaEhoYiODgY27dvl7oUIoti6JLN4A01GggYumQzFi5ciCNHjqCqyvw+ekSOgKFLNkOpVGLFihX48MMPpS6FyGIYumRTkpKS8Le//Q2tra1Sl0JkEQxdsim333477r77bnz55ZdSl0JkEQxdsjm8oUaOjKFLNmfevHk4d+4cDh8+LHUpRP2OoUs2Ry6X4/HHH8cHH3wgdSlE/Y6hSzbpsccew5dffgm1Wi11KUT9iqFLNsnf3x+zZs1CRkaG1KUQ9SuGLtms5ORkpKeno7stpYjsDUOXbNaMGTOg1WpRWFgodSlE/YahSzZLEAQ88cQTvKFGDoWhSzZt+fLl2LlzJxoaGqQuhahfMHTJpnl7e2PBggXcMZgcBkOXbF5ycjJ3DCaHwdAlmzd58mS4u7tj7969UpdCdMsYumTzBEFAcnIyb6iRQ2Dokl1YsmQJ8vPzUVtbK3UpRLeEoUt2wc3NDQ8//DB3DCa7x9Alu5GcnIyPP/6YOwaTXWPokt2YMGECRo0ahZ07d0pdCtFNY+iSXXnyySd5Q43sGkOX7MqiRYtw+PBhVFdXS10K0U1h6JJdUalUWL58OXcMJrvF0CW7k5SUhM2bN0Oj0UhdClGfKaQugKivgoODMWnSJGz+4itgVCQq69RQa/TwUCkQ4ueBhPBA+LgppS6TyCyGLtmd8pomOM98Gm9XGKE8WQWt/ueZDCpFHd7bW4WYsb5ImRaMicO9JKyUyBTbC2RXMorOYPHHRTjaJANkik6BCwAavRFavRF7jl/A4o+LkFF0RppCibrAK12yGxlFZ5CWXYFWXc/TxkQRaNUZkJZdAQBIjAyycHVEvcPQJbtQXtOEtOxKk8Ct2/IytP8+AUEmBwDI3X0QkPTzyoZWnRFp2ZUIC/RCWCBbDSQ9hi7ZhQ151dDoDWaPec9OhvvE2C7fq9EbsDGvGumJEZYqj6jX2NMlm9fQokV+VT1udlNgUQRyT9SjsUXbv4UR3QSGLtm8rJLuxzk25f0NNet/g7pPX4Tm7L/MniMAyCrlWEiSHtsLZPMq69QmqxTaDZ6+Ak4+wyHInXC1ogAXv1oD/xV/htNg/07nafRGVJ5vtka5RN3ilS7ZPLVG3+Ux5W1jIVMOgqBwgtuEmVAGjEPryeIuPocjIUl6DF2yeR6qPvxAJggAzDd/PVRO/VMQ0S1g6JLNC/HzgFJh+q1q1LSg9VQJRH0bRKMBLcdyoa05Cpfbw00/RN+Gn44cwNGjRyHe7B05on7Ani7ZvPjwQKzLOWHyumg0oKkgA7pLtYAgg5NPIHwXvgYn7wCTc52cneF37Qzi4t6Cq6srEhISEB8fjwkTJkAQBGv8MYgAAEJ3/+pHRESIxcXm+2NE1nDlyhWsWbMGX9S6QzEqHNfXIfSNIACx44chPTECoiji0KFDyMzMRFZWFpRKZUcAT5w4kQFM/UIQhBJRFM0uDGd7gWySwWDApk2bEBISgsuXL+P/Xk6Ei9PN/WCmUsiREhMM4Pp27pMnT8batWtx+vRpZGRkoK2tDQsXLsSYMWPwyiuvoLS0lC0Ishhe6ZLNKSgowMqVK+Hq6or169cjPPx6j7YvsxfauTjJkBo3rsfZC6IoorS0FFlZWcjMzIQoioiPj0dCQgLCw8N5BUx90t2VLkOXbMaZM2fw4osv4tChQ/jjH/+IBx980CTsrgdvJTR6Q7dPqAnC9Svc1LiQPg+7EUURhw8f7ghgnU7XEcB33303A5h6xPYC2bSWlha89tprCA8Px4QJE1BRUYGHHnrIbLglRgZha1IkYscPg1Ihg+oXqxpUChmUChlixw/D1qTIm5ouJggC7rrrLqSlpeHEiRPYvn07VCoVHnnkEQQFBeGFF15AUVERjMbeX3ETteOVLknGaDRiy5YteOWVVzBt2jS8/fbbGD58eK/f39iiRVZpLSrPN0Ot0cFD5YQQf3fET7LMzhGiKOLYsWPIzMxEZmYmmpubER8fj/j4eNx7772QyXgNQ9exvUA2p6ioCM899xwMBgPWr1+PqKgoqUvqs+PHj3cEcFNTExYtWoT4+HhER0czgAc4hi7ZjHPnzuHll1/G999/jzfffBNLly51iICqqKhAVlYWsrKyUF9fj4ULFyIhIQG/+tWvIJfLpS6PrIw9XZJca2sr/vCHPyAsLAwjRozAiRMnsGzZMocIXAAYN24c/ud//gfl5eXIy8uDv78/nnvuOQQEBCAlJQW5ubnQ67ueIUEDh2N8x5PNEkURmZmZGDduHA4fPozi4mKkpaXBzc1N6tIsZsyYMUhNTUVZWRl++OEHjBgxAqtXr0ZAQACSk5Oxb98+BvAAxvYCWUxZWRlWrlyJK1euYP369YiJiZG6JEmdPHkSX331FTIzM3H27FksWLAACQkJiImJgZMTh/E4ErYXyKouXLiAxx9/HHPnzkViYiJKS0sHfOACwOjRo/G73/0O//znP3Ho0CGMGTMGr732Gvz9/fHYY49h165d0Ok4ftLRMXSp37S1tWHt2rUIDQ2Fh4cHKisrkZSUxBtJZgQFBWH16tU4ePAgSkpKMH78ePz+97+Hv78/Hn30UWRnZ6OtrU3qMskCGLp0y0RRxLfffovQ0FDk5eVh//79WLduHby8uPtub4wcORLPP/88CgsLUVZWhrCwMLz55pvw8/PDsmXLsHPnTmi13N/NUbCnS7fk6NGjWLVqFc6dO4f33nsPsbFd78pLfXPu3Dl8/fXXyMzMxJEjR3D//fcjISEBs2fPhkqlkro86gZ7utTvGhsb8fTTT2PGjBn49a9/jfLycgZuPwsICMAzzzyDgoICHDt2DJGRkXj33Xfh7++PJUuWYNu2bWhtbZW6TOojXulSn+h0OqSnp2PNmjV48MEH8cYbb8DHx0fqsgaUuro6fPPNN8jMzERpaSnmzp2LhIQEzJkzB4MGDerXr9XQokVWSS0q69RQa/TwUCkQ4ueBhHDLPGrtKPhEGvWL3bt3Y9WqVbjtttvw/vvv44477pC6pAHv4sWLHQFcXFyM2NhYxMfHIy4uDq6urjf9ueU1TdiQV438qnoA6LQbs0ohgwggZqwvUqYFY+Jw9u5/iaFLt6SqqgovvPACKioqsG7dOsyfP5/jDW1QfX09tm3bhqysLBQVFWH27NmIj4/HvHnz+vQwijXGZzo69nTpply5cgWrV69GVFQUpk6dimPHjuGBBx5g4NooX19fPP7449i9ezdOnTqFOXPmYPPmzQgICMCiRYvw+eefo7m5udvP+HlQfPeBCwCiCLTqDEjLrkBG0Zn++4M4OIYumTAYDPjoo48wduxYNDU14ejRo3jxxRehVLKHZy98fHzw29/+Ft999x1Onz6N+++/HxkZGQgMDMSCBQuwZcsWqNXqTu8pr2lCWnZln3bmAIBWnRFp2ZX4V21Tf/4RHBZDlzrJz89HeHg4Pv30U2RnZ2PTpk3w8/OTuiy6Bd7e3lixYgX+/ve/48yZM1i4cCG++OILBAYGYv78+fj000/R1HS9h6vRG7r8HN2lczj7p/9Gw461Jsc0egM25lVb8o/hMBi6BOD6VjkJCQlYtmwZXn31VRQUFGDSpElSl0X9bPDgwXjkkUewY8cO1NTU4MEHH0RWVhZGjr0DOUfPddtSuLQnHUr//zJ7TBSB3BP1aGzhQxw9Yeg6gIYWLdLzT+K5rWV49G//xHNby5Cef7JXfwFaWlqQmpqK8PBwhIWFoaKiwuzeZOR4PD09kZiYiMEAQ/YAAAQTSURBVO3bt+P3/7e728e1rx7Ph0zlCtXIiV2eIwDIKq21QKWO5eb2tCab0P2ynjq8t7eqy2U9RqMRGRkZePXVVxETE4Py8nIEBgZatX6yHaeb2qAXzf9Da9ReQ9MPWzDs4TfRUr67y8/Q6I2oPN/9jTpi6Nqtnpb1aP4TwHuOX0BBVUOnZT1FRUVYuXIlACArKwuRkZHWKptslFrT9XzfpoJP4TZxNhQeQ3rxOZyS1hOGrh36eVlPz3eZb1zWc7mpCQcz1iI3NxdvvfUWEhMTHWbnBro1HirzUdB24RQ0Z8vhv2J9Lz+Hc4F7wtC1M90t67l6PB9N+z+HQV0Puetg+Mx7Dqrh158aa9UZsXbvKcwdMR4nTqQ79M4N1Hchfh5QKuo6tagAQPPTEeivXEDtxhUAALFNA4hGnG9YaRLEKoUMIf7uVqvZXjF07UxXy3paT5fhct5m+D7wEpxvGwNDyyWTc2ROSmD8bAYumYgPD8R7e6tMXne7Mxau46Z2/F596Gvor1yAd+xTJueKAOIn8b5AT/izpR1paNEiv6rebA/3yj+2wDP6YSgDQiAIMijch0Dh3rkHJ4LLesi8IW5KTBvji18uWpE5qSB3G9zxS3BSQVA4Qz7Is9N5ggBMH+vLITi9wNC1I1kl5pfjiEYDtOerYbx2BefSH0fthmW4tOcDGHWm4cplPdSVp2KCoVJ0v8uH15QlGPLr1SavqxRypMQEW6o0h8LQtSOVdWqTnhsAGK42AUY9rp3Yj2GJ78B/xZ/RduEUrhRuNTmXy3qoKxOHeyE1LgQuTn2LBRcnGVLjQhAWyGljvcHQtSNdLesRnK7/SOce/mso3LwhH+QJ97sXoPWk+QlxXNZDXUmMDEJq3Di4OMlNWg2/JAiAi5McqXHjOGWsD3gjzY50taxHrnKD/Bf92+6eKOOyHupOYmQQwgK9sDGvGrkn6iHg53XfwM/zdKeP9UVKTDCvcPuIoWtHulrWAwBuE2ahuWQnXG4PB+QKqP+5DYOC7zY5j8t6qDfCAr2QnhiBxhYtskprUXm+GWqNDh4qJ4T4uyN+EneOuFkMXTvS1bIeAPCMXgxDqxrnPnoCgsIJriFT4Bn1kMl5XNZDfeHjpsQTU0dLXYZDYejakfZlPTkVF0yWjQlyBXxiU+ATm9Ll+7msh0h6vJFmZ3qzrKcrXNZDJD2Grp3hsh4i+8b2gh1qX57DzQOJ7A9D105xWQ+RfWLo2jEu6yGyPwxdB8BlPUT2gzfSiIisiKFLRGRFDF0iIiti6BIRWRFDl4jIihi6RERWxNAlIrIihi4RkRUJYjcP7guCUA/grPXKISJyCCNFUfQ1d6Db0CUiov7F9gIRkRUxdImIrIihS0RkRQxdIiIrYugSEVnR/wdsil2yBdKFgwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"nD7ggaAHhhTR"},"source":["# how many points in graph? x points\n","MATRIX_SIZE = 8\n","\n","# create matrix x*y\n","R = np.matrix(np.ones(shape=(MATRIX_SIZE, MATRIX_SIZE)))\n","R *= -1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dr14Sb3vr6aN","executionInfo":{"status":"ok","timestamp":1636388588172,"user_tz":-330,"elapsed":3,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}},"outputId":"1ca66d79-babf-41d8-c63d-b16aca055a6a"},"source":["# assign zeros to paths and 100 to goal-reaching point\n","for point in points_list:\n","    print(point)\n","    if point[1] == goal:\n","        R[point] = 100\n","    else:\n","        R[point] = 0\n","\n","    if point[0] == goal:\n","        R[point[::-1]] = 100\n","    else:\n","        # reverse of point\n","        R[point[::-1]]= 0\n","\n","# add goal point round trip\n","R[goal,goal]= 100\n","\n","R"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(0, 1)\n","(1, 5)\n","(5, 6)\n","(5, 4)\n","(1, 2)\n","(2, 3)\n","(2, 7)\n"]},{"output_type":"execute_result","data":{"text/plain":["matrix([[ -1.,   0.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n","        [  0.,  -1.,   0.,  -1.,  -1.,   0.,  -1.,  -1.],\n","        [ -1.,   0.,  -1.,   0.,  -1.,  -1.,  -1., 100.],\n","        [ -1.,  -1.,   0.,  -1.,  -1.,  -1.,  -1.,  -1.],\n","        [ -1.,  -1.,  -1.,  -1.,  -1.,   0.,  -1.,  -1.],\n","        [ -1.,   0.,  -1.,  -1.,   0.,  -1.,   0.,  -1.],\n","        [ -1.,  -1.,  -1.,  -1.,  -1.,   0.,  -1.,  -1.],\n","        [ -1.,  -1.,   0.,  -1.,  -1.,  -1.,  -1., 100.]])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W_SzGu3HsQK3","executionInfo":{"status":"ok","timestamp":1636388589195,"user_tz":-330,"elapsed":3,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}},"outputId":"3dabad5c-2eb7-46ba-c021-1e02d3cef621"},"source":["Q = np.matrix(np.zeros([MATRIX_SIZE,MATRIX_SIZE]))\n","\n","# learning parameter\n","gamma = 0.8\n","\n","initial_state = 1\n","\n","def available_actions(state):\n","    current_state_row = R[state,]\n","    av_act = np.where(current_state_row >= 0)[1]\n","    return av_act\n","\n","available_act = available_actions(initial_state)\n","\n","def sample_next_action(available_actions_range):\n","    next_action = int(np.random.choice(available_act,1))\n","    return next_action\n","\n","action = sample_next_action(available_act)\n","\n","def update(current_state, action, gamma):\n","\n","  max_index = np.where(Q[action,] == np.max(Q[action,]))[1]\n","\n","  if max_index.shape[0] > 1:\n","      max_index = int(np.random.choice(max_index, size = 1))\n","  else:\n","      max_index = int(max_index)\n","  max_value = Q[action, max_index]\n","\n","  Q[current_state, action] = R[current_state, action] + gamma * max_value\n","  print('max_value', R[current_state, action] + gamma * max_value)\n","\n","  if (np.max(Q) > 0):\n","    return(np.sum(Q/np.max(Q)*100))\n","  else:\n","    return (0)\n","\n","update(initial_state, action, gamma)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["max_value 0.0\n"]},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1N5rX3zUwO4O","executionInfo":{"status":"ok","timestamp":1636388589968,"user_tz":-330,"elapsed":774,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}},"outputId":"aa132cf9-bc96-4aa4-fae5-11eca04c2862"},"source":["# Training\n","scores = []\n","for i in range(700):\n","    current_state = np.random.randint(0, int(Q.shape[0]))\n","    available_act = available_actions(current_state)\n","    action = sample_next_action(available_act)\n","    score = update(current_state,action,gamma)\n","    scores.append(score)\n","    print ('Score:', str(score))\n","\n","print(\"Trained Q matrix:\")\n","print(Q/np.max(Q)*100)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["max_value 0.0\n","Score: 0\n","max_value 0.0\n","Score: 0\n","max_value 0.0\n","Score: 0\n","max_value 0.0\n","Score: 0\n","max_value 100.0\n","Score: 100.0\n","max_value 0.0\n","Score: 100.0\n","max_value 0.0\n","Score: 100.0\n","max_value 0.0\n","Score: 100.0\n","max_value 80.0\n","Score: 180.0\n","max_value 0.0\n","Score: 180.0\n","max_value 80.0\n","Score: 180.0\n","max_value 0.0\n","Score: 180.0\n","max_value 0.0\n","Score: 180.0\n","max_value 0.0\n","Score: 180.0\n","max_value 0.0\n","Score: 180.0\n","max_value 80.0\n","Score: 260.0\n","max_value 0.0\n","Score: 260.0\n","max_value 80.0\n","Score: 260.0\n","max_value 0.0\n","Score: 260.0\n","max_value 80.0\n","Score: 340.0\n","max_value 0.0\n","Score: 340.0\n","max_value 80.0\n","Score: 340.0\n","max_value 64.0\n","Score: 404.0\n","max_value 0.0\n","Score: 404.0\n","max_value 0.0\n","Score: 404.0\n","max_value 0.0\n","Score: 404.0\n","max_value 64.0\n","Score: 404.0\n","max_value 64.0\n","Score: 404.0\n","max_value 64.0\n","Score: 404.0\n","max_value 0.0\n","Score: 404.0\n","max_value 80.0\n","Score: 404.0\n","max_value 0.0\n","Score: 404.0\n","max_value 0.0\n","Score: 404.0\n","max_value 0.0\n","Score: 404.0\n","max_value 64.0\n","Score: 404.0\n","max_value 0.0\n","Score: 404.0\n","max_value 0.0\n","Score: 404.0\n","max_value 164.0\n","Score: 285.3658536585366\n","max_value 131.20000000000002\n","Score: 316.5853658536586\n","max_value 131.20000000000002\n","Score: 316.5853658536586\n","max_value 0.0\n","Score: 316.5853658536586\n","max_value 64.0\n","Score: 316.5853658536586\n","max_value 131.20000000000002\n","Score: 347.80487804878055\n","max_value 0.0\n","Score: 347.80487804878055\n","max_value 0.0\n","Score: 347.80487804878055\n","max_value 64.0\n","Score: 347.80487804878055\n","max_value 104.96000000000002\n","Score: 411.8048780487805\n","max_value 204.96000000000004\n","Score: 349.49258391881335\n","max_value 64.0\n","Score: 349.49258391881335\n","max_value 64.0\n","Score: 380.7181889149102\n","max_value 163.96800000000005\n","Score: 396.70569867291175\n","max_value 0.0\n","Score: 396.70569867291175\n","max_value 131.17440000000005\n","Score: 409.495706479313\n","max_value 51.2\n","Score: 434.4761904761905\n","max_value 163.96800000000005\n","Score: 450.46370023419206\n","max_value 51.2\n","Score: 475.44418423106947\n","max_value 163.96800000000005\n","Score: 475.44418423106947\n","max_value 163.96800000000005\n","Score: 475.44418423106947\n","max_value 51.2\n","Score: 500.42466822794694\n","max_value 64.0\n","Score: 500.42466822794694\n","max_value 131.17440000000005\n","Score: 500.42466822794694\n","max_value 131.17440000000005\n","Score: 500.42466822794694\n","max_value 131.17440000000005\n","Score: 500.42466822794694\n","max_value 51.2\n","Score: 500.42466822794694\n","max_value 51.2\n","Score: 525.4051522248244\n","max_value 231.17440000000005\n","Score: 565.8259738102489\n","max_value 51.2\n","Score: 565.8259738102489\n","max_value 284.93952\n","Score: 487.1294511902035\n","max_value 227.95161600000003\n","Score: 509.5846079897939\n","max_value 51.2\n","Score: 509.5846079897939\n","max_value 64.0\n","Score: 532.0455147815228\n","max_value 227.95161600000003\n","Score: 532.0455147815228\n","max_value 51.2\n","Score: 532.0455147815228\n","max_value 51.2\n","Score: 532.0455147815228\n","max_value 64.0\n","Score: 532.0455147815228\n","max_value 64.0\n","Score: 532.0455147815228\n","max_value 64.0\n","Score: 532.0455147815228\n","max_value 51.2\n","Score: 532.0455147815228\n","max_value 64.0\n","Score: 532.0455147815228\n","max_value 51.2\n","Score: 532.0455147815228\n","max_value 51.2\n","Score: 532.0455147815228\n","max_value 64.0\n","Score: 532.0455147815228\n","max_value 40.96000000000001\n","Score: 546.4204951282294\n","max_value 40.96000000000001\n","Score: 560.795475474936\n","max_value 64.0\n","Score: 560.795475474936\n","max_value 51.2\n","Score: 560.795475474936\n","max_value 51.2\n","Score: 560.795475474936\n","max_value 51.2\n","Score: 560.795475474936\n","max_value 51.2\n","Score: 560.795475474936\n","max_value 40.96000000000001\n","Score: 560.795475474936\n","max_value 284.93952\n","Score: 560.795475474936\n","max_value 51.2\n","Score: 560.795475474936\n","max_value 40.96000000000001\n","Score: 560.795475474936\n","max_value 51.2\n","Score: 560.795475474936\n","max_value 284.93952\n","Score: 579.6644340525316\n","max_value 227.95161600000003\n","Score: 602.119590852122\n","max_value 51.2\n","Score: 602.119590852122\n","max_value 227.95161600000003\n","Score: 654.0434573624607\n","max_value 40.96000000000001\n","Score: 654.0434573624607\n","max_value 51.2\n","Score: 654.0434573624607\n","max_value 51.2\n","Score: 654.0434573624607\n","max_value 327.95161600000006\n","Score: 581.3785604276455\n","max_value 262.36129280000006\n","Score: 591.8708632922242\n","max_value 51.2\n","Score: 591.8708632922242\n","max_value 209.88903424000006\n","Score: 615.8727679634303\n","max_value 209.88903424000006\n","Score: 615.8727679634303\n","max_value 40.96000000000001\n","Score: 615.8727679634303\n","max_value 182.36129280000003\n","Score: 651.963851838437\n","max_value 182.36129280000003\n","Score: 688.0549357134437\n","max_value 262.36129280000006\n","Score: 688.0549357134437\n","max_value 51.2\n","Score: 688.0549357134437\n","max_value 262.36129280000006\n","Score: 688.0549357134437\n","max_value 51.2\n","Score: 688.0549357134437\n","max_value 51.2\n","Score: 688.0549357134437\n","max_value 262.36129280000006\n","Score: 688.0549357134437\n","max_value 262.36129280000006\n","Score: 688.0549357134437\n","max_value 51.2\n","Score: 688.0549357134437\n","max_value 327.95161600000006\n","Score: 701.1703142941672\n","max_value 262.36129280000006\n","Score: 701.1703142941672\n","max_value 262.36129280000006\n","Score: 701.1703142941672\n","max_value 51.2\n","Score: 701.1703142941672\n","max_value 362.36129280000006\n","Score: 644.0834326993547\n","max_value 209.88903424000006\n","Score: 644.0834326993547\n","max_value 289.88903424000006\n","Score: 661.1761574110378\n","max_value 182.36129280000003\n","Score: 661.1761574110378\n","max_value 182.36129280000003\n","Score: 661.1761574110378\n","max_value 51.2\n","Score: 661.1761574110378\n","max_value 362.36129280000006\n","Score: 670.6721155841951\n","max_value 51.2\n","Score: 670.6721155841951\n","max_value 182.36129280000003\n","Score: 670.6721155841951\n","max_value 289.88903424000006\n","Score: 670.6721155841951\n","max_value 51.2\n","Score: 670.6721155841951\n","max_value 182.36129280000003\n","Score: 670.6721155841951\n","max_value 289.88903424000006\n","Score: 670.6721155841951\n","max_value 51.2\n","Score: 670.6721155841951\n","max_value 40.96000000000001\n","Score: 670.6721155841951\n","max_value 289.88903424000006\n","Score: 670.6721155841951\n","max_value 389.88903424000006\n","Score: 630.3803580192737\n","max_value 51.2\n","Score: 630.3803580192737\n","max_value 51.2\n","Score: 630.3803580192737\n","max_value 311.91122739200006\n","Score: 643.0890854367005\n","max_value 51.2\n","Score: 643.0890854367005\n","max_value 182.36129280000003\n","Score: 673.4467724721203\n","max_value 311.91122739200006\n","Score: 673.4467724721203\n","max_value 145.88903424000003\n","Score: 697.7329221004562\n","max_value 182.36129280000003\n","Score: 697.7329221004562\n","max_value 145.88903424000003\n","Score: 722.0190717287921\n","max_value 145.88903424000003\n","Score: 722.0190717287921\n","max_value 311.91122739200006\n","Score: 722.0190717287921\n","max_value 145.88903424000003\n","Score: 722.0190717287921\n","max_value 182.36129280000003\n","Score: 722.0190717287921\n","max_value 116.71122739200003\n","Score: 741.4479914314608\n","max_value 311.91122739200006\n","Score: 741.4479914314608\n","max_value 311.91122739200006\n","Score: 762.9822239998787\n","max_value 145.88903424000003\n","Score: 762.9822239998787\n","max_value 145.88903424000003\n","Score: 762.9822239998787\n","max_value 311.91122739200006\n","Score: 762.9822239998787\n","max_value 311.91122739200006\n","Score: 768.6305472965128\n","max_value 145.88903424000003\n","Score: 768.6305472965128\n","max_value 145.88903424000003\n","Score: 768.6305472965128\n","max_value 145.88903424000003\n","Score: 768.6305472965128\n","max_value 249.52898191360006\n","Score: 785.8579333512471\n","max_value 249.52898191360006\n","Score: 785.8579333512471\n","max_value 116.71122739200003\n","Score: 785.8579333512471\n","max_value 249.52898191360006\n","Score: 796.0249152851886\n","max_value 199.62318553088005\n","Score: 834.0929737573119\n","max_value 311.91122739200006\n","Score: 834.0929737573119\n","max_value 199.62318553088005\n","Score: 834.0929737573119\n","max_value 311.91122739200006\n","Score: 834.0929737573119\n","max_value 311.91122739200006\n","Score: 834.0929737573119\n","max_value 311.91122739200006\n","Score: 834.0929737573119\n","max_value 145.88903424000003\n","Score: 834.0929737573119\n","max_value 311.91122739200006\n","Score: 834.0929737573119\n","max_value 249.52898191360006\n","Score: 834.0929737573119\n","max_value 311.91122739200006\n","Score: 834.0929737573119\n","max_value 116.71122739200003\n","Score: 834.0929737573119\n","max_value 116.71122739200003\n","Score: 853.5218934599807\n","max_value 145.88903424000003\n","Score: 853.5218934599807\n","max_value 145.88903424000003\n","Score: 853.5218934599807\n","max_value 249.52898191360006\n","Score: 870.749279514715\n","max_value 389.88903424000006\n","Score: 877.8096836355077\n","max_value 116.71122739200003\n","Score: 877.8096836355077\n","max_value 311.91122739200006\n","Score: 877.8096836355077\n","max_value 311.91122739200006\n","Score: 877.8096836355077\n","max_value 199.62318553088005\n","Score: 891.5915924792951\n","max_value 199.62318553088005\n","Score: 905.3735013230826\n","max_value 249.52898191360006\n","Score: 905.3735013230826\n","max_value 199.62318553088005\n","Score: 905.3735013230826\n","max_value 199.62318553088005\n","Score: 905.3735013230826\n","max_value 249.52898191360006\n","Score: 905.3735013230826\n","max_value 249.52898191360006\n","Score: 905.3735013230826\n","max_value 311.91122739200006\n","Score: 905.3735013230826\n","max_value 199.62318553088005\n","Score: 905.3735013230826\n","max_value 199.62318553088005\n","Score: 905.3735013230826\n","max_value 249.52898191360006\n","Score: 922.6008873778169\n","max_value 249.52898191360006\n","Score: 922.6008873778169\n","max_value 411.91122739200006\n","Score: 878.6218102753587\n","max_value 411.91122739200006\n","Score: 878.6218102753587\n","max_value 199.62318553088005\n","Score: 914.6546192062092\n","max_value 249.52898191360006\n","Score: 914.6546192062092\n","max_value 199.62318553088005\n","Score: 914.6546192062092\n","max_value 199.62318553088005\n","Score: 914.6546192062092\n","max_value 249.52898191360006\n","Score: 914.6546192062092\n","max_value 199.62318553088005\n","Score: 914.6546192062092\n","max_value 199.62318553088005\n","Score: 914.6546192062092\n","max_value 329.5289819136001\n","Score: 918.9316947870684\n","max_value 329.5289819136001\n","Score: 918.9316947870684\n","max_value 249.52898191360006\n","Score: 918.9316947870684\n","max_value 329.5289819136001\n","Score: 918.9316947870684\n","max_value 249.52898191360006\n","Score: 918.9316947870684\n","max_value 329.5289819136001\n","Score: 923.2087703679274\n","max_value 263.6231855308801\n","Score: 926.6304308326146\n","max_value 199.62318553088005\n","Score: 926.6304308326146\n","max_value 199.62318553088005\n","Score: 926.6304308326146\n","max_value 263.6231855308801\n","Score: 926.6304308326146\n","max_value 199.62318553088005\n","Score: 926.6304308326146\n","max_value 329.5289819136001\n","Score: 926.6304308326146\n","max_value 199.62318553088005\n","Score: 926.6304308326146\n","max_value 249.52898191360006\n","Score: 926.6304308326146\n","max_value 199.62318553088005\n","Score: 926.6304308326146\n","max_value 159.69854842470406\n","Score: 937.0664952499106\n","max_value 411.91122739200006\n","Score: 937.0664952499106\n","max_value 329.5289819136001\n","Score: 937.0664952499106\n","max_value 199.62318553088005\n","Score: 937.0664952499106\n","max_value 199.62318553088005\n","Score: 937.0664952499106\n","max_value 199.62318553088005\n","Score: 937.0664952499106\n","max_value 159.69854842470406\n","Score: 937.0664952499106\n","max_value 199.62318553088005\n","Score: 937.0664952499106\n","max_value 263.6231855308801\n","Score: 937.0664952499106\n","max_value 411.91122739200006\n","Score: 942.4128397259844\n","max_value 329.5289819136001\n","Score: 942.4128397259844\n","max_value 159.69854842470406\n","Score: 952.8489041432805\n","max_value 199.62318553088005\n","Score: 952.8489041432805\n","max_value 263.6231855308801\n","Score: 952.8489041432805\n","max_value 199.62318553088005\n","Score: 952.8489041432805\n","max_value 329.5289819136001\n","Score: 952.8489041432805\n","max_value 329.5289819136001\n","Score: 952.8489041432805\n","max_value 199.62318553088005\n","Score: 952.8489041432805\n","max_value 249.52898191360006\n","Score: 952.8489041432805\n","max_value 199.62318553088005\n","Score: 952.8489041432805\n","max_value 249.52898191360006\n","Score: 952.8489041432805\n","max_value 429.5289819136001\n","Score: 917.8680686935454\n","max_value 249.52898191360006\n","Score: 917.8680686935454\n","max_value 199.62318553088005\n","Score: 917.8680686935454\n","max_value 329.5289819136001\n","Score: 917.8680686935454\n","max_value 159.69854842470406\n","Score: 917.8680686935454\n","max_value 199.62318553088005\n","Score: 917.8680686935454\n","max_value 199.62318553088005\n","Score: 917.8680686935454\n","max_value 443.6231855308801\n","Score: 895.8551893883482\n","max_value 199.62318553088005\n","Score: 895.8551893883482\n","max_value 443.6231855308801\n","Score: 899.0322558891473\n","max_value 249.52898191360006\n","Score: 899.0322558891473\n","max_value 199.62318553088005\n","Score: 899.0322558891473\n","max_value 354.89854842470413\n","Score: 904.750975590586\n","max_value 199.62318553088005\n","Score: 904.750975590586\n","max_value 249.52898191360006\n","Score: 904.750975590586\n","max_value 354.89854842470413\n","Score: 910.4696952920247\n","max_value 354.89854842470413\n","Score: 910.4696952920247\n","max_value 199.62318553088005\n","Score: 910.4696952920247\n","max_value 454.89854842470413\n","Score: 890.3809525151785\n","max_value 249.52898191360006\n","Score: 890.3809525151785\n","max_value 354.89854842470413\n","Score: 899.8308224216812\n","max_value 463.9188387397633\n","Score: 886.7096265928385\n","max_value 371.13507099181066\n","Score: 890.2094893298668\n","max_value 463.9188387397633\n","Score: 892.1538575171046\n","max_value 199.62318553088005\n","Score: 892.1538575171046\n","max_value 371.13507099181066\n","Score: 895.6537202541326\n","max_value 296.90805679344857\n","Score: 905.8665141575995\n","max_value 371.13507099181066\n","Score: 909.3663768946276\n","max_value 296.90805679344857\n","Score: 919.5791707980943\n","max_value 371.13507099181066\n","Score: 919.5791707980943\n","max_value 371.13507099181066\n","Score: 919.5791707980943\n","max_value 237.52644543475887\n","Score: 927.7494059208677\n","max_value 296.90805679344857\n","Score: 927.7494059208677\n","max_value 190.0211563478071\n","Score: 934.2855940190865\n","max_value 237.52644543475887\n","Score: 942.45582914186\n","max_value 471.13507099181066\n","Score: 929.5521900381508\n","max_value 296.90805679344857\n","Score: 936.6170156713813\n","max_value 296.90805679344857\n","Score: 946.6733833241032\n","max_value 296.90805679344857\n","Score: 946.6733833241032\n","max_value 237.52644543475887\n","Score: 954.7184774462806\n","max_value 471.13507099181066\n","Score: 956.2501469602602\n","max_value 296.90805679344857\n","Score: 956.2501469602602\n","max_value 476.90805679344857\n","Score: 945.8852142009193\n","max_value 481.5264454347589\n","Score: 937.7722087737914\n","max_value 237.52644543475887\n","Score: 937.7722087737914\n","max_value 485.22115634780715\n","Score: 933.5345768172895\n","max_value 190.0211563478071\n","Score: 933.5345768172895\n","max_value 388.17692507824574\n","Score: 937.0467596360904\n","max_value 388.17692507824574\n","Score: 940.5589424548914\n","max_value 190.0211563478071\n","Score: 940.5589424548914\n","max_value 237.52644543475887\n","Score: 940.5589424548914\n","max_value 237.52644543475887\n","Score: 948.3704855848678\n","max_value 388.17692507824574\n","Score: 948.3704855848678\n","max_value 296.90805679344857\n","Score: 948.3704855848678\n","max_value 237.52644543475887\n","Score: 948.3704855848678\n","max_value 296.90805679344857\n","Score: 948.3704855848678\n","max_value 237.52644543475887\n","Score: 948.3704855848678\n","max_value 237.52644543475887\n","Score: 948.3704855848678\n","max_value 296.90805679344857\n","Score: 948.3704855848678\n","max_value 190.0211563478071\n","Score: 948.3704855848678\n","max_value 485.22115634780715\n","Score: 949.1319344344723\n","max_value 488.17692507824574\n","Score: 943.9906885236461\n","max_value 390.5415400625966\n","Score: 944.4750651631138\n","max_value 310.5415400625966\n","Score: 947.2677992250449\n","max_value 237.52644543475887\n","Score: 947.2677992250449\n","max_value 248.4332320500773\n","Score: 949.5019864745898\n","max_value 237.52644543475887\n","Score: 949.5019864745898\n","max_value 237.52644543475887\n","Score: 949.5019864745898\n","max_value 296.90805679344857\n","Score: 949.5019864745898\n","max_value 488.17692507824574\n","Score: 950.1074572739244\n","max_value 490.5415400625966\n","Score: 946.00958447905\n","max_value 490.5415400625966\n","Score: 946.4916262209276\n","max_value 237.52644543475887\n","Score: 946.4916262209276\n","max_value 190.0211563478071\n","Score: 946.4916262209276\n","max_value 237.52644543475887\n","Score: 946.4916262209276\n","max_value 237.52644543475887\n","Score: 946.4916262209276\n","max_value 492.4332320500773\n","Score: 943.2398119188643\n","max_value 310.5415400625966\n","Score: 943.2398119188643\n","max_value 393.94658564006187\n","Score: 947.8722195557908\n","max_value 492.4332320500773\n","Score: 947.8722195557908\n","max_value 310.5415400625966\n","Score: 947.8722195557908\n","max_value 190.0211563478071\n","Score: 954.0299290582275\n","max_value 310.5415400625966\n","Score: 954.0299290582275\n","max_value 310.5415400625966\n","Score: 956.798524348271\n","max_value 393.94658564006187\n","Score: 956.798524348271\n","max_value 393.94658564006187\n","Score: 957.4899979036379\n","max_value 393.94658564006187\n","Score: 958.6616614280099\n","max_value 315.15726851204954\n","Score: 959.5989922475073\n","max_value 315.15726851204954\n","Score: 959.5989922475073\n","max_value 315.15726851204954\n","Score: 959.5989922475073\n","max_value 237.52644543475887\n","Score: 959.5989922475073\n","max_value 315.15726851204954\n","Score: 959.5989922475073\n","max_value 190.0211563478071\n","Score: 959.5989922475073\n","max_value 315.15726851204954\n","Score: 963.3049183570483\n","max_value 393.94658564006187\n","Score: 963.3049183570483\n","max_value 393.94658564006187\n","Score: 963.3049183570483\n","max_value 252.12581480963965\n","Score: 966.2696592446812\n","max_value 492.4332320500773\n","Score: 966.2696592446812\n","max_value 315.15726851204954\n","Score: 969.9755853542224\n","max_value 252.12581480963965\n","Score: 970.7254500098204\n","max_value 393.94658564006187\n","Score: 970.7254500098204\n","max_value 201.70065184771173\n","Score: 973.0972427199267\n","max_value 252.12581480963965\n","Score: 976.0619836075596\n","max_value 393.94658564006187\n","Score: 976.0619836075596\n","max_value 315.15726851204954\n","Score: 976.999314427057\n","max_value 201.70065184771173\n","Score: 979.3711071371633\n","max_value 252.12581480963965\n","Score: 979.3711071371633\n","max_value 315.15726851204954\n","Score: 979.3711071371633\n","max_value 252.12581480963965\n","Score: 979.3711071371633\n","max_value 315.15726851204954\n","Score: 979.3711071371633\n","max_value 315.15726851204954\n","Score: 979.3711071371633\n","max_value 201.70065184771173\n","Score: 979.3711071371633\n","max_value 315.15726851204954\n","Score: 979.3711071371633\n","max_value 315.15726851204954\n","Score: 979.3711071371633\n","max_value 252.12581480963965\n","Score: 979.3711071371633\n","max_value 252.12581480963965\n","Score: 979.3711071371633\n","max_value 315.15726851204954\n","Score: 979.3711071371633\n","max_value 201.70065184771173\n","Score: 979.3711071371633\n","max_value 252.12581480963965\n","Score: 979.3711071371633\n","max_value 252.12581480963965\n","Score: 979.3711071371633\n","max_value 393.94658564006187\n","Score: 979.3711071371633\n","max_value 393.94658564006187\n","Score: 979.3711071371633\n","max_value 492.4332320500773\n","Score: 979.7552591123672\n","max_value 493.94658564006187\n","Score: 977.059864876652\n","max_value 395.15726851204954\n","Score: 977.3049688832762\n","max_value 316.1258148096397\n","Score: 977.5010520885758\n","max_value 315.15726851204954\n","Score: 977.5010520885758\n","max_value 252.12581480963965\n","Score: 977.5010520885758\n","max_value 395.15726851204954\n","Score: 977.5010520885758\n","max_value 395.15726851204954\n","Score: 977.7461560951999\n","max_value 493.94658564006187\n","Score: 977.7461560951999\n","max_value 315.15726851204954\n","Score: 977.7461560951999\n","max_value 315.15726851204954\n","Score: 977.7461560951999\n","max_value 493.94658564006187\n","Score: 977.7461560951999\n","max_value 252.12581480963965\n","Score: 977.7461560951999\n","max_value 252.12581480963965\n","Score: 977.7461560951999\n","max_value 315.15726851204954\n","Score: 977.7461560951999\n","max_value 395.15726851204954\n","Score: 977.9912601018243\n","max_value 316.1258148096397\n","Score: 978.1873433071237\n","max_value 316.1258148096397\n","Score: 978.3834265124231\n","max_value 252.12581480963965\n","Score: 978.3834265124231\n","max_value 316.1258148096397\n","Score: 978.3834265124231\n","max_value 316.1258148096397\n","Score: 978.3834265124231\n","max_value 395.15726851204954\n","Score: 978.3834265124231\n","max_value 316.1258148096397\n","Score: 978.3834265124231\n","max_value 395.15726851204954\n","Score: 978.3834265124231\n","max_value 395.15726851204954\n","Score: 978.3834265124231\n","max_value 395.15726851204954\n","Score: 978.3834265124231\n","max_value 493.94658564006187\n","Score: 978.6898065207033\n","max_value 252.12581480963965\n","Score: 981.6454640349591\n","max_value 252.12581480963965\n","Score: 981.6454640349591\n","max_value 495.15726851204954\n","Score: 979.4897992990254\n","max_value 316.1258148096397\n","Score: 979.4897992990254\n","max_value 252.12581480963965\n","Score: 979.4897992990254\n","max_value 316.1258148096397\n","Score: 979.4897992990254\n","max_value 252.12581480963965\n","Score: 979.4897992990254\n","max_value 496.1258148096397\n","Score: 977.772842504092\n","max_value 201.70065184771173\n","Score: 977.772842504092\n","max_value 252.12581480963965\n","Score: 977.772842504092\n","max_value 496.90065184771174\n","Score: 976.404096242929\n","max_value 316.1258148096397\n","Score: 976.404096242929\n","max_value 252.12581480963965\n","Score: 976.404096242929\n","max_value 201.70065184771173\n","Score: 976.404096242929\n","max_value 252.90065184771174\n","Score: 976.5600302380225\n","max_value 252.12581480963965\n","Score: 976.5600302380225\n","max_value 252.12581480963965\n","Score: 976.5600302380225\n","max_value 316.1258148096397\n","Score: 976.5600302380225\n","max_value 395.15726851204954\n","Score: 976.5600302380225\n","max_value 252.12581480963965\n","Score: 976.5600302380225\n","max_value 316.1258148096397\n","Score: 976.5600302380225\n","max_value 497.5205214781694\n","Score: 976.0616662298085\n","max_value 497.5205214781694\n","Score: 976.0616662298085\n","max_value 316.1258148096397\n","Score: 976.0616662298085\n","max_value 316.1258148096397\n","Score: 976.0616662298085\n","max_value 201.70065184771173\n","Score: 976.0616662298085\n","max_value 316.1258148096397\n","Score: 976.0616662298085\n","max_value 252.12581480963965\n","Score: 976.0616662298085\n","max_value 398.0164171825356\n","Score: 976.6363457750845\n","max_value 316.1258148096397\n","Score: 976.8310204177933\n","max_value 252.90065184771174\n","Score: 976.9867601319602\n","max_value 252.90065184771174\n","Score: 977.1424998461272\n","max_value 316.1258148096397\n","Score: 977.1424998461272\n","max_value 252.90065184771174\n","Score: 977.2982395602942\n","max_value 316.1258148096397\n","Score: 977.2982395602942\n","max_value 252.90065184771174\n","Score: 977.2982395602942\n","max_value 497.5205214781694\n","Score: 977.2982395602942\n","max_value 398.0164171825356\n","Score: 977.2982395602942\n","max_value 398.0164171825356\n","Score: 977.8729191055703\n","max_value 318.4131337460285\n","Score: 978.3326627417912\n","max_value 202.3205214781694\n","Score: 978.4572545131248\n","max_value 398.0164171825356\n","Score: 978.4572545131248\n","max_value 252.90065184771174\n","Score: 978.4572545131248\n","max_value 252.90065184771174\n","Score: 978.4572545131248\n","max_value 398.0164171825356\n","Score: 978.4572545131248\n","max_value 252.90065184771174\n","Score: 978.4572545131248\n","max_value 398.0164171825356\n","Score: 978.4572545131248\n","max_value 497.5205214781694\n","Score: 978.4572545131248\n","max_value 252.90065184771174\n","Score: 978.4572545131248\n","max_value 398.0164171825356\n","Score: 978.4572545131248\n","max_value 398.0164171825356\n","Score: 978.4572545131248\n","max_value 398.0164171825356\n","Score: 978.4572545131248\n","max_value 398.0164171825356\n","Score: 978.4572545131248\n","max_value 202.3205214781694\n","Score: 978.4572545131248\n","max_value 252.90065184771174\n","Score: 978.4572545131248\n","max_value 202.3205214781694\n","Score: 978.5818462844584\n","max_value 318.4131337460285\n","Score: 978.5818462844584\n","max_value 252.90065184771174\n","Score: 978.5818462844584\n","max_value 252.90065184771174\n","Score: 978.5818462844584\n","max_value 202.3205214781694\n","Score: 978.5818462844584\n","max_value 398.0164171825356\n","Score: 978.5818462844584\n","max_value 318.4131337460285\n","Score: 979.0415899206791\n","max_value 497.5205214781694\n","Score: 979.1661816920127\n","max_value 252.90065184771174\n","Score: 979.1661816920127\n","max_value 398.0164171825356\n","Score: 979.1661816920127\n","max_value 498.0164171825356\n","Score: 978.2907592804554\n","max_value 318.4131337460285\n","Score: 978.2907592804554\n","max_value 252.90065184771174\n","Score: 978.2907592804554\n","max_value 498.0164171825356\n","Score: 978.2907592804554\n","max_value 202.3205214781694\n","Score: 978.2907592804554\n","max_value 398.4131337460285\n","Score: 978.3704186149282\n","max_value 202.3205214781694\n","Score: 978.3704186149282\n","max_value 318.73050699682284\n","Score: 978.8934319328262\n","max_value 498.0164171825356\n","Score: 978.9930061009172\n","max_value 498.4131337460285\n","Score: 978.2933634528719\n","max_value 318.4131337460285\n","Score: 978.2933634528719\n","max_value 252.90065184771174\n","Score: 978.2933634528719\n","max_value 318.4131337460285\n","Score: 978.2933634528719\n","max_value 398.4131337460285\n","Score: 978.2933634528719\n","max_value 318.4131337460285\n","Score: 978.2933634528719\n","max_value 318.4131337460285\n","Score: 978.2933634528719\n","max_value 252.90065184771174\n","Score: 978.2933634528719\n","max_value 398.4131337460285\n","Score: 978.2933634528719\n","max_value 252.90065184771174\n","Score: 978.2933634528719\n","max_value 398.4131337460285\n","Score: 978.2933634528719\n","max_value 498.73050699682284\n","Score: 977.7344507414987\n","max_value 202.3205214781694\n","Score: 977.7344507414987\n","max_value 318.4131337460285\n","Score: 977.7344507414987\n","max_value 498.9844055974583\n","Score: 977.2878324779359\n","max_value 398.4131337460285\n","Score: 977.9403308721654\n","max_value 318.4131337460285\n","Score: 977.9403308721654\n","max_value 252.90065184771174\n","Score: 977.9403308721654\n","max_value 318.73050699682284\n","Score: 977.9403308721654\n","max_value 398.4131337460285\n","Score: 977.9403308721654\n","max_value 202.3205214781694\n","Score: 977.9403308721654\n","max_value 252.90065184771174\n","Score: 977.9403308721654\n","max_value 252.90065184771174\n","Score: 977.9403308721654\n","max_value 318.4131337460285\n","Score: 977.9403308721654\n","max_value 398.4131337460285\n","Score: 977.9403308721654\n","max_value 318.4131337460285\n","Score: 977.9403308721654\n","max_value 318.4131337460285\n","Score: 977.9403308721654\n","max_value 398.4131337460285\n","Score: 977.9403308721654\n","max_value 252.90065184771174\n","Score: 977.9403308721654\n","max_value 318.73050699682284\n","Score: 977.9403308721654\n","max_value 252.90065184771174\n","Score: 977.9403308721654\n","max_value 252.90065184771174\n","Score: 977.9403308721654\n","max_value 252.90065184771174\n","Score: 977.9403308721654\n","max_value 499.1875244779667\n","Score: 977.5830978717086\n","max_value 252.90065184771174\n","Score: 977.5830978717086\n","max_value 318.4131337460285\n","Score: 977.5830978717086\n","max_value 318.4131337460285\n","Score: 977.5830978717086\n","max_value 398.4131337460285\n","Score: 977.5830978717086\n","max_value 252.90065184771174\n","Score: 977.5830978717086\n","max_value 252.90065184771174\n","Score: 977.5830978717086\n","max_value 318.4131337460285\n","Score: 978.0413062251287\n","max_value 254.7305069968228\n","Score: 978.4078729078647\n","max_value 318.73050699682284\n","Score: 978.4078729078647\n","max_value 202.3205214781694\n","Score: 978.4078729078647\n","max_value 254.7305069968228\n","Score: 978.7744395906008\n","max_value 254.7305069968228\n","Score: 979.1410062733368\n","max_value 499.35001958237336\n","Score: 979.0894484901189\n","max_value 254.7305069968228\n","Score: 979.0894484901189\n","max_value 318.4131337460285\n","Score: 979.0894484901189\n","max_value 318.4131337460285\n","Score: 979.0894484901189\n","max_value 203.78440559745826\n","Score: 979.3826064077882\n","max_value 254.7305069968228\n","Score: 979.3826064077882\n","max_value 399.4800156658987\n","Score: 979.5962605337583\n","max_value 254.7305069968228\n","Score: 979.5962605337583\n","max_value 318.4131337460285\n","Score: 979.5962605337583\n","max_value 203.78440559745826\n","Score: 979.5962605337583\n","max_value 399.4800156658987\n","Score: 979.5962605337583\n","max_value 399.4800156658987\n","Score: 979.5962605337583\n","max_value 399.4800156658987\n","Score: 979.8893612498827\n","max_value 254.7305069968228\n","Score: 979.8893612498827\n","max_value 399.4800156658987\n","Score: 979.8893612498827\n","max_value 254.7305069968228\n","Score: 979.8893612498827\n","max_value 319.584012532719\n","Score: 980.1238418227822\n","max_value 254.7305069968228\n","Score: 980.1238418227822\n","max_value 319.584012532719\n","Score: 980.1238418227822\n","max_value 399.4800156658987\n","Score: 980.1238418227822\n","max_value 254.7305069968228\n","Score: 980.1238418227822\n","max_value 254.7305069968228\n","Score: 980.1238418227822\n","max_value 399.4800156658987\n","Score: 980.3374959487522\n","max_value 319.584012532719\n","Score: 980.3374959487522\n","max_value 399.4800156658987\n","Score: 980.3374959487522\n","max_value 319.584012532719\n","Score: 980.3374959487522\n","max_value 319.584012532719\n","Score: 980.5719765216518\n","max_value 399.4800156658987\n","Score: 980.5719765216518\n","max_value 254.7305069968228\n","Score: 980.5719765216518\n","max_value 499.35001958237336\n","Score: 980.6045178449789\n","max_value 319.584012532719\n","Score: 980.7754411457549\n","max_value 203.78440559745826\n","Score: 980.7754411457549\n","max_value 319.584012532719\n","Score: 980.7754411457549\n","max_value 319.584012532719\n","Score: 980.7754411457549\n","max_value 254.7305069968228\n","Score: 980.7754411457549\n","max_value 499.4800156658987\n","Score: 980.5462080348734\n","max_value 319.584012532719\n","Score: 980.5462080348734\n","max_value 319.584012532719\n","Score: 980.5462080348734\n","max_value 499.584012532719\n","Score: 980.3629074399207\n","max_value 254.7305069968228\n","Score: 980.3629074399207\n","max_value 254.7305069968228\n","Score: 980.3629074399207\n","max_value 319.584012532719\n","Score: 980.5972781878464\n","max_value 255.6672100261752\n","Score: 980.7847747861871\n","max_value 255.6672100261752\n","Score: 980.9722713845277\n","max_value 499.6672100261752\n","Score: 980.8724141420513\n","max_value 204.5337680209402\n","Score: 981.3153582653318\n","max_value 203.78440559745826\n","Score: 981.3153582653318\n","max_value 255.6672100261752\n","Score: 981.8690384194325\n","max_value 399.7337680209402\n","Score: 981.919822691434\n","max_value 319.7870144167522\n","Score: 981.960450109035\n","max_value 319.584012532719\n","Score: 981.960450109035\n","max_value 319.7870144167522\n","Score: 981.960450109035\n","max_value 399.7337680209402\n","Score: 982.0112343810364\n","max_value 203.78440559745826\n","Score: 982.0112343810364\n","max_value 319.7870144167522\n","Score: 982.0112343810364\n","max_value 255.6672100261752\n","Score: 982.0112343810364\n","max_value 319.7870144167522\n","Score: 982.0518617986376\n","max_value 399.7337680209402\n","Score: 982.102646070639\n","max_value 255.82961153340176\n","Score: 982.1351480047199\n","max_value 255.82961153340176\n","Score: 982.1676499388009\n","max_value 255.82961153340176\n","Score: 982.2001518728816\n","max_value 255.82961153340176\n","Score: 982.4201191860302\n","max_value 399.7337680209402\n","Score: 982.4201191860302\n","max_value 255.82961153340176\n","Score: 982.4201191860302\n","max_value 204.66368922672143\n","Score: 982.446120733295\n","max_value 255.82961153340176\n","Score: 982.446120733295\n","max_value 319.7870144167522\n","Score: 982.4867481508961\n","max_value 255.82961153340176\n","Score: 982.4867481508961\n","max_value 319.7870144167522\n","Score: 982.4867481508961\n","max_value 255.82961153340176\n","Score: 982.4867481508961\n","max_value 399.7337680209402\n","Score: 982.4867481508961\n","max_value 399.7337680209402\n","Score: 982.4867481508961\n","max_value 255.82961153340176\n","Score: 982.4867481508961\n","max_value 255.82961153340176\n","Score: 982.4867481508961\n","max_value 319.7870144167522\n","Score: 982.5273755684972\n","max_value 319.7870144167522\n","Score: 982.5273755684972\n","max_value 399.7337680209402\n","Score: 982.5273755684972\n","max_value 399.7337680209402\n","Score: 982.5273755684972\n","max_value 499.6672100261752\n","Score: 982.5440261494813\n","max_value 399.7337680209402\n","Score: 982.5440261494813\n","max_value 204.66368922672143\n","Score: 982.72\n","max_value 255.82961153340176\n","Score: 982.72\n","max_value 204.66368922672143\n","Score: 982.72\n","max_value 399.7337680209402\n","Score: 982.72\n","max_value 255.82961153340176\n","Score: 982.72\n","max_value 499.7337680209402\n","Score: 982.6024332536672\n","max_value 319.7870144167522\n","Score: 982.6024332536672\n","max_value 399.7870144167522\n","Score: 982.6130882062077\n","max_value 319.7870144167522\n","Score: 982.6130882062077\n","max_value 319.7870144167522\n","Score: 982.6130882062077\n","max_value 255.82961153340176\n","Score: 982.6130882062077\n","max_value 399.7870144167522\n","Score: 982.6130882062077\n","max_value 319.7870144167522\n","Score: 982.6130882062077\n","max_value 399.7870144167522\n","Score: 982.6237431587483\n","max_value 319.82961153340176\n","Score: 982.6322671207809\n","max_value 255.82961153340176\n","Score: 982.6322671207809\n","max_value 255.82961153340176\n","Score: 982.6322671207809\n","max_value 255.82961153340176\n","Score: 982.6322671207809\n","max_value 255.82961153340176\n","Score: 982.6322671207809\n","max_value 499.7337680209402\n","Score: 982.6455858114566\n","max_value 319.7870144167522\n","Score: 982.6455858114566\n","max_value 204.66368922672143\n","Score: 982.6455858114566\n","max_value 499.7870144167522\n","Score: 982.5515503626191\n","max_value 319.82961153340176\n","Score: 982.5515503626191\n","max_value 399.7870144167522\n","Score: 982.5515503626191\n","max_value 255.82961153340176\n","Score: 982.5515503626191\n","max_value 399.7870144167522\n","Score: 982.5515503626191\n","max_value 255.82961153340176\n","Score: 982.5515503626191\n","max_value 255.82961153340176\n","Score: 982.5515503626191\n","max_value 499.82961153340176\n","Score: 982.4763364287653\n","max_value 204.66368922672143\n","Score: 982.4763364287653\n","max_value 319.7870144167522\n","Score: 982.4763364287653\n","max_value 255.82961153340176\n","Score: 982.4763364287653\n","max_value 399.7870144167522\n","Score: 982.4763364287653\n","max_value 255.82961153340176\n","Score: 982.4763364287653\n","max_value 499.8636892267214\n","Score: 982.4353484411397\n","max_value 255.82961153340176\n","Score: 982.4353484411397\n","max_value 255.82961153340176\n","Score: 982.4353484411397\n","max_value 204.66368922672143\n","Score: 982.4353484411397\n","max_value 319.7870144167522\n","Score: 982.4353484411397\n","max_value 319.82961153340176\n","Score: 982.4353484411397\n","max_value 319.7870144167522\n","Score: 982.4353484411397\n","max_value 319.7870144167522\n","Score: 982.4353484411397\n","max_value 399.89095138137714\n","Score: 982.4561415027013\n","max_value 399.89095138137714\n","Score: 982.4769345642628\n","max_value 319.7870144167522\n","Score: 982.4769345642628\n","max_value 399.89095138137714\n","Score: 982.4769345642628\n","max_value 319.7870144167522\n","Score: 982.4769345642628\n","max_value 255.82961153340176\n","Score: 982.4769345642628\n","max_value 255.82961153340176\n","Score: 982.4769345642628\n","max_value 399.89095138137714\n","Score: 982.5083798090014\n","max_value 255.82961153340176\n","Score: 982.5083798090014\n","max_value 399.89095138137714\n","Score: 982.5083798090014\n","max_value 255.82961153340176\n","Score: 982.5083798090014\n","max_value 399.89095138137714\n","Score: 982.5083798090014\n","max_value 255.82961153340176\n","Score: 982.5083798090014\n","max_value 204.66368922672143\n","Score: 982.5083798090014\n","max_value 255.82961153340176\n","Score: 982.5083798090014\n","max_value 499.8636892267214\n","Score: 982.5151972062347\n","max_value 204.66368922672143\n","Score: 982.5151972062347\n","max_value 255.82961153340176\n","Score: 982.5151972062347\n","max_value 319.9127611051017\n","Score: 982.5403534020256\n","max_value 399.89095138137714\n","Score: 982.5403534020256\n","max_value 399.89095138137714\n","Score: 982.5403534020256\n","max_value 255.82961153340176\n","Score: 982.5403534020256\n","max_value 255.82961153340176\n","Score: 982.5403534020256\n","max_value 255.82961153340176\n","Score: 982.5403534020256\n","max_value 399.89095138137714\n","Score: 982.5403534020256\n","max_value 255.93020888408137\n","Score: 982.5604783586583\n","max_value 319.9127611051017\n","Score: 982.5771128079076\n","max_value 255.82961153340176\n","Score: 982.5771128079076\n","max_value 319.9127611051017\n","Score: 982.5771128079076\n","max_value 255.82961153340176\n","Score: 982.5771128079076\n","max_value 255.82961153340176\n","Score: 982.5771128079076\n","max_value 255.82961153340176\n","Score: 982.5771128079076\n","max_value 399.89095138137714\n","Score: 982.5771128079076\n","max_value 499.89095138137714\n","Score: 982.5289804028732\n","max_value 319.9127611051017\n","Score: 982.5289804028732\n","max_value 399.9127611051017\n","Score: 982.5333432991538\n","max_value 255.82961153340176\n","Score: 982.5333432991538\n","max_value 204.66368922672143\n","Score: 982.5333432991538\n","max_value 255.82961153340176\n","Score: 982.5333432991538\n","max_value 399.9127611051017\n","Score: 982.5377061954343\n","max_value 399.9127611051017\n","Score: 982.5377061954343\n","max_value 255.82961153340176\n","Score: 982.5377061954343\n","max_value 319.93020888408137\n","Score: 982.5663513363262\n","max_value 319.93020888408137\n","Score: 982.594996477218\n","max_value 255.94416710726512\n","Score: 982.6179125899316\n","max_value 399.9127611051017\n","Score: 982.6222754862122\n","max_value 319.93020888408137\n","Score: 982.6257658032366\n","max_value 319.93020888408137\n","Score: 982.6257658032366\n","max_value 399.9127611051017\n","Score: 982.6257658032366\n","max_value 204.7553336858121\n","Score: 982.6440986934074\n","max_value 319.93020888408137\n","Score: 982.6440986934074\n","max_value 399.9127611051017\n","Score: 982.6440986934074\n","max_value 399.9127611051017\n","Score: 982.6440986934074\n","max_value 255.94416710726512\n","Score: 982.6440986934074\n","max_value 204.66368922672143\n","Score: 982.6440986934074\n","max_value 204.7553336858121\n","Score: 982.6440986934074\n","max_value 319.93020888408137\n","Score: 982.6440986934074\n","max_value 319.93020888408137\n","Score: 982.6440986934074\n","max_value 399.9127611051017\n","Score: 982.6440986934074\n","max_value 319.93020888408137\n","Score: 982.6440986934074\n","max_value 255.94416710726512\n","Score: 982.6440986934074\n","max_value 319.93020888408137\n","Score: 982.6475890104318\n","max_value 399.9127611051017\n","Score: 982.6475890104318\n","max_value 319.93020888408137\n","Score: 982.6475890104318\n","max_value 255.94416710726512\n","Score: 982.6475890104318\n","max_value 399.9127611051017\n","Score: 982.6475890104318\n","max_value 319.93020888408137\n","Score: 982.6475890104318\n","Trained Q matrix:\n","[[  0.          64.           0.           0.           0.\n","    0.           0.           0.        ]\n"," [ 51.19720775   0.          80.           0.           0.\n","   51.17708389   0.           0.        ]\n"," [  0.          64.           0.          64.           0.\n","    0.           0.         100.        ]\n"," [  0.           0.          80.           0.           0.\n","    0.           0.           0.        ]\n"," [  0.           0.           0.           0.           0.\n","   51.17708389   0.           0.        ]\n"," [  0.          64.           0.           0.          40.94166711\n","    0.          40.96         0.        ]\n"," [  0.           0.           0.           0.           0.\n","   51.2          0.           0.        ]\n"," [  0.           0.          80.           0.           0.\n","    0.           0.          99.99454638]]\n"]}]},{"cell_type":"code","metadata":{"id":"A5WGCzBIz0Ck","colab":{"base_uri":"https://localhost:8080/","height":306},"executionInfo":{"status":"ok","timestamp":1636388590504,"user_tz":-330,"elapsed":550,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}},"outputId":"8bb5958d-c087-40d3-9cc9-27cc6229e7e1"},"source":["# Testing\n","current_state = 0\n","steps = [current_state]\n","\n","while current_state != 7:\n","\n","    next_step_index = np.where(Q[current_state,]\n","        == np.max(Q[current_state,]))[1]\n","\n","    if next_step_index.shape[0] > 1:\n","        next_step_index = int(np.random.choice(next_step_index, size = 1))\n","    else:\n","        next_step_index = int(next_step_index)\n","\n","    steps.append(next_step_index)\n","    current_state = next_step_index\n","\n","print(\"Most efficient path:\")\n","print(steps)\n","\n","plt.plot(scores)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Most efficient path:\n","[0, 1, 2, 7]\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"6_guuzaKXGfr"},"source":["\n","\n","#***Shortest Path Using Deep Reinforcement Learning***\n"]},{"cell_type":"code","metadata":{"id":"z0Irdok90Jpd"},"source":["from __future__ import print_function\n","import os, sys, time, datetime, json, random\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Activation\n","from tensorflow.keras.optimizers import SGD , Adam, RMSprop\n","# from tensorflow.keras.optimizers import SGD\n","from keras.layers.advanced_activations import PReLU\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DU95wSQX1zbw"},"source":["maze = np.array([\n","    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  1.],\n","    [ 1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.],\n","    [ 1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],\n","    [ 1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.]\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WdhDZ7re2AYk"},"source":["visited_mark = 0.8  # Cells visited by the rat will be painted by gray 0.8\n","rat_mark = 0.5      # The current rat cell will be painteg by gray 0.5\n","LEFT = 0\n","UP = 1\n","RIGHT = 2\n","DOWN = 3\n","\n","# Actions dictionary\n","actions_dict = {\n","    LEFT: 'left',\n","    UP: 'up',\n","    RIGHT: 'right',\n","    DOWN: 'down',\n","}\n","\n","num_actions = len(actions_dict)\n","\n","# Exploration factor\n","epsilon = 0.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vN6-J1Nj47sw"},"source":["# maze is a 2d Numpy array of floats between 0.0 to 1.0\n","# 1.0 corresponds to a free cell, and 0.0 an occupied cell\n","# rat = (row, col) initial rat position (defaults to (0,0))\n","\n","class Qmaze(object):\n","    def __init__(self, maze, rat=(0,0)):\n","        self._maze = np.array(maze)\n","        nrows, ncols = self._maze.shape\n","        self.target = (nrows-1, ncols-1)   # target cell where the \"cheese\" is\n","        self.free_cells = [(r,c) for r in range(nrows) for c in range(ncols) if self._maze[r,c] == 1.0]\n","        self.free_cells.remove(self.target)\n","        if self._maze[self.target] == 0.0:\n","            raise Exception(\"Invalid maze: target cell cannot be blocked!\")\n","        if not rat in self.free_cells:\n","            raise Exception(\"Invalid Rat Location: must sit on a free cell\")\n","        self.reset(rat)\n","\n","    def reset(self, rat):\n","        self.rat = rat\n","        self.maze = np.copy(self._maze)\n","        nrows, ncols = self.maze.shape\n","        row, col = rat\n","        self.maze[row, col] = rat_mark\n","        self.state = (row, col, 'start')\n","        self.min_reward = -0.5 * self.maze.size\n","        self.total_reward = 0\n","        self.visited = set()\n","\n","    def update_state(self, action):\n","        nrows, ncols = self.maze.shape\n","        nrow, ncol, nmode = rat_row, rat_col, mode = self.state\n","\n","        if self.maze[rat_row, rat_col] > 0.0:\n","            self.visited.add((rat_row, rat_col))  # mark visited cell\n","\n","        valid_actions = self.valid_actions()\n","                \n","        if not valid_actions:\n","            nmode = 'blocked'\n","        elif action in valid_actions:\n","            nmode = 'valid'\n","            if action == LEFT:\n","                ncol -= 1\n","            elif action == UP:\n","                nrow -= 1\n","            if action == RIGHT:\n","                ncol += 1\n","            elif action == DOWN:\n","                nrow += 1\n","        else:                  # invalid action, no change in rat position\n","            mode = 'invalid'\n","\n","        # new state\n","        self.state = (nrow, ncol, nmode)\n","\n","    def get_reward(self):\n","        rat_row, rat_col, mode = self.state\n","        nrows, ncols = self.maze.shape\n","        if rat_row == nrows-1 and rat_col == ncols-1:\n","            return 1.0\n","        if mode == 'blocked':\n","            return self.min_reward - 1\n","        if (rat_row, rat_col) in self.visited:\n","            return -0.25\n","        if mode == 'invalid':\n","            return -0.75\n","        if mode == 'valid':\n","            return -0.04\n","\n","    def act(self, action):\n","        self.update_state(action)\n","        reward = self.get_reward()\n","        self.total_reward += reward\n","        status = self.game_status()\n","        envstate = self.observe()\n","        return envstate, reward, status\n","\n","    def observe(self):\n","        canvas = self.draw_env()\n","        envstate = canvas.reshape((1, -1))\n","        return envstate\n","\n","    def draw_env(self):\n","        canvas = np.copy(self.maze)\n","        nrows, ncols = self.maze.shape\n","        # clear all visual marks\n","        for r in range(nrows):\n","            for c in range(ncols):\n","                if canvas[r,c] > 0.0:\n","                    canvas[r,c] = 1.0\n","        # draw the rat\n","        row, col, valid = self.state\n","        canvas[row, col] = rat_mark\n","        return canvas\n","\n","    def game_status(self):\n","        if self.total_reward < self.min_reward:\n","            return 'lose'\n","        rat_row, rat_col, mode = self.state\n","        nrows, ncols = self.maze.shape\n","        if rat_row == nrows-1 and rat_col == ncols-1:\n","            return 'win'\n","\n","        return 'not_over'\n","\n","    def valid_actions(self, cell=None):\n","        if cell is None:\n","            row, col, mode = self.state\n","        else:\n","            row, col = cell\n","        actions = [0, 1, 2, 3]\n","        nrows, ncols = self.maze.shape\n","        if row == 0:\n","            actions.remove(1)\n","        elif row == nrows-1:\n","            actions.remove(3)\n","\n","        if col == 0:\n","            actions.remove(0)\n","        elif col == ncols-1:\n","            actions.remove(2)\n","\n","        if row>0 and self.maze[row-1,col] == 0.0:\n","            actions.remove(1)\n","        if row<nrows-1 and self.maze[row+1,col] == 0.0:\n","            actions.remove(3)\n","\n","        if col>0 and self.maze[row,col-1] == 0.0:\n","            actions.remove(0)\n","        if col<ncols-1 and self.maze[row,col+1] == 0.0:\n","            actions.remove(2)\n","\n","        return actions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o2JPntLyUUiE"},"source":["def show(qmaze):\n","    plt.grid('on')\n","    nrows, ncols = qmaze.maze.shape\n","    ax = plt.gca()\n","    ax.set_xticks(np.arange(0.5, nrows, 1))\n","    ax.set_yticks(np.arange(0.5, ncols, 1))\n","    ax.set_xticklabels([])\n","    ax.set_yticklabels([])\n","    canvas = np.copy(qmaze.maze)\n","    for row,col in qmaze.visited:\n","        canvas[row,col] = 0.6\n","    rat_row, rat_col, _ = qmaze.state\n","    canvas[rat_row, rat_col] = 0.3   # rat cell\n","    canvas[nrows-1, ncols-1] = 0.9 # cheese cell\n","    img = plt.imshow(canvas, interpolation='none', cmap='gray')\n","    return img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vnxJGfMeUWQH"},"source":["maze = [\n","    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.],\n","    [ 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.],\n","    [ 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.]\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"wL5cNliVUYVr","executionInfo":{"status":"ok","timestamp":1636462049109,"user_tz":-330,"elapsed":15,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}},"outputId":"52ab811a-5aaa-432d-87b1-a9626f5dc382"},"source":["qmaze = Qmaze(maze)\n","canvas, reward, game_over = qmaze.act(DOWN)\n","print(\"reward=\", reward)\n","show(qmaze)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["reward= -0.04\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fd01d782890>"]},"metadata":{},"execution_count":7},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":273},"id":"qV55o89eUaCG","executionInfo":{"status":"ok","timestamp":1636462049110,"user_tz":-330,"elapsed":12,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}},"outputId":"45bf99bc-312f-4bb4-c400-f95cdd57e075"},"source":["qmaze.act(DOWN)  # move down\n","qmaze.act(RIGHT)  # move right\n","qmaze.act(RIGHT)  # move right\n","qmaze.act(RIGHT)  # move right\n","qmaze.act(UP)  # move up\n","show(qmaze)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fd01d259c50>"]},"metadata":{},"execution_count":8},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"gpd-sVBsUcaZ"},"source":["def play_game(model, qmaze, rat_cell):\n","    qmaze.reset(rat_cell)\n","    envstate = qmaze.observe()\n","    while True:\n","        prev_envstate = envstate\n","        # get next action\n","        q = model.predict(prev_envstate)\n","        action = np.argmax(q[0])\n","\n","        # apply action, get rewards and new state\n","        envstate, reward, game_status = qmaze.act(action)\n","        if game_status == 'win':\n","            return True\n","        elif game_status == 'lose':\n","            return False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1l_UubvWUeKf"},"source":["def completion_check(model, qmaze):\n","    for cell in qmaze.free_cells:\n","        if not qmaze.valid_actions(cell):\n","            return False\n","        if not play_game(model, qmaze, cell):\n","            return False\n","    return True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dO8sFmVLUgCg"},"source":["class Experience(object):\n","    def __init__(self, model, max_memory=100, discount=0.95):\n","        self.model = model\n","        self.max_memory = max_memory\n","        self.discount = discount\n","        self.memory = list()\n","        self.num_actions = model.output_shape[-1]\n","\n","    def remember(self, episode):\n","        # episode = [envstate, action, reward, envstate_next, game_over]\n","        # memory[i] = episode\n","        # envstate == flattened 1d maze cells info, including rat cell (see method: observe)\n","        self.memory.append(episode)\n","        if len(self.memory) > self.max_memory:\n","            del self.memory[0]\n","\n","    def predict(self, envstate):\n","        return self.model.predict(envstate)[0]\n","\n","    def get_data(self, data_size=10):\n","        env_size = self.memory[0][0].shape[1]   # envstate 1d size (1st element of episode)\n","        mem_size = len(self.memory)\n","        data_size = min(mem_size, data_size)\n","        inputs = np.zeros((data_size, env_size))\n","        targets = np.zeros((data_size, self.num_actions))\n","        for i, j in enumerate(np.random.choice(range(mem_size), data_size, replace=False)):\n","            envstate, action, reward, envstate_next, game_over = self.memory[j]\n","            inputs[i] = envstate\n","            # There should be no target values for actions not taken.\n","            targets[i] = self.predict(envstate)\n","            # Q_sa = derived policy = max quality env/action = max_a' Q(s', a')\n","            Q_sa = np.max(self.predict(envstate_next))\n","            if game_over:\n","                targets[i, action] = reward\n","            else:\n","                # reward + gamma * max_a' Q(s', a')\n","                targets[i, action] = reward + self.discount * Q_sa\n","        return inputs, targets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ncvxxtw3UjIZ"},"source":["def qtrain(model, maze, **opt):\n","    global epsilon\n","    n_epoch = opt.get('n_epoch', 15000)\n","    max_memory = opt.get('max_memory', 1000)\n","    data_size = opt.get('data_size', 50)\n","    weights_file = opt.get('weights_file', \"\")\n","    name = opt.get('name', 'model')\n","    start_time = datetime.datetime.now()\n","\n","    # If you want to continue training from a previous model,\n","    # just supply the h5 file name to weights_file option\n","    if weights_file:\n","        print(\"loading weights from file: %s\" % (weights_file,))\n","        model.load_weights(weights_file)\n","\n","    # Construct environment/game from numpy array: maze (see above)\n","    qmaze = Qmaze(maze)\n","\n","    # Initialize experience replay object\n","    experience = Experience(model, max_memory=max_memory)\n","\n","    win_history = []   # history of win/lose game\n","    n_free_cells = len(qmaze.free_cells)\n","    hsize = qmaze.maze.size//2   # history window size\n","    win_rate = 0.0\n","    imctr = 1\n","\n","    for epoch in range(n_epoch):\n","        loss = 0.0\n","        rat_cell = random.choice(qmaze.free_cells)\n","        qmaze.reset(rat_cell)\n","        game_over = False\n","\n","        # get initial envstate (1d flattened canvas)\n","        envstate = qmaze.observe()\n","\n","        n_episodes = 0\n","        while not game_over:\n","            valid_actions = qmaze.valid_actions()\n","            if not valid_actions: break\n","            prev_envstate = envstate\n","            # Get next action\n","            if np.random.rand() < epsilon:\n","                action = random.choice(valid_actions)\n","            else:\n","                action = np.argmax(experience.predict(prev_envstate))\n","\n","            # Apply action, get reward and new envstate\n","            envstate, reward, game_status = qmaze.act(action)\n","            if game_status == 'win':\n","                win_history.append(1)\n","                game_over = True\n","            elif game_status == 'lose':\n","                win_history.append(0)\n","                game_over = True\n","            else:\n","                game_over = False\n","\n","            # Store episode (experience)\n","            episode = [prev_envstate, action, reward, envstate, game_over]\n","            experience.remember(episode)\n","            n_episodes += 1\n","\n","            # Train neural network model\n","            inputs, targets = experience.get_data(data_size=data_size)\n","            h = model.fit(\n","                inputs,\n","                targets,\n","                epochs=8,\n","                batch_size=16,\n","                verbose=0,\n","            )\n","            loss = model.evaluate(inputs, targets, verbose=0)\n","\n","        if len(win_history) > hsize:\n","            win_rate = sum(win_history[-hsize:]) / hsize\n","    \n","        dt = datetime.datetime.now() - start_time\n","        t = format_time(dt.total_seconds())\n","        template = \"Epoch: {:03d}/{:d} | Loss: {:.4f} | Episodes: {:d} | Win count: {:d} | Win rate: {:.3f} | time: {}\"\n","        print(template.format(epoch, n_epoch-1, loss, n_episodes, sum(win_history), win_rate, t))\n","        # we simply check if training has exhausted all free cells and if in all\n","        # cases the agent won\n","        if win_rate > 0.9 : epsilon = 0.05\n","        if sum(win_history[-hsize:]) == hsize and completion_check(model, qmaze):\n","            print(\"Reached 100%% win rate at epoch: %d\" % (epoch,))\n","            break\n","\n","    # Save trained model weights and architecture, this will be used by the visualization code\n","    h5file = name + \".h5\"\n","    json_file = name + \".json\"\n","    model.save_weights(h5file, overwrite=True)\n","    with open(json_file, \"w\") as outfile:\n","        json.dump(model.to_json(), outfile)\n","    end_time = datetime.datetime.now()\n","    dt = datetime.datetime.now() - start_time\n","    seconds = dt.total_seconds()\n","    t = format_time(seconds)\n","    print('files: %s, %s' % (h5file, json_file))\n","    print(\"n_epoch: %d, max_mem: %d, data: %d, time: %s\" % (epoch, max_memory, data_size, t))\n","    return seconds\n","\n","# This is a small utility for printing readable time strings:\n","def format_time(seconds):\n","    if seconds < 400:\n","        s = float(seconds)\n","        return \"%.1f seconds\" % (s,)\n","    elif seconds < 4000:\n","        m = seconds / 60.0\n","        return \"%.2f minutes\" % (m,)\n","    else:\n","        h = seconds / 3600.0\n","        return \"%.2f hours\" % (h,)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"powNWat5UnRd"},"source":["def build_model(maze, lr=0.001):\n","    model = Sequential()\n","    model.add(Dense(maze.size, input_shape=(maze.size,)))\n","    model.add(PReLU())\n","    model.add(Dense(maze.size))\n","    model.add(PReLU())\n","    model.add(Dense(num_actions))\n","    model.compile(optimizer='adam', loss='mse')\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":273},"id":"q2AqyhMzUpP9","executionInfo":{"status":"ok","timestamp":1636462049481,"user_tz":-330,"elapsed":6,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}},"outputId":"0b0d645c-fdce-47bc-ffb3-5bcd2b7a651e"},"source":["maze =  np.array([\n","    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  0.,  0.,  1.,  0.],\n","    [ 0.,  0.,  0.,  1.,  1.,  1.,  0.],\n","    [ 1.,  1.,  1.,  1.,  0.,  0.,  1.],\n","    [ 1.,  0.,  0.,  0.,  1.,  1.,  1.],\n","    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  0.,  1.,  1.,  1.]\n","])\n","\n","qmaze = Qmaze(maze)\n","show(qmaze)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fd01d1dda10>"]},"metadata":{},"execution_count":14},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yoYfVz0eUsK5","outputId":"5c546892-fbde-429a-efd4-b0b757fd4f6d"},"source":["model = build_model(maze)\n","qtrain(model, maze, epochs=100, max_memory=8*maze.size, data_size=32)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 000/14999 | Loss: 0.0023 | Episodes: 106 | Win count: 0 | Win rate: 0.000 | time: 302.9 seconds\n","Epoch: 001/14999 | Loss: 0.0565 | Episodes: 111 | Win count: 0 | Win rate: 0.000 | time: 11.24 minutes\n","Epoch: 002/14999 | Loss: 0.0019 | Episodes: 104 | Win count: 0 | Win rate: 0.000 | time: 17.00 minutes\n","Epoch: 003/14999 | Loss: 0.0034 | Episodes: 29 | Win count: 1 | Win rate: 0.000 | time: 18.56 minutes\n","Epoch: 004/14999 | Loss: 0.0485 | Episodes: 104 | Win count: 1 | Win rate: 0.000 | time: 24.11 minutes\n","Epoch: 005/14999 | Loss: 0.0041 | Episodes: 106 | Win count: 1 | Win rate: 0.000 | time: 29.78 minutes\n","Epoch: 006/14999 | Loss: 0.0135 | Episodes: 106 | Win count: 1 | Win rate: 0.000 | time: 35.53 minutes\n","Epoch: 007/14999 | Loss: 0.0029 | Episodes: 107 | Win count: 1 | Win rate: 0.000 | time: 41.35 minutes\n","Epoch: 008/14999 | Loss: 0.0016 | Episodes: 104 | Win count: 1 | Win rate: 0.000 | time: 46.99 minutes\n","Epoch: 009/14999 | Loss: 0.0013 | Episodes: 104 | Win count: 1 | Win rate: 0.000 | time: 52.66 minutes\n","Epoch: 010/14999 | Loss: 0.0028 | Episodes: 101 | Win count: 1 | Win rate: 0.000 | time: 58.26 minutes\n","Epoch: 011/14999 | Loss: 0.0010 | Episodes: 104 | Win count: 1 | Win rate: 0.000 | time: 63.95 minutes\n","Epoch: 012/14999 | Loss: 0.0026 | Episodes: 103 | Win count: 1 | Win rate: 0.000 | time: 1.16 hours\n","Epoch: 013/14999 | Loss: 0.0022 | Episodes: 102 | Win count: 1 | Win rate: 0.000 | time: 1.25 hours\n","Epoch: 014/14999 | Loss: 0.0014 | Episodes: 65 | Win count: 2 | Win rate: 0.000 | time: 1.31 hours\n","Epoch: 015/14999 | Loss: 0.0021 | Episodes: 106 | Win count: 2 | Win rate: 0.000 | time: 1.41 hours\n","Epoch: 016/14999 | Loss: 0.0015 | Episodes: 111 | Win count: 2 | Win rate: 0.000 | time: 1.51 hours\n","Epoch: 017/14999 | Loss: 0.0023 | Episodes: 109 | Win count: 2 | Win rate: 0.000 | time: 1.60 hours\n","Epoch: 018/14999 | Loss: 0.0015 | Episodes: 55 | Win count: 3 | Win rate: 0.000 | time: 1.65 hours\n","Epoch: 019/14999 | Loss: 0.0102 | Episodes: 104 | Win count: 3 | Win rate: 0.000 | time: 1.75 hours\n","Epoch: 020/14999 | Loss: 0.0221 | Episodes: 102 | Win count: 3 | Win rate: 0.000 | time: 1.84 hours\n","Epoch: 021/14999 | Loss: 0.0357 | Episodes: 108 | Win count: 3 | Win rate: 0.000 | time: 1.93 hours\n","Epoch: 022/14999 | Loss: 0.0013 | Episodes: 105 | Win count: 3 | Win rate: 0.000 | time: 2.02 hours\n","Epoch: 023/14999 | Loss: 0.0014 | Episodes: 106 | Win count: 3 | Win rate: 0.000 | time: 2.12 hours\n","Epoch: 024/14999 | Loss: 0.0032 | Episodes: 23 | Win count: 4 | Win rate: 0.167 | time: 2.14 hours\n","Epoch: 025/14999 | Loss: 0.0055 | Episodes: 104 | Win count: 4 | Win rate: 0.167 | time: 2.23 hours\n","Epoch: 026/14999 | Loss: 0.0012 | Episodes: 103 | Win count: 4 | Win rate: 0.167 | time: 2.33 hours\n","Epoch: 027/14999 | Loss: 0.0012 | Episodes: 3 | Win count: 5 | Win rate: 0.167 | time: 2.33 hours\n","Epoch: 028/14999 | Loss: 0.1357 | Episodes: 107 | Win count: 5 | Win rate: 0.167 | time: 2.42 hours\n","Epoch: 029/14999 | Loss: 0.0017 | Episodes: 10 | Win count: 6 | Win rate: 0.208 | time: 2.43 hours\n","Epoch: 030/14999 | Loss: 0.0429 | Episodes: 103 | Win count: 7 | Win rate: 0.250 | time: 2.52 hours\n","Epoch: 031/14999 | Loss: 0.0033 | Episodes: 4 | Win count: 8 | Win rate: 0.292 | time: 2.52 hours\n","Epoch: 032/14999 | Loss: 0.0034 | Episodes: 104 | Win count: 8 | Win rate: 0.292 | time: 2.62 hours\n","Epoch: 033/14999 | Loss: 0.0022 | Episodes: 103 | Win count: 8 | Win rate: 0.292 | time: 2.71 hours\n","Epoch: 034/14999 | Loss: 0.0020 | Episodes: 107 | Win count: 8 | Win rate: 0.292 | time: 2.80 hours\n","Epoch: 035/14999 | Loss: 0.0016 | Episodes: 104 | Win count: 8 | Win rate: 0.292 | time: 2.89 hours\n","Epoch: 036/14999 | Loss: 0.0005 | Episodes: 68 | Win count: 9 | Win rate: 0.333 | time: 2.95 hours\n","Epoch: 037/14999 | Loss: 0.0018 | Episodes: 103 | Win count: 9 | Win rate: 0.333 | time: 3.04 hours\n","Epoch: 038/14999 | Loss: 0.0010 | Episodes: 2 | Win count: 10 | Win rate: 0.333 | time: 3.04 hours\n","Epoch: 039/14999 | Loss: 0.0016 | Episodes: 104 | Win count: 10 | Win rate: 0.333 | time: 3.14 hours\n","Epoch: 040/14999 | Loss: 0.0017 | Episodes: 3 | Win count: 11 | Win rate: 0.375 | time: 3.14 hours\n","Epoch: 041/14999 | Loss: 0.0023 | Episodes: 62 | Win count: 12 | Win rate: 0.417 | time: 3.20 hours\n","Epoch: 042/14999 | Loss: 0.0149 | Episodes: 104 | Win count: 12 | Win rate: 0.375 | time: 3.29 hours\n","Epoch: 043/14999 | Loss: 0.0029 | Episodes: 3 | Win count: 13 | Win rate: 0.417 | time: 3.30 hours\n","Epoch: 044/14999 | Loss: 0.0050 | Episodes: 14 | Win count: 14 | Win rate: 0.458 | time: 3.31 hours\n","Epoch: 045/14999 | Loss: 0.0072 | Episodes: 61 | Win count: 15 | Win rate: 0.500 | time: 3.37 hours\n","Epoch: 046/14999 | Loss: 0.0024 | Episodes: 15 | Win count: 16 | Win rate: 0.542 | time: 3.38 hours\n","Epoch: 047/14999 | Loss: 0.0109 | Episodes: 18 | Win count: 17 | Win rate: 0.583 | time: 3.39 hours\n","Epoch: 048/14999 | Loss: 0.0019 | Episodes: 104 | Win count: 17 | Win rate: 0.542 | time: 3.49 hours\n","Epoch: 049/14999 | Loss: 0.0039 | Episodes: 53 | Win count: 18 | Win rate: 0.583 | time: 3.54 hours\n","Epoch: 050/14999 | Loss: 0.0025 | Episodes: 15 | Win count: 19 | Win rate: 0.625 | time: 3.55 hours\n","Epoch: 051/14999 | Loss: 0.0395 | Episodes: 10 | Win count: 20 | Win rate: 0.625 | time: 3.56 hours\n","Epoch: 052/14999 | Loss: 0.0013 | Episodes: 25 | Win count: 21 | Win rate: 0.667 | time: 3.58 hours\n","Epoch: 053/14999 | Loss: 0.0015 | Episodes: 23 | Win count: 22 | Win rate: 0.667 | time: 3.60 hours\n","Epoch: 054/14999 | Loss: 0.0046 | Episodes: 117 | Win count: 23 | Win rate: 0.667 | time: 3.70 hours\n","Epoch: 055/14999 | Loss: 0.0018 | Episodes: 37 | Win count: 24 | Win rate: 0.667 | time: 3.73 hours\n","Epoch: 056/14999 | Loss: 0.0008 | Episodes: 11 | Win count: 25 | Win rate: 0.708 | time: 3.74 hours\n","Epoch: 057/14999 | Loss: 0.0005 | Episodes: 29 | Win count: 26 | Win rate: 0.750 | time: 3.77 hours\n","Epoch: 058/14999 | Loss: 0.0013 | Episodes: 33 | Win count: 27 | Win rate: 0.792 | time: 3.80 hours\n","Epoch: 059/14999 | Loss: 0.0011 | Episodes: 18 | Win count: 28 | Win rate: 0.833 | time: 3.82 hours\n"]}]},{"cell_type":"code","metadata":{"id":"sAh_ooFtUuhU","executionInfo":{"status":"ok","timestamp":1636980636480,"user_tz":-330,"elapsed":653,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}}},"source":[""],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9QaURe3mc4CB"},"source":["# ***Reinforcement Learning***"]},{"cell_type":"markdown","metadata":{"id":"n2bi4E5YfkzP"},"source":["## ***MountainCar-v0***"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Opfi_k7dfW7j","executionInfo":{"status":"ok","timestamp":1636716305400,"user_tz":-330,"elapsed":13525,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}},"outputId":"7c9d3393-035f-449a-d4db-9418d83ceb49"},"source":["!pip install --no-cache gym[all]\n","!pip install IPython\n","!pip install Box2D"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gym[all] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.19.5)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.3.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.4.1)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.5.0)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from gym[all]) (2.4.1)\n","Collecting box2d-py~=2.3.5\n","  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n","\u001b[K     || 448 kB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (0.2.9)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[all]) (7.1.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gym[all]) (4.1.2.30)\n","Collecting mujoco-py<2.0,>=1.50\n","  Downloading mujoco-py-1.50.1.68.tar.gz (120 kB)\n","\u001b[K     || 120 kB 56.4 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[all]) (1.15.0)\n","Collecting glfw>=1.4.0\n","  Downloading glfw-2.4.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (205 kB)\n","\u001b[K     || 205 kB 51.7 MB/s \n","\u001b[?25hRequirement already satisfied: Cython>=0.27.2 in /usr/local/lib/python3.7/dist-packages (from mujoco-py<2.0,>=1.50->gym[all]) (0.29.24)\n","Requirement already satisfied: cffi>=1.10 in /usr/local/lib/python3.7/dist-packages (from mujoco-py<2.0,>=1.50->gym[all]) (1.15.0)\n","Collecting lockfile>=0.12.2\n","  Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.10->mujoco-py<2.0,>=1.50->gym[all]) (2.21)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[all]) (0.16.0)\n","Building wheels for collected packages: mujoco-py\n","  Building wheel for mujoco-py (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for mujoco-py\u001b[0m\n","\u001b[?25h  Running setup.py clean for mujoco-py\n","Failed to build mujoco-py\n","Installing collected packages: lockfile, glfw, mujoco-py, box2d-py\n","    Running setup.py install for mujoco-py ... \u001b[?25l\u001b[?25herror\n","\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-6bjijqw4/mujoco-py_d2d12c1e88634b089be0a4202063747d/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-6bjijqw4/mujoco-py_d2d12c1e88634b089be0a4202063747d/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-gbido7mk/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/mujoco-py Check the logs for full command output.\u001b[0m\n","Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (5.5.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython) (4.4.2)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython) (0.8.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython) (5.1.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython) (0.7.5)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython) (57.4.0)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython) (4.8.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython) (1.0.18)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython) (2.6.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython) (0.7.0)\n","Collecting Box2D\n","  Downloading Box2D-2.3.10-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n","\u001b[K     || 1.3 MB 5.3 MB/s \n","\u001b[?25hInstalling collected packages: Box2D\n","Successfully installed Box2D-2.3.10\n"]}]},{"cell_type":"code","metadata":{"id":"6vdvl0w4f4QG"},"source":["class State:\n","  def __init__(self, position_tile, velocity_tile):\n","    self.position_tile = position_tile\n","    self.velocity_tile = velocity_tile\n","\n","  def __eq__(self, other):\n","    if isinstance(other, State):\n","      return (self.position_tile == other.position_tile and\n","              self.velocity_tile == other.velocity_tile)\n","    else:\n","      return False\n","\n","  def __hash__(self):\n","    return hash((self.position_tile, self.velocity_tile))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X-DIriV3gFTH"},"source":["import numpy as np\n","\n","ACTIONS_COUNT = 3\n","eps_greedy = 0\n","\n","\n","def find_best_action_quality(Q, state):\n","  best_action, best_q = None, None\n","  for action in range(ACTIONS_COUNT):\n","    cur_q = Q[(state, action)]\n","    if best_q is None or best_q < cur_q:\n","      best_action, best_q = action, cur_q\n","  return best_action, best_q\n","\n","\n","def choose_eps_greedy_action(Q, state):\n","  best_action, best_q = find_best_action_quality(Q, state)\n","  best_count = 0\n","  for action in range(ACTIONS_COUNT):\n","    if Q[(state, action)] == best_q:\n","        best_count += 1\n","  p = []\n","  for action in range(ACTIONS_COUNT):\n","    prob = eps_greedy / ACTIONS_COUNT\n","    if Q[(state, action)] == best_q:\n","      prob += (1 - eps_greedy) / best_count\n","    p.append(prob)\n","  return np.random.choice(ACTIONS_COUNT, 1, p=p)[0]\n","\n","\n","def map_observation_to_state(observation, position_grid, velocity_grid):\n","  return State(int(round(observation[0] / position_grid)),\n","                int(round(observation[1] / velocity_grid)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvMjBIwOgG1d"},"source":["import gym\n","from collections import defaultdict\n","\n","training_episodes = 5000\n","timesteps_limit = 200  # limit from OpenAI gym\n","\n","gamma = 0.9\n","\n","\n","def evaluate_parameters(alpha, position_grid, velocity_grid):\n","  env = gym.make('MountainCar-v0')\n","  env.seed(0)\n","  np.random.seed(0)\n","  cumulative_completion = []\n","  completed = 0\n","  Q = defaultdict(lambda: 0.0)\n","  for episode in range(training_episodes):\n","    observation = env.reset()\n","    state = map_observation_to_state(\n","      observation, position_grid, velocity_grid)\n","    action = choose_eps_greedy_action(Q, state)\n","    for timestep in range(timesteps_limit):\n","      observation, reward, done, info = env.step(action)\n","      to_state = map_observation_to_state(\n","        observation, position_grid, velocity_grid)\n","      next_action = choose_eps_greedy_action(Q, to_state)\n","      Q[(state, action)] += alpha * (reward +\n","                                      gamma * Q[(to_state, action)] -\n","                                      Q[(state, action)])\n","      action, state = next_action, to_state\n","      if done:\n","        if timestep != timesteps_limit - 1:\n","          completed += 1\n","        cumulative_completion.append(completed)\n","        break\n","  env.close()\n","  return cumulative_completion"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8sMTRo1UgIYk"},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","\n","def evaluate_and_plot_parameters(alpha, position_grid, velocity_grid, color):\n","  cumulative_completion = evaluate_parameters(alpha, position_grid, velocity_grid)\n","  title = f'alpha={alpha} pos_grid={position_grid} vel_grid={velocity_grid}'\n","  print(f'Evaluated {title}')\n","  line, = plt.plot(\n","      np.arange(1, training_episodes + 1),\n","      cumulative_completion,\n","      c=next(color),\n","      label=title)\n","  return line"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"id":"jzfSsvw4gJmk","executionInfo":{"status":"ok","timestamp":1636716450122,"user_tz":-330,"elapsed":144319,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}},"outputId":"98d65df6-aeed-4e85-b655-db741e25a3bc"},"source":["from matplotlib.pyplot import cm\n","\n","\n","color = iter(cm.rainbow(np.linspace(0, 1, 5)))\n","handles = []\n","\n","alpha, position_grid, velocity_grid = 0.25, 0.05, 0.01\n","handles.append(evaluate_and_plot_parameters(\n","  alpha, position_grid, velocity_grid, color\n","))\n","\n","plt.xlabel('episodes experienced')\n","plt.ylabel('overall episodes completed')\n","plt.legend(handles=handles)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluated alpha=0.25 pos_grid=0.05 vel_grid=0.01\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f269f4c4b10>"]},"metadata":{},"execution_count":9},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"MMk82luBgPLW"},"source":["## ***Roulette***"]},{"cell_type":"code","metadata":{"id":"DzcSQ9oQgR7w"},"source":["import numpy as np \n","\n","class model(object):\n","\tdef __init__(self, *args):\n","\t\tif not args is None:\n","\t\t\tself.env = args[0]\n","\t\t\tself.Q = args[1]\n","\t\t\tself.alpha = args[2]\n","\t\t\tself.gamma = args[3]\n","\t\t\tself.epsilon = args[4]\n","\t\t\tself.n_episodes = args[5]\n","\t\t\tself.verbose = args[6]\n","\t\t\tself.record_training = args[7]\n","\t\t\tself.checkpoint = self.n_episodes * 0.1\n","\t\telse:\n","\t\t\tprint('Invalid arguments.')\n","\n","\tdef eps_greedy(self, obs):\n","\t\tif np.random.uniform() < self.epsilon:\n","\t\t\treturn np.random.randint(self.env.action_space.n)\n","\t\telse:\n","\t\t\taction_values = [self.Q[obs, a] for a in \n","\t\t\t\t\t\t\t range(self.env.action_space.n)]\n","\t\t\tgreedy_idx = np.argwhere(action_values == np.max(action_values))\n","\t\t\tgreedy_act_idx = np.random.choice(greedy_idx.flatten())\n","\t\t\treturn greedy_act_idx\n","\n","\tdef greedy_action(self, obs):\n","\t\taction_values = [self.Q[obs, a] for a in \n","\t\t\t\t\t\t range(self.env.action_space.n)]\n","\t\tgreedy_idx = np.argmax(action_values)\n","\t\treturn greedy_idx\n","\n","\tdef train(self, idx=None, q=None):\n","\t\tif self.record_training:\n","\t\t\tself.all_rewards = []\n","\n","\t\tfor episode in range(self.n_episodes):\n","\t\t\tdone = False\n","\t\t\tobs = self.env.reset()\n","\t\t\tif self.record_training:\n","\t\t\t\tepisode_reward = 0\n","\t\t\ta = self.eps_greedy(obs)\n","\n","\t\t\twhile not done:\n","\t\t\t\tobs_prime, reward, done, info = self.env.step(a)\n","\t\t\t\ta_prime = self.eps_greedy(obs_prime)\n","\t\t\t\tself.Q[obs,a] += self.alpha * (reward + self.gamma*self.Q[obs_prime, a] -\n","\t\t\t\t\t\t\t\t\t\t\t\t   self.Q[obs, a])\n","\t\t\t\tif self.record_training:\n","\t\t\t\t\tepisode_reward += reward\n","\t\t\t\tobs = obs_prime\n","\t\t\t\ta = a_prime\n","\t\t\t\t\n","\t\t\t\t\n","\t\t\tif self.record_training:\n","\t\t\t\tself.all_rewards.append(episode_reward)\n","\t\t\tif self.verbose and episode % self.checkpoint == 0:\n","\t\t\t\tif not idx is None:\n","\t\t\t\t\tprint(f'Agent: {idx} Episode: {episode}')\n","\t\t\t\telse:\n","\t\t\t\t\tprint(f'Episode: {episode}')\n","\t\tif not q is None:\n","\t\t\tq.put(self)\n","\t\tif not idx is None:\n","\t\t\tprint(f'Agent: {idx} - Training complete.')\n","\t\telse:\n","\t\t\tprint('Training complete.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uqDTzUNpgTzP","executionInfo":{"status":"ok","timestamp":1636716453557,"user_tz":-330,"elapsed":2859,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}},"outputId":"c27b4844-6a68-4861-8010-d9ed15beeedc"},"source":["import gym\n","import pickle\n","import numpy as np \n","from itertools import product\n","\n","# Initialize environment, hyperparameters and action value function.\n","gamma = 1\n","alpha = 0.1\n","epsilon = 0.1\n","n_epsiodes = 10000\n","env = gym.make('Roulette-v0')\n","Q = dict.fromkeys(product([0], range(38)), 0.0)\n","\n","# Create and train agent.\n","agent = model(env, Q, alpha, gamma, epsilon, n_epsiodes, True, False)\n","agent.train()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Episode: 0\n","Episode: 1000\n","Episode: 2000\n","Episode: 3000\n","Episode: 4000\n","Episode: 5000\n","Episode: 6000\n","Episode: 7000\n","Episode: 8000\n","Episode: 9000\n","Training complete.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":294},"id":"RaKte-7mgVVE","executionInfo":{"status":"ok","timestamp":1636716454441,"user_tz":-330,"elapsed":886,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}},"outputId":"357147c7-ea5f-41cc-d404-4e296c50d3cb"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","action_values = np.array([i for i in agent.Q.values()])\n","plt.bar(range(len(action_values)), action_values)\n","plt.xticks(range(len(action_values)))\n","plt.tick_params(axis='x', which='major', labelsize=9)\n","plt.xlabel('Agent bet: ')\n","plt.ylabel('Action value: ')\n","plt.title('Learned action value function for Roulette-v0:')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgcVb3G8e9LAoQlCYQ9ARIQEFlCkAhyZROisnlBiCwiyiZwvbg84sIqIIvgzgURgyiKEEARREA2ARFBICA7iizBsGlYkwASSH73j3OaqVS6Z3oy09MzqffzPPNMd5+qU6eqT9WvzjlV1YoIzMysehZpdwHMzKw9HADMzCrKAcDMrKIcAMzMKsoBwMysohwAzMwqygFgISXpPEkn9cFyzpZ0bKuX0x2Spkqa0IJ8l5D0O0mvSvpVb+ffxbIfkrRNC/JdSdItkmZK+m5v59+bJN0s6aB2l2Nh4gDQhFYdUAYaSftJurX4WUQcGhEntqtMfWwisBKwXER8vFULqRe8I2L9iLi5BYs7GHgBGBYRh/c0s1xH5kiaJWmGpPsk7dzzYna7HCFprcL7bSQ93cLljZF0k6TXJf1toBwvHAD6CUmD2l0G69Jo4NGIeLvdBelFo4GHYwHuCJU0uEHS7RGxNLAMcBZwkaRlelDGgWAy8FdgOeBo4NeSVmhvkZoQEf7r4g+YCkyo8/kiwBHA48CLwCXAiEL6r4DngVeBW4D1C2nnAT8CrgZeAybk5XwZuD/PczEwpDDPzsC9wCvAbcDYQtrGwD3AzDzfRcBJDdbnXcCNucwvABcAyxTSVwN+A0zP05wJvAf4DzAHmAW8UliPkwrzfgZ4DHgJuAIYWUgL4FDgH3kdfgioTvlGAm+UtuXGuayLNlH+d76vOuXbBni6tKxL87o+CXy+wTY7AZgNvJXX/0DgeOCXhWnG5HUcnN/fDJwI/Dl/L9cByxem3yJ/j68A04D9SGfkb+VlzQJ+V2edFgd+ADyb/34ALF5cP+Bw4N/Ac8D+DdbpvNKyJjSZ99dI9fr8OnnuB9xaeL9k3ibvy++HA7/I2/sp4BhgkZzWzPY8qJB+APAI8DJwLTA6f35Lnu+1vF6fJtWnufn9rPy9d7r/ltbr98Bhpc/uA3YD1gHeBIYW0v4EHNruY1dXf24B9MzngF2BrUkV6mXSQa3m98DawIqkg/MFpfk/AZwMDAVqXSt7ANsDawBjSTsUkjYGfgocQjrL+DFwhaTFJS0GXA6cD4wgBZ7dOym3gG/mMr+HdMA/Pi9nEHAlaeccA4wCLoqIR0gH79sjYumImO+MTtK2Od89gFVyHheVJtsZeF9etz2Aj5TziYhngdtL6/AJ4NcR8VZn5e8OSYsAvyPtyKOA7YAvSqpXpuOAU4CL8/qf2+RiPgHsT6oDi5ECPJJGk+rHGcAKwDjg3oiYRKon38rL+WidPI8G3p/n2QjYlHQgrVmZdKAdRQpUP5S0bJ112q+0rBuazHsEqeVwcGcrnuvS/qQg81T++IxctjVJ+82n8jTdImkX4CjSAXgF0gF3cl6vrfJkG+X1+jmwA/Bsfr90rmNd7b9Fk4G9C8tfj7QNrgLWB56IiJmF6e/LnyNpC0mvdHcd+0S7I9BA+KNxC+ARYLvC+1VIlX1wnWmXIZ2VDM/vzwN+UWc5nyy8/xZwdn79I+DE0vR/J1XerUhnayqk3UaDFkCdsu0K/DW/3px0dlZvHfajcHZXWI+T8utzSQeTWtrSeXuMye8D2KKQfglwRIMyHQTcmF+LdIa8VVflL39fdNICADYD/lnK60jgZw2WczzznqGW349h/jPWYwrpnwWuKSznsgbLmafMddbpcWDHQtpHgKmF9Xuj+P2RWgLvb2ZZTeQ9m0KrtEEdeZvUqnkrl2WPnDYoz79eYfpDgJu7sT0Pyq9/DxxYmHYR4HU6WgEBrFXve1/A/XcoqUVRy/9k4Kf59b7AX0rTnwyc18z+184/twB6ZjRwmaRXcoR/hNRFspKkQZJOlfS4pBmkHRhg+cL80+rk+Xzh9eukg2htWYfXlpWXtxrpzGUk8Ezkmpc9RQP5yo+LJD2Ty/bLQrlWA56KBevnHllcbkTMIjWtRzWxfmWXAptLWoUU4OaSzvK6Kn93jAZGlrbpUaSB3t7SaH1XIx1sF8Q82zm/Hll4/2Lp++tsO3c37+kR8Z8u8vhLpBbisqRuwC3z58uTuvDK+Y+i+0YDpxe+t5dIJwrdyauz/ffsPJA9S9JRkc7urwL2yvPuTUeLfhYwrJT3MFK3X7/mANAz04AdImKZwt+QiHiG1PTfhdSvOpx0NgOpktZ0Z+BtGnByaVlLRsRkUj/vKEnFvFfvJK9T8rI3jIhhwCcL5ZoGrN5ggK+r8j5L2qkAkLQUqbvqmS7mm39BES+T+sz3JG3LiwoBrrPyl71G6oeuWbnwehrwZGmbDo2IHZssZmd5d2UaaSyjnm5tZ9J3/Ww3lt2TvJuus/kE4H+AfXMX5gukM+xy/rX60Z3tOQ04pPTdLRERtzUqToM86u6/ka5uq3UXnZKnnwzsLWlzYAhwU/78IWBNSUMLeW+UP+/XHACat6ikIYW/wcDZwMm5PxdJK+S+SUhNxjdJZ8BLkg5aPXEOcKikzZQsJWmnXOluJzW7Py9pUUm7kfpuGxlKOmt5VdIo4CuFtDtJAeXUvIwhkj6Q0/4FrJrHHOqZDOwvaZykxUnrfEdETF3Adb6Q1Ec8Mb9upvxl9wI7ShohaWXgi4W0O4GZkr6Wr/EfJGkDSe9rsnz3AltJWl3ScFK3TrMuACZI2kPSYEnLSRqX0/5F6iNvZDJwTK5vywNfJ7WCekOv5h0RLwE/Ab4eEXNI3X4nSxqa95svFfLvzvY8GzhSUq2ffbik4qW55W34L2C5nG8xj0b7bz1Xk4LXN0hjQXPzOj6ay35c3l8+RhrjurSTvPoFB4DmXU3qz6z9HQ+cTmriXidpJvAXUr8ypCsdniKd3Tyc0xZYREwhXWFzJmmw6jHyAHFEzCYNhu1HagrvSbqKp5ETgPeSrjS6qjht3kk/CqwF/JN01ceeOflG0lnN85JeqFPGG4BjSRX/OdIZ7l7l6brhCtIg+vMRcV8z5a/jfNKA3FRSi+LiQnnnkAalx5GuAHqBdLAaPl8udUTE9Tm/+4G7SYPnTYmIfwI7kq7WeYl0ANkoJ58LrJe7Ji6vM/tJwJS83AdIFxj01k1/rcj7B6QgPJY08Poa8ATpwocLSRc3dGt7RsRlwGmkS0xnAA+SBnprjgd+nrfhHhHxN1JweyJ/NpLO9996y3yTVNcmMO8JCaR6Pp60b54KTIyI6QCStpQ0q9Mt1Caat9vYzMyqwi0AM7OKamsAkLS9pL9LekzSEe0si5lZ1bStCyjfJPIo8CFSP/NdwN4R8XBbCmRmVjHtbAFsCjwWEU/kQcyLSJdNmplZH2j0MKe+MIp5b4R6mjoj8JIOJt9yvtRSS22y7rrrLtDCHnjm1YZpG44aPuDTofE6Or216bVpFvZ06L/fwcKS3ip33333CxEx38Pp2tkFNBHYPiIOyu/3BTaLiMMazTN+/PiYMmXKAi1vzBFXNUybeupOAz4dGq+j01ubXptmYU+H/vsdLCzprSLp7ogYX/68nV1Az5Buh69ZlQW4Y9TMzBZMOwPAXcDaktbId5buRbopw8zM+kDbxgAi4m1Jh5Ge4z2I9GS9fv/sDDOzhUU7B4GJiKtJj1jo93raR9fqPr6BUgbrv1w/qsd3ApuZVZQDgJlZRTkAmJlVlAOAmVlFtXUQ2Dp4AK7/83dkXdWBgVZH3AIwM6soBwAzs4pyADAzqyiPAfSSgdb3V8/CsA7Wv/W0D911tHe5BWBmVlEOAGZmFeUAYGZWUQ4AZmYV5UFgs17S7ifGeoDUusstADOzinIAMDOrKAcAM7OK8hiADRgDvY97oJcfFo51sA5uAZiZVZQDgJlZRTkAmJlVlAOAmVlFeRB4gOgPg2+tLkN/WMeFmbevlbkFYGZWUQ4AZmYV5QBgZlZRDgBmZhXlQWBbaPhpmtbf9bc65haAmVlFOQCYmVWUA4CZWUV5DCDrb31zZtZ93o+7xy0AM7OKcgAwM6soBwAzs4pyADAzqygHADOzimpLAJD0cUkPSZoraXw7ymBmVnXtagE8COwG3NKm5ZuZVV5b7gOIiEcAJLVj8WZmxgC4EUzSwcDBAKuvvnqbS2NmA5lvFJtXywKApBuAleskHR0Rv202n4iYBEwCGD9+fPRS8czMKq9lASAiJrQqbzMz6zlfBmpmVlHtugz0Y5KeBjYHrpJ0bTvKYWZWZe26Cugy4LJ2LNtaxwNsZgOLu4DMzCrKAcDMrKIcAMzMKsoBwMysovr9ncDWvP4+CNvu8rV7+T010Mtv/Y9bAGZmFeUAYGZWUQ4AZmYV5TEAM7OsauMsbgGYmVWUA4CZWUU5AJiZVZQDgJlZRXkQ2Mx6TdUGUQc6twDMzCrKAcDMrKIcAMzMKsoBwMysohwAzMwqygHAzKyiHADMzCrKAcDMrKIcAMzMKsoBwMysohwAzMwqygHAzKyiHADMzCrKAcDMrKIcAMzMKqqpACDpns7em5nZwNNUAIiI93b23szMBp5mWwCjJU3Ir5eQNLS1xTIzs1brMgBI+gzwa+DH+aNVgctbWSgzM2u9ZloA/wt8AJgBEBH/AFZsZaHMzKz1mgkAb0bE7NobSYOBaF2RzMysLzQTAP4o6ShgCUkfAn4F/K61xTIzs1ZrJgAcAUwHHgAOAa4GjmlloczMrPUGdzVBRMwFzsl/vULSt4GPArOBx4H9I+KV3srfzMy61sxVQE9KeqL818PlXg9sEBFjgUeBI3uYn5mZdVOXLQBgfOH1EODjwIieLDQiriu8/QswsSf5mZlZ93XZAoiIFwt/z0TED4CderEMBwC/b5Qo6WBJUyRNmT59ei8u1sys2rpsAUgqPvZhEVKLoJn5bgBWrpN0dET8Nk9zNPA2cEGjfCJiEjAJYPz48b781MyslzTTBfTdwuu3ganAHl3NFBETOkuXtB+wM7BdRPjAbmbWx5q5CuiDvb1QSdsDXwW2jojXezt/MzPrWsMAIOlLnc0YEd/rwXLPBBYHrpcE8JeIOLQH+ZmZWTd11gJo2RM/I2KtVuVtZmbNaRgAIuKEviyImZn1rWau5hkCHAisT7oPAICIOKCF5TIzsxZr5llA55Mu5/wI8EfS7wHMbGWhzMys9ZoJAGtFxLHAaxHxc9JNYJu1tlhmZtZqzQSAt/L/VyRtAAzHPwhjZjbgNXMj2CRJywLHAlcAS+fXZmY2gDUTAH4WEXNI/f9rtrg8ZmbWR5rpAnpS0iRJ2ynftWVmZgNfMwFgXeAG0o/DT5V0pqQtWlssMzNrtWYeB/16RFwSEbsB44BhpO4gMzMbwJppASBpa0lnAXeTbgbr8mmgZmbWvzVzJ/BU4K/AJcBXIuK1VhfKzMxar5mrgMZGxIyWl8TMzPpUM2MAPvibmS2EmhoDMDOzhY8DgJlZRTUzCLw4sDswpjh9RHyjdcUyM7NWa2YQ+LfAq6RLQN9sbXHMzKyvNBMAVo2I7VteEjMz61PNjAHcJmnDlpfEzMz6VDMtgC2A/SQ9SeoCEhARMbalJTMzs5ZqJgDs0PJSmJlZn2vmRrCngGWAj+a/ZfJnZmY2gHUZACR9AbiA9DOQKwK/lPS5VhfMzMxaq5kuoAOBzWoPgZN0GnA7cEYrC2ZmZq3VzFVAAuYU3s/Jn5mZ2QDW1G8CA3dIuiy/3xU4t3VFMjOzvtBlAIiI70m6mXQ5KMD+EfHXlpbKzMxarmEAkDQsImZIGgFMzX+1tBER8VLri2dmZq3SWQvgQmBn0jOAovC58vs1W1guMzNrsYYBICJ2zv/X6LvimJlZX2nmPoA/NPOZmZkNLJ2NAQwBlgSWl7QsHZd+DgNG9UHZzMyshTobAzgE+CIwkjQOUAsAM4AzW1wuMzNrsc7GAE4HTpf0uYjwXb9mZguZZu4EnitpmdobSctK+mwLy2RmZn2gmQDwmYh4pfYmIl4GPtO6IpmZWV9oJgAMkvTOs38kDQIW68lCJZ0o6X5J90q6TtLInuRnZmbd10wAuAa4WNJ2krYDJufPeuLbETE2IsYBVwJf72F+ZmbWTc08DO5rwMHA/+T31wPn9GShETGj8HYp5r3T2MzM+kAzvwg2NyLOjoiJETEReJhe+C0ASSdLmgbsQyctAEkHS5oiacr06dN7ulgzM8ua6QJC0saSviVpKvAN4G9NzHODpAfr/O0CEBFHR8RqpF8bO6xRPhExKSLGR8T4FVZYoamVMjOzrnV2J/A6wN757wXgYkAR8cFmMo6ICU2W4QLgauC4Jqc3M7Ne0FkL4G/AtsDOEbFFvhlsTifTN03S2oW3u9BEi8LMzHpXZ4PAuwF7ATdJuga4iN77KchTJb0bmAs8BRzaS/mamVmTOnsUxOXA5ZKWIp2lfxFYUdKPgMsi4roFXWhE7L6g85qZWe9o5iqg1yLiwoj4KLAq8FfSpaFmZjaANXUVUE1EvJyvytmuVQUyM7O+0a0AYGZmCw8HADOzinIAMDOrKAcAM7OKcgAwM6soBwAzs4pyADAzqygHADOzinIAMDOrKAcAM7OKcgAwM6soBwAzs4pyADAzqygHADOzinIAMDOrKAcAM7OKcgAwM6soBwAzs4pyADAzqygHADOzinIAMDOrKAcAM7OKcgAwM6soBwAzs4pyADAzqygHADOzinIAMDOrKAcAM7OKcgAwM6soBwAzs4pyADAzqygHADOzinIAMDOrKAcAM7OKcgAwM6uotgYASYdLCknLt7McZmZV1LYAIGk14MPAP9tVBjOzKmtnC+D7wFeBaGMZzMwqqy0BQNIuwDMRcV8T0x4saYqkKdOnT++D0pmZVcPgVmUs6QZg5TpJRwNHkbp/uhQRk4BJAOPHj3drwcysl7QsAETEhHqfS9oQWAO4TxLAqsA9kjaNiOdbVR4zM5tXywJAIxHxALBi7b2kqcD4iHihr8tiZlZlvg/AzKyi+rwFUBYRY9pdBjOzKnILwMysohwAzMwqygHAzKyiHADMzCrKAcDMrKIcAMzMKsoBwMysohwAzMwqygHAzKyiHADMzCrKAcDMrKIcAMzMKsoBwMysohwAzMwqygHAzKyiHADMzCrKAcDMrKLa/otgfWXqqTu1uwhmZv2KWwBmZhXlAGBmVlEOAGZmFeUAYGZWUQ4AZmYV5QBgZlZRDgBmZhXlAGBmVlEOAGZmFeUAYGZWUYqIdpehaZKmA0/1QlbLAy+0ML0vluH0aqf3hzI4vf11oFmjI2KF+T6NiMr9AVNamd4Xy3B6tdP7Qxmc3v460NM/dwGZmVWUA4CZWUVVNQBManF6XyzD6dVO7w9lcHp703tsQA0Cm5lZ76lqC8DMrPIcAMzMKqoyPwlZI2k/4GAggM9FxD2l9GuB9wKnR8RJpbSNgTOBOcDbwEER8UQhfRhwDTAbWBI4MiL+UKcM6wAPAR+MiFtLaW8Ad+S350fEuaX0TYBvAosCd0XEV0vp6wFn5beLA+tExHKFdAFnAJuQvv/vRcTkUh4nAB/K6/F54NvFbZLz+D9gHPAqsAQwtpD+LuAS4N3A9sCxpfk/BRwG/Ad4FhgBbFxI3xo4JW/juaQTlfUofSeS9if1k95Yyn8bYDLw9zzp4Tm/eb7XXI5P5/xHACMLeXyCVE8AVgKWBQYV0pcFLs7buLYfrVNIXxL4Bela7rmk+jA7r9NBeb3PBVYHZgLL5LRa+srAj4G1gbWAFSjVPWAisHt+/8+cVzF907yd5+byLVYsQ63u5u97f2Baaf6tgONI994sTdpn3ijOL+lrpLqyDDAEeKkw/67Af+dlr53/P15IBzgvl2+p/P6NQvprwM/zNn4OWAN4M2/LI0nfe60evpa/w9cL6VPpqIe7AcdT2DeBUXTUw3/n98X836ajHip/PovSvl2oh3eV8p9DRz0cBAwDXi7OX6iDi5K+82cL86/EvHXw4YjYnd7U6utM+9MfaSe+h7QjrAHcWmeaVYH9gGPqpK0MDM2vdyQdoIvpiwCD8+s1SQfoeuU4H7gB2KJO2mOdlH8x4PpaGZpY3z2As0ufbQDclF8PBR4vpY8Dfp9frwbcVN4mpIP6ufn1p4AfltKXJO2M5wFb1Jl/TWBQfv0t4Mul9MUK5TkA+FH5OyEdbK4kHVDK+W8D/KSz7xVYn3SAVr300rxnAZ8tzX8YcFxheVeU0r8IHJFfHwx8u1hvgEOBYwvb4Aul9OGkg+7NuWzz1T1g7UIZrwB2LqUXt+N3gS+V6y7pwDIZeLJO/sX1qbf8HYBTmtw3bgC2Lc3/HeDT+bMvAN8vpf8A2Ct/dgRwSHHfYt56+GngtFJ6sR5uSWnfZP56+JlSenH7HQh8p7xvM289LOe/DbkeUufYQKEO1kuvUwf36ukxsPxXtS6gTYE/RcTsiHgSGCpp8eIEEfF0o5kj4vmImJnfvkk6Myimz42I2mfDgPvLeUjaDHgeaLSclSX9UdJvJI0ppW1OOgO5UNKNkrZsVNbsk8AvS589C8yWtCgpALxUSl8HuDuvzzRSoJxemmZrUqUH+B3pzPodEfF6RLxUeP90Kf2JiJiT375Zzj8iZhfeDgNuq7NunwfOTpPX/c4+IulPks6QtESdaSaSzhavk3RZnfkByNtpB+BnpaRHctkgnViU71BfB5iSX18PfCC/rtWb4jacDLy/mB4Rr0bErFpm9epeRPyjsLxXSS2JYnpxO0I6+SmWAVLr7JvAnAZ1+1OSbgX+l3SWXUzfAxgi6Q+kVuIideZH0orAqIi4sZT+EKnlQJ736VJ6cRveQdpm0LFvFbfhFaQWyzvppXoY5X2zTj2cXUovbr+hwH2l5cO89bDevv8RSX8CTied5RfT36mDwKWkIFqev1gHf0svq1oAWI7UBKt5hXSG0C2SlgJOIlX6ctqovMNcB9Q7sBwNnNpJ9mMiYmtS8//cUtpIYCNgH2Bf4JzcHVOvjMsB6wJ/LiW9DPwDeBS4N69H0YPANpIWk7QR6exz2dI0xe34Sp30pkhal3QWd3GdtJ0kTSGded9eSlsW2CoirizPl91NOjveEphBamGUjczr8WHSdv5Og7x2AG6JiDfqLOP9kh4kdal9t5T+QF43SGe0I0r1prwNy+l11Zsmd5mtAtxSTpd0oKQHSGfADxXTJa0NLB0R9zfI/7fAe0gH2tHAPqX0kcDciNiOdIA+ssE67EXqiinnfwNwiKT7SS2in5TSy9twldK+Vd6GK3S27zXaNwv18E/l9FI9fKKYXq6HdfIv18MTSunlOvjDBuVvVAd7rGoB4CU6zjggNbPLZ8CdytH4YlJz8+FyekQ8ExFbkFobZ5bm3Yl0e/eLjfKPiBfy/2tJO125/LdFxIyIeIb0nJD5n++R7An8KnL7seBDpL7OtUgB4pRiKyiv04Wks9YvkM7Syi2A4nYczrxBtSmSViX17+4VEf8pp0fEVRExHjiG1A9bdCSpyV5XRMws5HkBML7OZC8B1+btcy2wYYPs6rWiAL4KXBoRGwAfJ3WDFZ1LOju+ibS9n2PeelNvGzasV1C/7kkaSzqh2Is0FjFPekScGxEbAr8GvlZKPx44sVH+EfFyRMzJZ8kXkep0eR2uybNfQzo5qbcO+wC/rFP+00hdTGNzWU4tpZ8CbCbpxrxuT5b2rfI2nN5o38vbYr59s1QPnyinl+rhF0rp89TDcv516uG765S/WAfXalD+RnWwx6oWAO4AtpC0qKTVgVkR8WazM0tahPRFXB4Rl9dJL3YnzaCjSV4zjnR2fQ3pQPwdSaML8y8taVB+PZb5HwR1B7COpMGShgIrAo2CyT7UrzQCXs479UzSuMKg4gQRcVZuhXwPeKDQTK75I+mMjPz/jw3KUJek5UlN3kMj4vE66UMKb18hNZOL1gGOyttxFUnztCAkDS+83ZaOweCim+kIDJuQ+nDL5RiW0+YbyCdtx9r3829KLcnczXhYRHyQ1D00jHnrTXEb7kQKyHXrVS7LfHVP0lrAT0kH/5fqpBe346uks9ziMtYknXVeQ2pBPFSav3iytC3wX6X5b6ZjG74PeFd5HfIFD0HavuV9p7gNp+ft8U567gbbNyK2JXXP/DpPW9u3itvwv+moh/X2vUULr2cAM4v1kHm7ZGvpxe33Gh31sJZ/o3pYm79YDz9MRz2szX8zHdvv/XTUwXfK30Ud7LHK3Qgm6QDSFQZBiuhTSunnkCr64sCDEbFrIW0iaUCpNs8DEfG5QvomwPdJo/+DgeOjzlVAedrzSANEtxY+25TU9TMzl+/zEXFfab59gUNIFfrUiKjX1F0TuCSfuZTTBpHOTtfK63h+RPxfaZrrcvlfJPX9nlzcJqQrKs4gXfkzI0+3SSH9U8BvSFfuPEM60RhSSH+adIXIY3mRi5CawrX0K0ldXHNJfbMv52XV+04eIw1UF8t3HWnw+HXSAeYAUpdCcZqPkQLcxnn5z5MG5d5ZRq4r60fE4eV6QeoSOJ8UPJcgHcDWKKQfRRq4m0O6smUbCvWG1IL4KamLTaSTg2L6GXn+TXJ+jwCfKE2zBqkV9zSpJbgmHVeQPUAKTNvl90NIFwA0qrvPkfq5i/nPACaQ+uPfJJ2ZFtO/DJxDulhgWdKVPncV85f0jbxtnqO075D6zn+c81+ZdBXTnYX0y0hjFHPz+o+lsG+RvvdaPYT0XbxZSL+Ljnr4MmlQ/YlC+sfoqIdL5/V/tpC+Bh31cPGc/+vU2bclTSMNpBfL92466uHbOY/ZhfQb6aiDw/K8s4r5F+sgLVC5AGBmZknVuoDMzCxzADAzqygHADOzinIAMDOrKAcAM7OKcgCwhZ6kXSVFvuOzFfmPk7Rjg7T9JM13U1IX+R3VOyUz65wDgFXB3sCt+X8rjKPjhqTe4ABgfcIBwBZqkpYmPZH0QNIds7XPF5F0lqS/Sbpe0tX5Rj8kbaL0QL67JV0raZX8+c2STpN0p6RHJW0paTHgG8Ceku6VtGedYqyW5/2HpOMKZfhkzuteST+WNEjSqcAS+bMLWrhpzBwAbKG3C3BNRGn/mosAAAHdSURBVDwKvJjv1oZ0N/MY0l2i+5KetFp7Hs4ZwMSI2IR0t+7JhfwGR8SmpMc9H5efGPl14OKIGBcR8z3YjnQH7e6kO1Y/Lmm8pPeQntf0gYgYR7oLdJ+IOAJ4I+e1Ty7T1ZJG9tYGMaup3A/CWOXsTXoUL6QHmu1NekrjFqSH5c0Fns8PbYN0+/4GwPVKD1odRHqMQc1v8v+7SQGkGdfXHgAo6Td52W+THvNwV17OEqRHN8wnInqze8nsHQ4AttCSNIL0ELMNJQXpYB6SvtLZbMBDEbF5g/TawwNrz3xpRvl5K5GX8/OIOLLJPMx6nbuAbGE2kfSwu9ERMSYiViM9sGtL0u8k7J7HAlYiPawN0hMbV5D0TpeQpPW7WM5M0oPEGvmQpBGSliA9fOzPpKc7TlT6sRRyeu3JsG/lriizlnIAsIXZ3sz/wyCX5s8vJT1F82HSY4rvAV7NffoTgdMk3Uf60Zz/6mI5NwHrdTIIfGde3v2k3xCYkp93fwzpF8nuJ/3+wip5+knA/bVBYI8BWKv4aaBWWZKWjohZSr+edidpQPb5dpfLrK94DMCq7Mr8oyeLASf64G9V4xaAmVlFeQzAzKyiHADMzCrKAcDMrKIcAMzMKsoBwMysov4fhiG9y87QbTMAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"ebqIYd1-gaPO"},"source":["# ***Deep Reinforcement Learning***"]},{"cell_type":"markdown","metadata":{"id":"EcqgshmAgixU"},"source":["## ***MountainCar-v0***"]},{"cell_type":"code","metadata":{"id":"edTKG3HcgeJ3"},"source":["from keras import models\n","from keras import layers\n","from tensorflow.keras.optimizers import Adam\n","from collections import deque\n","import random\n","import numpy as np\n","\n","class MountainCarTrain:\n","    def __init__(self,env):\n","        self.env=env\n","        self.gamma=0.99\n","\n","        self.epsilon = 1\n","        self.epsilon_decay = 0.05\n","\n","        self.epsilon_min=0.01\n","\n","\n","        self.learingRate=0.001\n","\n","        self.replayBuffer=deque(maxlen=20000)\n","        self.trainNetwork=self.createNetwork()\n","\n","        self.episodeNum=400\n","\n","        self.iterationNum=201 #max is 200\n","\n","        self.numPickFromBuffer=32\n","\n","        self.targetNetwork=self.createNetwork()\n","\n","        self.targetNetwork.set_weights(self.trainNetwork.get_weights())\n","\n","    def createNetwork(self):\n","        model = models.Sequential()\n","        state_shape = self.env.observation_space.shape\n","\n","        model.add(layers.Dense(24, activation='relu', input_shape=state_shape))\n","        model.add(layers.Dense(48, activation='relu'))\n","        model.add(layers.Dense(self.env.action_space.n,activation='linear'))\n","        # model.compile(optimizer=optimizers.RMSprop(lr=self.learingRate), loss=losses.mean_squared_error)\n","        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learingRate))\n","        return model\n","\n","    def getBestAction(self,state):\n","\n","        self.epsilon = max(self.epsilon_min, self.epsilon)\n","\n","        if np.random.rand(1) < self.epsilon:\n","            action = np.random.randint(0, 3)\n","        else:\n","            action=np.argmax(self.trainNetwork.predict(state)[0])\n","\n","        return action\n","\n","    \n","\n","    def trainFromBuffer_Boost(self):\n","        if len(self.replayBuffer) < self.numPickFromBuffer:\n","            return\n","        samples = random.sample(self.replayBuffer,self.numPickFromBuffer)\n","        npsamples = np.array(samples)\n","        states_temp, actions_temp, rewards_temp, newstates_temp, dones_temp = np.hsplit(npsamples, 5)\n","        states = np.concatenate((np.squeeze(states_temp[:])), axis = 0)\n","        rewards = rewards_temp.reshape(self.numPickFromBuffer,).astype(float)\n","        targets = self.trainNetwork.predict(states)\n","        newstates = np.concatenate(np.concatenate(newstates_temp))\n","        dones = np.concatenate(dones_temp).astype(bool)\n","        notdones = ~dones\n","        notdones = notdones.astype(float)\n","        dones = dones.astype(float)\n","        Q_futures = self.targetNetwork.predict(newstates).max(axis = 1)\n","        targets[(np.arange(self.numPickFromBuffer), actions_temp.reshape(self.numPickFromBuffer,).astype(int))] = rewards * dones + (rewards + Q_futures * self.gamma)*notdones\n","        self.trainNetwork.fit(states, targets, epochs=1, verbose=0)\n","\n","\n","\n","    def trainFromBuffer(self):\n","        if len(self.replayBuffer) < self.numPickFromBuffer:\n","            return\n","\n","        samples = random.sample(self.replayBuffer,self.numPickFromBuffer)\n","\n","        states = []\n","        newStates=[]\n","        for sample in samples:\n","            state, action, reward, new_state, done = sample\n","            states.append(state)\n","            newStates.append(new_state)\n","\n","        newArray = np.array(states)\n","        states = newArray.reshape(self.numPickFromBuffer, 2)\n","\n","        newArray2 = np.array(newStates)\n","        newStates = newArray2.reshape(self.numPickFromBuffer, 2)\n","\n","        targets = self.trainNetwork.predict(states)\n","        new_state_targets=self.targetNetwork.predict(newStates)\n","\n","        i=0\n","        for sample in samples:\n","            state, action, reward, new_state, done = sample\n","            target = targets[i]\n","            if done:\n","                target[action] = reward\n","            else:\n","                Q_future = max(new_state_targets[i])\n","                target[action] = reward + Q_future * self.gamma\n","            i+=1\n","\n","        self.trainNetwork.fit(states, targets, epochs=1, verbose=0)\n","\n","\n","    def orginalTry(self,currentState,eps):\n","        rewardSum = 0\n","        max_position=-99\n","\n","        for i in range(self.iterationNum):\n","            bestAction = self.getBestAction(currentState)\n","\n","            #show the animation every 50 eps\n","            # if eps%50==0:\n","            #     env.render()\n","\n","            new_state, reward, done, _ = env.step(bestAction)\n","\n","            new_state = new_state.reshape(1, 2)\n","\n","            # # Keep track of max position\n","            if new_state[0][0] > max_position:\n","                max_position = new_state[0][0]\n","\n","\n","            # # Adjust reward for task completion\n","            if new_state[0][0] >= 0.5:\n","                reward += 10\n","\n","            self.replayBuffer.append([currentState, bestAction, reward, new_state, done])\n","\n","            #Or you can use self.trainFromBuffer_Boost(), it is a matrix wise version for boosting \n","            self.trainFromBuffer()\n","\n","            rewardSum += reward\n","\n","            currentState = new_state\n","\n","            if done:\n","                break\n","\n","        if i >= 199:\n","            print(\"Failed to finish task in epsoide {}\".format(eps))\n","        else:\n","            print(\"Success in epsoide {}, used {} iterations!\".format(eps, i))\n","            self.trainNetwork.save('./trainNetworkInEPS{}.h5'.format(eps))\n","\n","        #Sync\n","        self.targetNetwork.set_weights(self.trainNetwork.get_weights())\n","\n","        print(\"now epsilon is {}, the reward is {} maxPosition is {}\".format(max(self.epsilon_min, self.epsilon), rewardSum,max_position))\n","        self.epsilon -= self.epsilon_decay\n","\n","    def start(self):\n","        for eps in range(self.episodeNum):\n","            currentState=env.reset().reshape(1,2)\n","            self.orginalTry(currentState, eps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9tEgKYtqgwz_","executionInfo":{"status":"ok","timestamp":1636729090497,"user_tz":-330,"elapsed":10479037,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}},"outputId":"d1e862d9-1408-4eec-a1d5-100b3bf30692"},"source":["import gym\n","\n","env = gym.make('MountainCar-v0')\n","dqn=MountainCarTrain(env=env)\n","dqn.start()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Failed to finish task in epsoide 0\n","now epsilon is 1, the reward is -200.0 maxPosition is -0.3524132933850725\n","Failed to finish task in epsoide 1\n","now epsilon is 0.95, the reward is -200.0 maxPosition is -0.3070783992907518\n","Failed to finish task in epsoide 2\n","now epsilon is 0.8999999999999999, the reward is -200.0 maxPosition is -0.4299435894539687\n","Failed to finish task in epsoide 3\n","now epsilon is 0.8499999999999999, the reward is -200.0 maxPosition is -0.43446207858135955\n","Failed to finish task in epsoide 4\n","now epsilon is 0.7999999999999998, the reward is -200.0 maxPosition is -0.280338239602065\n","Failed to finish task in epsoide 5\n","now epsilon is 0.7499999999999998, the reward is -200.0 maxPosition is -0.3681538690378387\n","Failed to finish task in epsoide 6\n","now epsilon is 0.6999999999999997, the reward is -200.0 maxPosition is -0.36261997202587165\n","Failed to finish task in epsoide 7\n","now epsilon is 0.6499999999999997, the reward is -200.0 maxPosition is -0.2033583982262082\n","Failed to finish task in epsoide 8\n","now epsilon is 0.5999999999999996, the reward is -200.0 maxPosition is -0.13855569023469297\n","Failed to finish task in epsoide 9\n","now epsilon is 0.5499999999999996, the reward is -200.0 maxPosition is -0.14842178324856836\n","Failed to finish task in epsoide 10\n","now epsilon is 0.4999999999999996, the reward is -200.0 maxPosition is -0.2793319258043251\n","Failed to finish task in epsoide 11\n","now epsilon is 0.4499999999999996, the reward is -200.0 maxPosition is -0.3795558553134636\n","Failed to finish task in epsoide 12\n","now epsilon is 0.39999999999999963, the reward is -200.0 maxPosition is -0.15214968359420947\n","Failed to finish task in epsoide 13\n","now epsilon is 0.34999999999999964, the reward is -200.0 maxPosition is -0.2348832047537745\n","Failed to finish task in epsoide 14\n","now epsilon is 0.29999999999999966, the reward is -200.0 maxPosition is -0.1497673992059681\n","Failed to finish task in epsoide 15\n","now epsilon is 0.24999999999999967, the reward is -200.0 maxPosition is -0.08413258119435982\n","Failed to finish task in epsoide 16\n","now epsilon is 0.19999999999999968, the reward is -200.0 maxPosition is -0.2788637847690169\n","Failed to finish task in epsoide 17\n","now epsilon is 0.1499999999999997, the reward is -200.0 maxPosition is -0.17541139327945746\n","Failed to finish task in epsoide 18\n","now epsilon is 0.09999999999999969, the reward is -200.0 maxPosition is -0.23885933016467759\n","Failed to finish task in epsoide 19\n","now epsilon is 0.049999999999999684, the reward is -200.0 maxPosition is -0.11590947866633974\n","Failed to finish task in epsoide 20\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.12057596031550417\n","Success in epsoide 21, used 185 iterations!\n","now epsilon is 0.01, the reward is -176.0 maxPosition is 0.5294146062416286\n","Failed to finish task in epsoide 22\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.18958001342887487\n","Failed to finish task in epsoide 23\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.07687881686420892\n","Failed to finish task in epsoide 24\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.20245064840757712\n","Failed to finish task in epsoide 25\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.07706479055932372\n","Failed to finish task in epsoide 26\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.10456900634389282\n","Failed to finish task in epsoide 27\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.02419682800432305\n","Failed to finish task in epsoide 28\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.3085194327013536\n","Failed to finish task in epsoide 29\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.1193437903467623\n","Failed to finish task in epsoide 30\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.13010469556431345\n","Failed to finish task in epsoide 31\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.253077924123337\n","Failed to finish task in epsoide 32\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.04981205956334721\n","Failed to finish task in epsoide 33\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.09580553163391546\n","Failed to finish task in epsoide 34\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.004608990170606679\n","Failed to finish task in epsoide 35\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2760154039240527\n","Failed to finish task in epsoide 36\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.19128354963158592\n","Failed to finish task in epsoide 37\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.03475348570020361\n","Failed to finish task in epsoide 38\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.22268068276799002\n","Failed to finish task in epsoide 39\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2033148717134867\n","Failed to finish task in epsoide 40\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.2145653751979175\n","Failed to finish task in epsoide 41\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.09969594676308417\n","Failed to finish task in epsoide 42\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.04221954398141184\n","Failed to finish task in epsoide 43\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.23829267350123073\n","Failed to finish task in epsoide 44\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.22811383970325916\n","Failed to finish task in epsoide 45\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.019928887042185605\n","Failed to finish task in epsoide 46\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.16465049047824673\n","Failed to finish task in epsoide 47\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.23211727866456927\n","Success in epsoide 48, used 115 iterations!\n","now epsilon is 0.01, the reward is -106.0 maxPosition is 0.5146450313176049\n","Failed to finish task in epsoide 49\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.03757323940397939\n","Failed to finish task in epsoide 50\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.1327045195014213\n","Failed to finish task in epsoide 51\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.17859691787926024\n","Failed to finish task in epsoide 52\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.28437722651457875\n","Failed to finish task in epsoide 53\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.31784345259358654\n","Success in epsoide 54, used 166 iterations!\n","now epsilon is 0.01, the reward is -157.0 maxPosition is 0.5187573452834087\n","Failed to finish task in epsoide 55\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2495120525554502\n","Failed to finish task in epsoide 56\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.026103184552185105\n","Failed to finish task in epsoide 57\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.1928315780895043\n","Failed to finish task in epsoide 58\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.16206150286733176\n","Failed to finish task in epsoide 59\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.12057070647127391\n","Success in epsoide 60, used 98 iterations!\n","now epsilon is 0.01, the reward is -89.0 maxPosition is 0.5154675016263012\n","Failed to finish task in epsoide 61\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.3266907765543536\n","Success in epsoide 62, used 115 iterations!\n","now epsilon is 0.01, the reward is -106.0 maxPosition is 0.5093562372516088\n","Success in epsoide 63, used 102 iterations!\n","now epsilon is 0.01, the reward is -93.0 maxPosition is 0.5032665865268193\n","Failed to finish task in epsoide 64\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.03158751851330652\n","Failed to finish task in epsoide 65\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2424638410147817\n","Failed to finish task in epsoide 66\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.1019430074053843\n","Failed to finish task in epsoide 67\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.14255415900949733\n","Failed to finish task in epsoide 68\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.05053562716336016\n","Failed to finish task in epsoide 69\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.14940601513888294\n","Success in epsoide 70, used 158 iterations!\n","now epsilon is 0.01, the reward is -149.0 maxPosition is 0.5211466536320155\n","Failed to finish task in epsoide 71\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.22828822537240048\n","Failed to finish task in epsoide 72\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.28256147766800965\n","Failed to finish task in epsoide 73\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.3577043644844212\n","Failed to finish task in epsoide 74\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.13450531822988185\n","Success in epsoide 75, used 174 iterations!\n","now epsilon is 0.01, the reward is -165.0 maxPosition is 0.5059110852620284\n","Failed to finish task in epsoide 76\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.138928734339838\n","Failed to finish task in epsoide 77\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.27758137421887413\n","Failed to finish task in epsoide 78\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.25317017857459756\n","Failed to finish task in epsoide 79\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2258238267981899\n","Failed to finish task in epsoide 80\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.3130529841388198\n","Failed to finish task in epsoide 81\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.08706571126531527\n","Failed to finish task in epsoide 82\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.1462486634505181\n","Failed to finish task in epsoide 83\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.34276160870772293\n","Failed to finish task in epsoide 84\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.0870642490145532\n","Failed to finish task in epsoide 85\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.01879483725826105\n","Failed to finish task in epsoide 86\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.3674493707721311\n","Failed to finish task in epsoide 87\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.28638191156605713\n","Success in epsoide 88, used 159 iterations!\n","now epsilon is 0.01, the reward is -150.0 maxPosition is 0.5076502699253835\n","Failed to finish task in epsoide 89\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.35281639577528084\n","Failed to finish task in epsoide 90\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2932727044705906\n","Failed to finish task in epsoide 91\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.06956679438850356\n","Failed to finish task in epsoide 92\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.26076986791356377\n","Failed to finish task in epsoide 93\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2408647638434624\n","Failed to finish task in epsoide 94\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.08280775649750768\n","Failed to finish task in epsoide 95\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.16373455704236908\n","Failed to finish task in epsoide 96\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.1484855716729034\n","Failed to finish task in epsoide 97\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.4066075962847191\n","Failed to finish task in epsoide 98\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.03091052433703733\n","Failed to finish task in epsoide 99\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2749867307157541\n","Failed to finish task in epsoide 100\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.0013214572967789905\n","Failed to finish task in epsoide 101\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2171181534465875\n","Failed to finish task in epsoide 102\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.1241058264474776\n","Failed to finish task in epsoide 103\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.010188534873267888\n","Failed to finish task in epsoide 104\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.0021787170758499654\n","Failed to finish task in epsoide 105\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.4171489240764023\n","Failed to finish task in epsoide 106\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.40799331971256275\n","Failed to finish task in epsoide 107\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.10868328455358472\n","Failed to finish task in epsoide 108\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.31992749019392\n","Success in epsoide 109, used 152 iterations!\n","now epsilon is 0.01, the reward is -143.0 maxPosition is 0.5221052039242029\n","Failed to finish task in epsoide 110\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.10003874232306688\n","Failed to finish task in epsoide 111\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.02444470209764\n","Failed to finish task in epsoide 112\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.15709576188779367\n","Failed to finish task in epsoide 113\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.03843210057705962\n","Failed to finish task in epsoide 114\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.04351552286369948\n","Failed to finish task in epsoide 115\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.1468716207805081\n","Failed to finish task in epsoide 116\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.07642418458642222\n","Failed to finish task in epsoide 117\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.36747026615683426\n","Failed to finish task in epsoide 118\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.15824449466394083\n","Failed to finish task in epsoide 119\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.07298235077250485\n","Success in epsoide 120, used 163 iterations!\n","now epsilon is 0.01, the reward is -154.0 maxPosition is 0.5250838395911595\n","Failed to finish task in epsoide 121\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.00787213243487874\n","Failed to finish task in epsoide 122\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.0854474665777644\n","Failed to finish task in epsoide 123\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.1417763280201628\n","Success in epsoide 124, used 132 iterations!\n","now epsilon is 0.01, the reward is -123.0 maxPosition is 0.5212711802880642\n","Failed to finish task in epsoide 125\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.27775662796627576\n","Failed to finish task in epsoide 126\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.19929083510645101\n","Success in epsoide 127, used 195 iterations!\n","now epsilon is 0.01, the reward is -186.0 maxPosition is 0.5177758039357164\n","Failed to finish task in epsoide 128\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.07281634191825924\n","Failed to finish task in epsoide 129\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.23514054916909405\n","Failed to finish task in epsoide 130\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.057916105681928925\n","Success in epsoide 131, used 186 iterations!\n","now epsilon is 0.01, the reward is -177.0 maxPosition is 0.5191966956131646\n","Failed to finish task in epsoide 132\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2431024558792686\n","Failed to finish task in epsoide 133\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.33212900649025073\n","Failed to finish task in epsoide 134\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2896495091176193\n","Failed to finish task in epsoide 135\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.23403085407605875\n","Failed to finish task in epsoide 136\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.19508774569403695\n","Failed to finish task in epsoide 137\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.10848715865766262\n","Failed to finish task in epsoide 138\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.3807164705646364\n","Failed to finish task in epsoide 139\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.53637911462134\n","Failed to finish task in epsoide 140\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5067311088727282\n","Failed to finish task in epsoide 141\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.04346658918499973\n","Failed to finish task in epsoide 142\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.28551421884480604\n","Failed to finish task in epsoide 143\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.16662953999750757\n","Failed to finish task in epsoide 144\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.1258727848972562\n","Success in epsoide 145, used 186 iterations!\n","now epsilon is 0.01, the reward is -177.0 maxPosition is 0.5071286824350305\n","Failed to finish task in epsoide 146\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.3527220887394995\n","Success in epsoide 147, used 196 iterations!\n","now epsilon is 0.01, the reward is -187.0 maxPosition is 0.5025737952388928\n","Failed to finish task in epsoide 148\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.34994944722049426\n","Failed to finish task in epsoide 149\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.1679413263924455\n","Failed to finish task in epsoide 150\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.12593262817692463\n","Failed to finish task in epsoide 151\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5081660470660619\n","Failed to finish task in epsoide 152\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.40813675021640883\n","Success in epsoide 153, used 191 iterations!\n","now epsilon is 0.01, the reward is -182.0 maxPosition is 0.5001177961030273\n","Success in epsoide 154, used 99 iterations!\n","now epsilon is 0.01, the reward is -90.0 maxPosition is 0.5158885869590966\n","Failed to finish task in epsoide 155\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.08934228711530823\n","Failed to finish task in epsoide 156\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.12987132939915952\n","Failed to finish task in epsoide 157\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.3635141594455871\n","Failed to finish task in epsoide 158\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.015729962296154067\n","Success in epsoide 159, used 182 iterations!\n","now epsilon is 0.01, the reward is -173.0 maxPosition is 0.5245149251599214\n","Failed to finish task in epsoide 160\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.13743351588489944\n","Failed to finish task in epsoide 161\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.32877994226174195\n","Failed to finish task in epsoide 162\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.39322571768888115\n","Failed to finish task in epsoide 163\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.1328073667469478\n","Failed to finish task in epsoide 164\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.007507882628279195\n","Failed to finish task in epsoide 165\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.34710568506345274\n","Failed to finish task in epsoide 166\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.050038344962540775\n","Failed to finish task in epsoide 167\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5323028992044582\n","Failed to finish task in epsoide 168\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.1733235302403134\n","Failed to finish task in epsoide 169\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.2723347978802802\n","Success in epsoide 170, used 183 iterations!\n","now epsilon is 0.01, the reward is -174.0 maxPosition is 0.5085949577799603\n","Success in epsoide 171, used 178 iterations!\n","now epsilon is 0.01, the reward is -169.0 maxPosition is 0.5156499066168116\n","Failed to finish task in epsoide 172\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.29331676393455547\n","Failed to finish task in epsoide 173\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.03734431939163221\n","Success in epsoide 174, used 195 iterations!\n","now epsilon is 0.01, the reward is -186.0 maxPosition is 0.5173555183544168\n","Success in epsoide 175, used 127 iterations!\n","now epsilon is 0.01, the reward is -118.0 maxPosition is 0.5076784760942776\n","Failed to finish task in epsoide 176\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.46917394976471816\n","Success in epsoide 177, used 179 iterations!\n","now epsilon is 0.01, the reward is -170.0 maxPosition is 0.5200948158319417\n","Failed to finish task in epsoide 178\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.26599991121625777\n","Failed to finish task in epsoide 179\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.40696723025268444\n","Success in epsoide 180, used 176 iterations!\n","now epsilon is 0.01, the reward is -167.0 maxPosition is 0.5017570810916677\n","Success in epsoide 181, used 184 iterations!\n","now epsilon is 0.01, the reward is -175.0 maxPosition is 0.5074174909892076\n","Success in epsoide 182, used 185 iterations!\n","now epsilon is 0.01, the reward is -176.0 maxPosition is 0.5192736070568075\n","Success in epsoide 183, used 195 iterations!\n","now epsilon is 0.01, the reward is -186.0 maxPosition is 0.5061002953511963\n","Success in epsoide 184, used 168 iterations!\n","now epsilon is 0.01, the reward is -159.0 maxPosition is 0.5126335280808539\n","Success in epsoide 185, used 135 iterations!\n","now epsilon is 0.01, the reward is -126.0 maxPosition is 0.5222766334213044\n","Failed to finish task in epsoide 186\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.496170714535724\n","Success in epsoide 187, used 188 iterations!\n","now epsilon is 0.01, the reward is -179.0 maxPosition is 0.5038491073612663\n","Success in epsoide 188, used 189 iterations!\n","now epsilon is 0.01, the reward is -180.0 maxPosition is 0.5289076277013133\n","Success in epsoide 189, used 173 iterations!\n","now epsilon is 0.01, the reward is -164.0 maxPosition is 0.5132240455375635\n","Success in epsoide 190, used 132 iterations!\n","now epsilon is 0.01, the reward is -123.0 maxPosition is 0.5007067825792395\n","Success in epsoide 191, used 137 iterations!\n","now epsilon is 0.01, the reward is -128.0 maxPosition is 0.5036285384244206\n","Success in epsoide 192, used 146 iterations!\n","now epsilon is 0.01, the reward is -137.0 maxPosition is 0.5251084107491971\n","Failed to finish task in epsoide 193\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.25280145222186906\n","Success in epsoide 194, used 184 iterations!\n","now epsilon is 0.01, the reward is -175.0 maxPosition is 0.5168520693424925\n","Success in epsoide 195, used 102 iterations!\n","now epsilon is 0.01, the reward is -93.0 maxPosition is 0.5147889152332306\n","Failed to finish task in epsoide 196\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.3044876615782575\n","Success in epsoide 197, used 176 iterations!\n","now epsilon is 0.01, the reward is -167.0 maxPosition is 0.5142995709631081\n","Failed to finish task in epsoide 198\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.20051720120671024\n","Failed to finish task in epsoide 199\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.30504320056441964\n","Success in epsoide 200, used 116 iterations!\n","now epsilon is 0.01, the reward is -107.0 maxPosition is 0.5154271293080845\n","Failed to finish task in epsoide 201\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.273408590436358\n","Success in epsoide 202, used 128 iterations!\n","now epsilon is 0.01, the reward is -119.0 maxPosition is 0.5096890039957227\n","Failed to finish task in epsoide 203\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.11326490299649283\n","Failed to finish task in epsoide 204\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.2833137043151989\n","Success in epsoide 205, used 121 iterations!\n","now epsilon is 0.01, the reward is -112.0 maxPosition is 0.5061840405109604\n","Failed to finish task in epsoide 206\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.24257898087796734\n","Failed to finish task in epsoide 207\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.05717395325635527\n","Success in epsoide 208, used 166 iterations!\n","now epsilon is 0.01, the reward is -157.0 maxPosition is 0.508812141263922\n","Failed to finish task in epsoide 209\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.12176754594095415\n","Failed to finish task in epsoide 210\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.18307186721219373\n","Success in epsoide 211, used 180 iterations!\n","now epsilon is 0.01, the reward is -171.0 maxPosition is 0.5088893895937298\n","Failed to finish task in epsoide 212\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.13660276698026647\n","Failed to finish task in epsoide 213\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.24082172003829\n","Failed to finish task in epsoide 214\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.12325192443901363\n","Failed to finish task in epsoide 215\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.29235619311248306\n","Failed to finish task in epsoide 216\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.18075233896314713\n","Failed to finish task in epsoide 217\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.11972948014929852\n","Failed to finish task in epsoide 218\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.0016394815316916815\n","Success in epsoide 219, used 179 iterations!\n","now epsilon is 0.01, the reward is -170.0 maxPosition is 0.5156499066168116\n","Failed to finish task in epsoide 220\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.059449682514593136\n","Failed to finish task in epsoide 221\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.03725454636448963\n","Failed to finish task in epsoide 222\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.2522611171096353\n","Failed to finish task in epsoide 223\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.04933299303819067\n","Failed to finish task in epsoide 224\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.00456951959023612\n","Success in epsoide 225, used 160 iterations!\n","now epsilon is 0.01, the reward is -151.0 maxPosition is 0.510738735443973\n","Success in epsoide 226, used 103 iterations!\n","now epsilon is 0.01, the reward is -94.0 maxPosition is 0.5055861836853976\n","Success in epsoide 227, used 181 iterations!\n","now epsilon is 0.01, the reward is -172.0 maxPosition is 0.5125805611439715\n","Success in epsoide 228, used 183 iterations!\n","now epsilon is 0.01, the reward is -174.0 maxPosition is 0.5051443499346304\n","Success in epsoide 229, used 155 iterations!\n","now epsilon is 0.01, the reward is -146.0 maxPosition is 0.5104080635903744\n","Success in epsoide 230, used 151 iterations!\n","now epsilon is 0.01, the reward is -142.0 maxPosition is 0.5205603734740933\n","Failed to finish task in epsoide 231\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.015384440032770482\n","Success in epsoide 232, used 150 iterations!\n","now epsilon is 0.01, the reward is -141.0 maxPosition is 0.5225951874497831\n","Success in epsoide 233, used 169 iterations!\n","now epsilon is 0.01, the reward is -160.0 maxPosition is 0.5326581113024246\n","Failed to finish task in epsoide 234\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.22360406767354488\n","Success in epsoide 235, used 170 iterations!\n","now epsilon is 0.01, the reward is -161.0 maxPosition is 0.523663181689715\n","Failed to finish task in epsoide 236\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.4395651150509545\n","Success in epsoide 237, used 152 iterations!\n","now epsilon is 0.01, the reward is -143.0 maxPosition is 0.5314932056475683\n","Failed to finish task in epsoide 238\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.35087120088274204\n","Success in epsoide 239, used 167 iterations!\n","now epsilon is 0.01, the reward is -158.0 maxPosition is 0.501399043641431\n","Failed to finish task in epsoide 240\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.402662975951206\n","Success in epsoide 241, used 170 iterations!\n","now epsilon is 0.01, the reward is -161.0 maxPosition is 0.512541364035775\n","Failed to finish task in epsoide 242\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.08058398722110718\n","Failed to finish task in epsoide 243\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.4572944086125372\n","Success in epsoide 244, used 140 iterations!\n","now epsilon is 0.01, the reward is -131.0 maxPosition is 0.5052800100824854\n","Failed to finish task in epsoide 245\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.38919377315275316\n","Failed to finish task in epsoide 246\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.26831229200639123\n","Success in epsoide 247, used 176 iterations!\n","now epsilon is 0.01, the reward is -167.0 maxPosition is 0.5059158386879964\n","Failed to finish task in epsoide 248\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.424643607585222\n","Success in epsoide 249, used 168 iterations!\n","now epsilon is 0.01, the reward is -159.0 maxPosition is 0.503106542999169\n","Success in epsoide 250, used 171 iterations!\n","now epsilon is 0.01, the reward is -162.0 maxPosition is 0.5129109719935041\n","Failed to finish task in epsoide 251\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.13167255120063995\n","Failed to finish task in epsoide 252\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.18216387262067923\n","Success in epsoide 253, used 163 iterations!\n","now epsilon is 0.01, the reward is -154.0 maxPosition is 0.5022357688707656\n","Failed to finish task in epsoide 254\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.16014519112826636\n","Failed to finish task in epsoide 255\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.16115114774040248\n","Success in epsoide 256, used 161 iterations!\n","now epsilon is 0.01, the reward is -152.0 maxPosition is 0.5011844219837774\n","Success in epsoide 257, used 193 iterations!\n","now epsilon is 0.01, the reward is -184.0 maxPosition is 0.5045368641193779\n","Failed to finish task in epsoide 258\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.460610042494133\n","Failed to finish task in epsoide 259\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.2434202588483171\n","Success in epsoide 260, used 119 iterations!\n","now epsilon is 0.01, the reward is -110.0 maxPosition is 0.5022682003904714\n","Failed to finish task in epsoide 261\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.4963203243129449\n","Success in epsoide 262, used 84 iterations!\n","now epsilon is 0.01, the reward is -75.0 maxPosition is 0.5068621771946921\n","Success in epsoide 263, used 162 iterations!\n","now epsilon is 0.01, the reward is -153.0 maxPosition is 0.510454900543527\n","Success in epsoide 264, used 87 iterations!\n","now epsilon is 0.01, the reward is -78.0 maxPosition is 0.514679671207304\n","Success in epsoide 265, used 153 iterations!\n","now epsilon is 0.01, the reward is -144.0 maxPosition is 0.5220490622322357\n","Success in epsoide 266, used 154 iterations!\n","now epsilon is 0.01, the reward is -145.0 maxPosition is 0.5122627620704988\n","Success in epsoide 267, used 155 iterations!\n","now epsilon is 0.01, the reward is -146.0 maxPosition is 0.5015085364567435\n","Success in epsoide 268, used 154 iterations!\n","now epsilon is 0.01, the reward is -145.0 maxPosition is 0.5028316823875842\n","Success in epsoide 269, used 151 iterations!\n","now epsilon is 0.01, the reward is -142.0 maxPosition is 0.5368577983788596\n","Success in epsoide 270, used 85 iterations!\n","now epsilon is 0.01, the reward is -76.0 maxPosition is 0.5018168325185327\n","Success in epsoide 271, used 94 iterations!\n","now epsilon is 0.01, the reward is -85.0 maxPosition is 0.5011861669828531\n","Success in epsoide 272, used 91 iterations!\n","now epsilon is 0.01, the reward is -82.0 maxPosition is 0.5004692093438424\n","Success in epsoide 273, used 90 iterations!\n","now epsilon is 0.01, the reward is -81.0 maxPosition is 0.5190579681491923\n","Success in epsoide 274, used 158 iterations!\n","now epsilon is 0.01, the reward is -149.0 maxPosition is 0.5396609947637298\n","Success in epsoide 275, used 175 iterations!\n","now epsilon is 0.01, the reward is -166.0 maxPosition is 0.503780048166395\n","Failed to finish task in epsoide 276\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.11993668135289244\n","Success in epsoide 277, used 158 iterations!\n","now epsilon is 0.01, the reward is -149.0 maxPosition is 0.5368577983788596\n","Failed to finish task in epsoide 278\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.4282744910229501\n","Success in epsoide 279, used 168 iterations!\n","now epsilon is 0.01, the reward is -159.0 maxPosition is 0.5368577983788596\n","Failed to finish task in epsoide 280\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.05490740260597486\n","Success in epsoide 281, used 172 iterations!\n","now epsilon is 0.01, the reward is -163.0 maxPosition is 0.5368577983788596\n","Success in epsoide 282, used 183 iterations!\n","now epsilon is 0.01, the reward is -174.0 maxPosition is 0.5368577983788596\n","Failed to finish task in epsoide 283\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.12029166277232908\n","Success in epsoide 284, used 163 iterations!\n","now epsilon is 0.01, the reward is -154.0 maxPosition is 0.5368577983788596\n","Success in epsoide 285, used 123 iterations!\n","now epsilon is 0.01, the reward is -114.0 maxPosition is 0.5104924964055697\n","Success in epsoide 286, used 90 iterations!\n","now epsilon is 0.01, the reward is -81.0 maxPosition is 0.5047868193997761\n","Success in epsoide 287, used 84 iterations!\n","now epsilon is 0.01, the reward is -75.0 maxPosition is 0.5180044005560268\n","Success in epsoide 288, used 155 iterations!\n","now epsilon is 0.01, the reward is -146.0 maxPosition is 0.5368577983788596\n","Success in epsoide 289, used 158 iterations!\n","now epsilon is 0.01, the reward is -149.0 maxPosition is 0.5066004166176113\n","Success in epsoide 290, used 147 iterations!\n","now epsilon is 0.01, the reward is -138.0 maxPosition is 0.5043155639159533\n","Failed to finish task in epsoide 291\n","now epsilon is 0.01, the reward is -200.0 maxPosition is 0.2869967940337662\n","Success in epsoide 292, used 100 iterations!\n","now epsilon is 0.01, the reward is -91.0 maxPosition is 0.5037177311982022\n","Success in epsoide 293, used 131 iterations!\n","now epsilon is 0.01, the reward is -122.0 maxPosition is 0.5153602627291055\n","Success in epsoide 294, used 177 iterations!\n","now epsilon is 0.01, the reward is -168.0 maxPosition is 0.5178236928840169\n","Success in epsoide 295, used 144 iterations!\n","now epsilon is 0.01, the reward is -135.0 maxPosition is 0.5162936237262619\n","Success in epsoide 296, used 155 iterations!\n","now epsilon is 0.01, the reward is -146.0 maxPosition is 0.5368577983788596\n","Success in epsoide 297, used 92 iterations!\n","now epsilon is 0.01, the reward is -83.0 maxPosition is 0.5109950215918876\n","Success in epsoide 298, used 150 iterations!\n","now epsilon is 0.01, the reward is -141.0 maxPosition is 0.502802491577734\n","Success in epsoide 299, used 159 iterations!\n","now epsilon is 0.01, the reward is -150.0 maxPosition is 0.5126748855866896\n","Success in epsoide 300, used 90 iterations!\n","now epsilon is 0.01, the reward is -81.0 maxPosition is 0.5010716742088425\n","Success in epsoide 301, used 138 iterations!\n","now epsilon is 0.01, the reward is -129.0 maxPosition is 0.5368577983788596\n","Success in epsoide 302, used 164 iterations!\n","now epsilon is 0.01, the reward is -155.0 maxPosition is 0.5218396476447826\n","Success in epsoide 303, used 170 iterations!\n","now epsilon is 0.01, the reward is -161.0 maxPosition is 0.5368577983788596\n","Success in epsoide 304, used 157 iterations!\n","now epsilon is 0.01, the reward is -148.0 maxPosition is 0.5307989070535666\n","Success in epsoide 305, used 146 iterations!\n","now epsilon is 0.01, the reward is -137.0 maxPosition is 0.505662886654018\n","Success in epsoide 306, used 137 iterations!\n","now epsilon is 0.01, the reward is -128.0 maxPosition is 0.5368577983788596\n","Success in epsoide 307, used 156 iterations!\n","now epsilon is 0.01, the reward is -147.0 maxPosition is 0.5368577983788596\n","Success in epsoide 308, used 141 iterations!\n","now epsilon is 0.01, the reward is -132.0 maxPosition is 0.5368577983788596\n","Success in epsoide 309, used 149 iterations!\n","now epsilon is 0.01, the reward is -140.0 maxPosition is 0.5368577983788596\n","Success in epsoide 310, used 144 iterations!\n","now epsilon is 0.01, the reward is -135.0 maxPosition is 0.5055352839757251\n","Success in epsoide 311, used 154 iterations!\n","now epsilon is 0.01, the reward is -145.0 maxPosition is 0.5368577983788596\n","Failed to finish task in epsoide 312\n","now epsilon is 0.01, the reward is -200.0 maxPosition is -0.1482236132131905\n","Success in epsoide 313, used 154 iterations!\n","now epsilon is 0.01, the reward is -145.0 maxPosition is 0.5368577983788596\n","Success in epsoide 314, used 134 iterations!\n","now epsilon is 0.01, the reward is -125.0 maxPosition is 0.5368577983788596\n","Success in epsoide 315, used 149 iterations!\n","now epsilon is 0.01, the reward is -140.0 maxPosition is 0.5368577983788596\n","Success in epsoide 316, used 149 iterations!\n","now epsilon is 0.01, the reward is -140.0 maxPosition is 0.5168264933681779\n","Success in epsoide 317, used 150 iterations!\n","now epsilon is 0.01, the reward is -141.0 maxPosition is 0.5164555154369531\n","Success in epsoide 318, used 162 iterations!\n","now epsilon is 0.01, the reward is -153.0 maxPosition is 0.5368577983788596\n","Success in epsoide 319, used 167 iterations!\n","now epsilon is 0.01, the reward is -158.0 maxPosition is 0.5410568598079735\n","Success in epsoide 320, used 138 iterations!\n","now epsilon is 0.01, the reward is -129.0 maxPosition is 0.5344569582148987\n","Success in epsoide 321, used 128 iterations!\n","now epsilon is 0.01, the reward is -119.0 maxPosition is 0.5214169148439793\n","Success in epsoide 322, used 89 iterations!\n","now epsilon is 0.01, the reward is -80.0 maxPosition is 0.5150715461162264\n","Success in epsoide 323, used 87 iterations!\n","now epsilon is 0.01, the reward is -78.0 maxPosition is 0.5128036159395065\n","Success in epsoide 324, used 133 iterations!\n","now epsilon is 0.01, the reward is -124.0 maxPosition is 0.5368577983788596\n","Success in epsoide 325, used 152 iterations!\n","now epsilon is 0.01, the reward is -143.0 maxPosition is 0.5368577983788596\n","Success in epsoide 326, used 111 iterations!\n","now epsilon is 0.01, the reward is -102.0 maxPosition is 0.5063570394381067\n","Success in epsoide 327, used 112 iterations!\n","now epsilon is 0.01, the reward is -103.0 maxPosition is 0.5383601931733877\n","Success in epsoide 328, used 121 iterations!\n","now epsilon is 0.01, the reward is -112.0 maxPosition is 0.5103238791603762\n","Success in epsoide 329, used 111 iterations!\n","now epsilon is 0.01, the reward is -102.0 maxPosition is 0.505103877914227\n","Success in epsoide 330, used 149 iterations!\n","now epsilon is 0.01, the reward is -140.0 maxPosition is 0.5368577983788596\n","Success in epsoide 331, used 135 iterations!\n","now epsilon is 0.01, the reward is -126.0 maxPosition is 0.5368577983788596\n","Success in epsoide 332, used 83 iterations!\n","now epsilon is 0.01, the reward is -74.0 maxPosition is 0.5115580699527941\n","Success in epsoide 333, used 130 iterations!\n","now epsilon is 0.01, the reward is -121.0 maxPosition is 0.5368577983788596\n","Success in epsoide 334, used 138 iterations!\n","now epsilon is 0.01, the reward is -129.0 maxPosition is 0.5368577983788596\n","Success in epsoide 335, used 84 iterations!\n","now epsilon is 0.01, the reward is -75.0 maxPosition is 0.5169294727007353\n","Success in epsoide 336, used 174 iterations!\n","now epsilon is 0.01, the reward is -165.0 maxPosition is 0.5368577983788596\n","Success in epsoide 337, used 110 iterations!\n","now epsilon is 0.01, the reward is -101.0 maxPosition is 0.5066575500348665\n","Success in epsoide 338, used 112 iterations!\n","now epsilon is 0.01, the reward is -103.0 maxPosition is 0.5142626584307007\n","Success in epsoide 339, used 84 iterations!\n","now epsilon is 0.01, the reward is -75.0 maxPosition is 0.5056961384935496\n","Success in epsoide 340, used 146 iterations!\n","now epsilon is 0.01, the reward is -137.0 maxPosition is 0.5257126142082267\n","Success in epsoide 341, used 153 iterations!\n","now epsilon is 0.01, the reward is -144.0 maxPosition is 0.5368577983788596\n","Success in epsoide 342, used 118 iterations!\n","now epsilon is 0.01, the reward is -109.0 maxPosition is 0.5022375123349831\n","Success in epsoide 343, used 107 iterations!\n","now epsilon is 0.01, the reward is -98.0 maxPosition is 0.5368577983788596\n","Success in epsoide 344, used 126 iterations!\n","now epsilon is 0.01, the reward is -117.0 maxPosition is 0.5368577983788596\n","Success in epsoide 345, used 156 iterations!\n","now epsilon is 0.01, the reward is -147.0 maxPosition is 0.5215723838392536\n","Success in epsoide 346, used 115 iterations!\n","now epsilon is 0.01, the reward is -106.0 maxPosition is 0.5350022315419667\n","Success in epsoide 347, used 144 iterations!\n","now epsilon is 0.01, the reward is -135.0 maxPosition is 0.5129352477415754\n","Success in epsoide 348, used 123 iterations!\n","now epsilon is 0.01, the reward is -114.0 maxPosition is 0.5255893747224784\n","Success in epsoide 349, used 148 iterations!\n","now epsilon is 0.01, the reward is -139.0 maxPosition is 0.5129352477415754\n","Success in epsoide 350, used 113 iterations!\n","now epsilon is 0.01, the reward is -104.0 maxPosition is 0.5368577983788596\n","Success in epsoide 351, used 117 iterations!\n","now epsilon is 0.01, the reward is -108.0 maxPosition is 0.5219072612042372\n","Success in epsoide 352, used 142 iterations!\n","now epsilon is 0.01, the reward is -133.0 maxPosition is 0.531806603976885\n","Success in epsoide 353, used 87 iterations!\n","now epsilon is 0.01, the reward is -78.0 maxPosition is 0.5074467006083948\n","Success in epsoide 354, used 83 iterations!\n","now epsilon is 0.01, the reward is -74.0 maxPosition is 0.5094936491906414\n","Success in epsoide 355, used 114 iterations!\n","now epsilon is 0.01, the reward is -105.0 maxPosition is 0.5220428176325399\n","Success in epsoide 356, used 84 iterations!\n","now epsilon is 0.01, the reward is -75.0 maxPosition is 0.5069459992731968\n","Success in epsoide 357, used 108 iterations!\n","now epsilon is 0.01, the reward is -99.0 maxPosition is 0.5136887664481644\n","Success in epsoide 358, used 104 iterations!\n","now epsilon is 0.01, the reward is -95.0 maxPosition is 0.5068717433547105\n","Success in epsoide 359, used 148 iterations!\n","now epsilon is 0.01, the reward is -139.0 maxPosition is 0.5368577983788596\n","Success in epsoide 360, used 139 iterations!\n","now epsilon is 0.01, the reward is -130.0 maxPosition is 0.5371390279228068\n","Success in epsoide 361, used 169 iterations!\n","now epsilon is 0.01, the reward is -160.0 maxPosition is 0.5363251097334638\n","Success in epsoide 362, used 141 iterations!\n","now epsilon is 0.01, the reward is -132.0 maxPosition is 0.5387670642806129\n","Success in epsoide 363, used 152 iterations!\n","now epsilon is 0.01, the reward is -143.0 maxPosition is 0.5368577983788596\n","Success in epsoide 364, used 109 iterations!\n","now epsilon is 0.01, the reward is -100.0 maxPosition is 0.5103039789848584\n","Success in epsoide 365, used 153 iterations!\n","now epsilon is 0.01, the reward is -144.0 maxPosition is 0.5368577983788596\n","Success in epsoide 366, used 110 iterations!\n","now epsilon is 0.01, the reward is -101.0 maxPosition is 0.5331773244315756\n","Success in epsoide 367, used 121 iterations!\n","now epsilon is 0.01, the reward is -112.0 maxPosition is 0.5415510801349341\n","Success in epsoide 368, used 116 iterations!\n","now epsilon is 0.01, the reward is -107.0 maxPosition is 0.5416077270794938\n","Success in epsoide 369, used 107 iterations!\n","now epsilon is 0.01, the reward is -98.0 maxPosition is 0.5238782807602149\n","Success in epsoide 370, used 125 iterations!\n","now epsilon is 0.01, the reward is -116.0 maxPosition is 0.524843358283106\n","Success in epsoide 371, used 113 iterations!\n","now epsilon is 0.01, the reward is -104.0 maxPosition is 0.5082745260400259\n","Success in epsoide 372, used 109 iterations!\n","now epsilon is 0.01, the reward is -100.0 maxPosition is 0.5368577983788596\n","Success in epsoide 373, used 111 iterations!\n","now epsilon is 0.01, the reward is -102.0 maxPosition is 0.5334419889449963\n","Success in epsoide 374, used 118 iterations!\n","now epsilon is 0.01, the reward is -109.0 maxPosition is 0.5126415094929134\n","Success in epsoide 375, used 115 iterations!\n","now epsilon is 0.01, the reward is -106.0 maxPosition is 0.5288914748242523\n","Success in epsoide 376, used 170 iterations!\n","now epsilon is 0.01, the reward is -161.0 maxPosition is 0.5420727081567481\n","Success in epsoide 377, used 139 iterations!\n","now epsilon is 0.01, the reward is -130.0 maxPosition is 0.5368577983788596\n","Success in epsoide 378, used 112 iterations!\n","now epsilon is 0.01, the reward is -103.0 maxPosition is 0.5044215392055983\n","Success in epsoide 379, used 120 iterations!\n","now epsilon is 0.01, the reward is -111.0 maxPosition is 0.534332189475921\n","Success in epsoide 380, used 153 iterations!\n","now epsilon is 0.01, the reward is -144.0 maxPosition is 0.5171996084428573\n","Success in epsoide 381, used 119 iterations!\n","now epsilon is 0.01, the reward is -110.0 maxPosition is 0.5201790005648352\n","Success in epsoide 382, used 116 iterations!\n","now epsilon is 0.01, the reward is -107.0 maxPosition is 0.5327995356778372\n","Success in epsoide 383, used 118 iterations!\n","now epsilon is 0.01, the reward is -109.0 maxPosition is 0.5202960534529724\n","Success in epsoide 384, used 114 iterations!\n","now epsilon is 0.01, the reward is -105.0 maxPosition is 0.5263137791606775\n","Success in epsoide 385, used 193 iterations!\n","now epsilon is 0.01, the reward is -184.0 maxPosition is 0.538779943878305\n","Success in epsoide 386, used 135 iterations!\n","now epsilon is 0.01, the reward is -126.0 maxPosition is 0.5016541452092518\n","Success in epsoide 387, used 119 iterations!\n","now epsilon is 0.01, the reward is -110.0 maxPosition is 0.5121105382877043\n","Success in epsoide 388, used 110 iterations!\n","now epsilon is 0.01, the reward is -101.0 maxPosition is 0.5028131788767619\n","Success in epsoide 389, used 113 iterations!\n","now epsilon is 0.01, the reward is -104.0 maxPosition is 0.5156746093942552\n","Success in epsoide 390, used 112 iterations!\n","now epsilon is 0.01, the reward is -103.0 maxPosition is 0.5220196017047704\n","Success in epsoide 391, used 179 iterations!\n","now epsilon is 0.01, the reward is -170.0 maxPosition is 0.5368577983788596\n","Success in epsoide 392, used 176 iterations!\n","now epsilon is 0.01, the reward is -167.0 maxPosition is 0.5368577983788596\n","Success in epsoide 393, used 112 iterations!\n","now epsilon is 0.01, the reward is -103.0 maxPosition is 0.5089490934484102\n","Success in epsoide 394, used 111 iterations!\n","now epsilon is 0.01, the reward is -102.0 maxPosition is 0.5203538584174375\n","Success in epsoide 395, used 115 iterations!\n","now epsilon is 0.01, the reward is -106.0 maxPosition is 0.5253030230069918\n","Success in epsoide 396, used 109 iterations!\n","now epsilon is 0.01, the reward is -100.0 maxPosition is 0.502343098735524\n","Success in epsoide 397, used 123 iterations!\n","now epsilon is 0.01, the reward is -114.0 maxPosition is 0.506910749017576\n","Success in epsoide 398, used 113 iterations!\n","now epsilon is 0.01, the reward is -104.0 maxPosition is 0.5239921412095027\n","Success in epsoide 399, used 114 iterations!\n","now epsilon is 0.01, the reward is -105.0 maxPosition is 0.5186724733350173\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wmFLfYqcg22U","executionInfo":{"status":"ok","timestamp":1636729211716,"user_tz":-330,"elapsed":121236,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}},"outputId":"53af131a-f8ee-4f9f-d846-9f09acc6fb05"},"source":["# After trainging it we save those models in which we now take the latest model to use.\n","\n","import gym\n","import numpy as np\n","from keras import models\n","\n","env = gym.make('MountainCar-v0')\n","\n","#play 20 times\n","#load the network\n","model=models.load_model('trainNetworkInEPS399.h5')\n","\n","completed = 0\n","num_episodes = 20\n","\n","for i_episode in range(num_episodes):\n","\n","    currentState = env.reset().reshape(1, 2)\n","\n","    print(\"============================================\")\n","\n","    rewardSum=0\n","    done = False\n","    t = 0\n","    while not done:\n","        # env.render()\n","        action = np.argmax(model.predict(currentState)[0])\n","\n","        new_state, reward, done, info = env.step(action)\n","\n","        new_state = new_state.reshape(1, 2)\n","\n","        currentState=new_state\n","\n","        rewardSum+=reward\n","        \n","        t+=1\n","\n","        if t == 200 :\n","          print(\"Episode finished but couldnot reach the top of the hill\")\n","          break\n","\n","        if done:\n","            completed +=1 \n","            print(\"Episode finished after {} timesteps reward is {}\".format(t,rewardSum))\n","            break\n","\n","\n","\n","\n","print(f\"Among {num_episodes} , {completed} episodes were completed and able to reach the top of the hill\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================\n","Episode finished after 110 timesteps reward is -110.0\n","============================================\n","Episode finished but couldnot reach the top of the hill\n","============================================\n","Episode finished after 122 timesteps reward is -122.0\n","============================================\n","Episode finished but couldnot reach the top of the hill\n","============================================\n","Episode finished after 116 timesteps reward is -116.0\n","============================================\n","Episode finished after 118 timesteps reward is -118.0\n","============================================\n","Episode finished after 116 timesteps reward is -116.0\n","============================================\n","Episode finished after 110 timesteps reward is -110.0\n","============================================\n","Episode finished after 109 timesteps reward is -109.0\n","============================================\n","Episode finished after 116 timesteps reward is -116.0\n","============================================\n","Episode finished after 111 timesteps reward is -111.0\n","============================================\n","Episode finished after 112 timesteps reward is -112.0\n","============================================\n","Episode finished after 110 timesteps reward is -110.0\n","============================================\n","Episode finished after 115 timesteps reward is -115.0\n","============================================\n","Episode finished after 121 timesteps reward is -121.0\n","============================================\n","Episode finished after 116 timesteps reward is -116.0\n","============================================\n","Episode finished after 115 timesteps reward is -115.0\n","============================================\n","Episode finished after 115 timesteps reward is -115.0\n","============================================\n","Episode finished after 112 timesteps reward is -112.0\n","============================================\n","Episode finished after 112 timesteps reward is -112.0\n","Among 20 , 18 episodes were completed and able to reach the top of the hill\n"]}]},{"cell_type":"code","metadata":{"id":"P-MpIrRCg5cm"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TA8op3jTaamg"},"source":["## **Roulette**"]},{"cell_type":"code","metadata":{"id":"bPvrr_HkahR4","executionInfo":{"status":"ok","timestamp":1636976883446,"user_tz":-330,"elapsed":926,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}}},"source":["from keras import models\n","from keras import layers\n","from tensorflow.keras.optimizers import Adam\n","from collections import deque\n","import random\n","import numpy as np\n","\n","class RouletteTrain:\n","    def __init__(self,env):\n","        self.env=env\n","        self.gamma=0.99\n","\n","        self.epsilon = 1\n","        self.epsilon_decay = 0.05\n","\n","        self.epsilon_min=0.01\n","\n","\n","        self.learingRate=0.001\n","\n","        self.replayBuffer=deque(maxlen=20000)\n","        self.trainNetwork=self.createNetwork()\n","\n","        self.episodeNum=100\n","\n","        self.iterationNum=201 #max is 200\n","\n","        self.numPickFromBuffer=32\n","\n","        self.targetNetwork=self.createNetwork()\n","\n","        self.targetNetwork.set_weights(self.trainNetwork.get_weights())\n","\n","    def createNetwork(self):\n","        model = models.Sequential()\n","        state_shape = self.env.observation_space.shape\n","\n","        model.add(layers.Dense(24, activation='relu', input_shape=(1,1)))\n","        model.add(layers.Dense(48, activation='relu'))\n","        model.add(layers.Dense(self.env.action_space.n,activation='linear'))\n","        # model.compile(optimizer=optimizers.RMSprop(lr=self.learingRate), loss=losses.mean_squared_error)\n","        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learingRate))\n","        return model\n","\n","    def getBestAction(self,state):\n","\n","        self.epsilon = max(self.epsilon_min, self.epsilon)\n","\n","        if np.random.rand(1) < self.epsilon:\n","            action = np.random.randint(0, 3)\n","        else:\n","            action=np.argmax(self.trainNetwork.predict(state)[0])\n","\n","        return action\n","\n","    \n","\n","    def trainFromBuffer_Boost(self):\n","        if len(self.replayBuffer) < self.numPickFromBuffer:\n","            return\n","        samples = random.sample(self.replayBuffer,self.numPickFromBuffer)\n","        npsamples = np.array(samples)\n","        states_temp, actions_temp, rewards_temp, newstates_temp, dones_temp = np.hsplit(npsamples, 5)\n","        states = np.concatenate((np.squeeze(states_temp[:])), axis = 0)\n","        rewards = rewards_temp.reshape(self.numPickFromBuffer,).astype(float)\n","        targets = self.trainNetwork.predict(states)\n","        newstates = np.concatenate(np.concatenate(newstates_temp))\n","        dones = np.concatenate(dones_temp).astype(bool)\n","        notdones = ~dones\n","        notdones = notdones.astype(float)\n","        dones = dones.astype(float)\n","        Q_futures = self.targetNetwork.predict(newstates).max(axis = 1)\n","        targets[(np.arange(self.numPickFromBuffer), actions_temp.reshape(self.numPickFromBuffer,).astype(int))] = rewards * dones + (rewards + Q_futures * self.gamma)*notdones\n","        self.trainNetwork.fit(states, targets, epochs=1, verbose=0)\n","\n","\n","\n","    def trainFromBuffer(self):\n","        if len(self.replayBuffer) < self.numPickFromBuffer:\n","            return\n","\n","        samples = random.sample(self.replayBuffer,self.numPickFromBuffer)\n","        # print(samples)\n","        states = []\n","        newStates=[]\n","        for sample in samples:\n","            state, action, reward, new_state, done = sample\n","            states.append(state)\n","            newStates.append(new_state)\n","\n","        newArray = np.array(states)\n","        states = newArray.reshape(self.numPickFromBuffer, 1)\n","\n","        newArray2 = np.array(newStates)\n","        newStates = newArray2.reshape(self.numPickFromBuffer, 1)\n","\n","        targets = self.trainNetwork.predict(states)\n","        new_state_targets=self.targetNetwork.predict(newStates)\n","        # print(new_state_targets)\n","\n","        i=0\n","        for sample in samples:\n","            state, action, reward, new_state, done = sample\n","            target = targets[i]\n","            # print(target[0],target[0][0])\n","            # print(target,action)\n","            if done:\n","                target[0][action] = reward\n","            else:\n","                Q_future = max(new_state_targets[i][0])\n","                # print(Q_future);\n","                target[0][action] = reward + Q_future * self.gamma\n","            i+=1\n","\n","        self.trainNetwork.fit(states, targets, epochs=1, verbose=0)\n","\n","\n","    def orginalTry(self,currentState,eps):\n","        rewardSum = 0\n","\n","        for i in range(self.iterationNum):\n","            bestAction = self.getBestAction(currentState)\n","\n","            #show the animation every 50 eps\n","            # if eps%50==0:\n","            #     env.render()\n","\n","            nw_state, reward, done, _ = env.step(bestAction)\n","\n","            new_state = np.zeros((1,1),dtype=np.float64)\n","            new_state[0] = nw_state\n","\n","            self.replayBuffer.append([currentState, bestAction, reward, new_state, done])\n","\n","            #Or you can use self.trainFromBuffer_Boost(), it is a matrix wise version for boosting \n","            self.trainFromBuffer()\n","\n","            rewardSum += reward\n","\n","            currentState = new_state\n","\n","            if done:\n","                break\n","\n","        # if i >= 199:\n","        #     print(\"Failed to finish task in epsoide {}\".format(eps))\n","        # else:\n","        print(\"Success in epsoide {}, used {} iterations!\".format(eps, i))\n","        self.trainNetwork.save('./trainNetworkInEPS{}.h5'.format(eps))\n","\n","        #Sync\n","        self.targetNetwork.set_weights(self.trainNetwork.get_weights())\n","\n","        print(\"now epsilon is {}, the reward is {}\".format(max(self.epsilon_min, self.epsilon), rewardSum))\n","        self.epsilon -= self.epsilon_decay\n","\n","    def start(self):\n","        for eps in range(self.episodeNum):\n","            a = env.reset()\n","            currentState=np.zeros((1,1),dtype=np.float64)\n","            currentState[0] = a\n","            self.orginalTry(currentState, eps)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOJewGPralDa","executionInfo":{"status":"ok","timestamp":1636978740652,"user_tz":-330,"elapsed":1857209,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}},"outputId":"726fa93c-5dd6-4e8d-e283-c144c5d02461"},"source":["import gym\n","\n","env = gym.make('Roulette-v0')\n","dqn=RouletteTrain(env=env)\n","dqn.start()"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Success in epsoide 0, used 99 iterations!\n","now epsilon is 1, the reward is 13.0\n","Success in epsoide 1, used 99 iterations!\n","now epsilon is 0.95, the reward is 1.0\n","Success in epsoide 2, used 99 iterations!\n","now epsilon is 0.8999999999999999, the reward is -32.0\n","Success in epsoide 3, used 99 iterations!\n","now epsilon is 0.8499999999999999, the reward is -28.0\n","Success in epsoide 4, used 99 iterations!\n","now epsilon is 0.7999999999999998, the reward is -8.0\n","Success in epsoide 5, used 99 iterations!\n","now epsilon is 0.7499999999999998, the reward is -32.0\n","Success in epsoide 6, used 99 iterations!\n","now epsilon is 0.6999999999999997, the reward is 13.0\n","Success in epsoide 7, used 99 iterations!\n","now epsilon is 0.6499999999999997, the reward is -6.0\n","Success in epsoide 8, used 99 iterations!\n","now epsilon is 0.5999999999999996, the reward is -8.0\n","Success in epsoide 9, used 99 iterations!\n","now epsilon is 0.5499999999999996, the reward is -8.0\n","Success in epsoide 10, used 99 iterations!\n","now epsilon is 0.4999999999999996, the reward is 44.0\n","Success in epsoide 11, used 99 iterations!\n","now epsilon is 0.4499999999999996, the reward is 15.0\n","Success in epsoide 12, used 99 iterations!\n","now epsilon is 0.39999999999999963, the reward is -18.0\n","Success in epsoide 13, used 99 iterations!\n","now epsilon is 0.34999999999999964, the reward is 21.0\n","Success in epsoide 14, used 99 iterations!\n","now epsilon is 0.29999999999999966, the reward is -12.0\n","Success in epsoide 15, used 99 iterations!\n","now epsilon is 0.24999999999999967, the reward is -12.0\n","Success in epsoide 16, used 99 iterations!\n","now epsilon is 0.19999999999999968, the reward is 45.0\n","Success in epsoide 17, used 99 iterations!\n","now epsilon is 0.1499999999999997, the reward is -12.0\n","Success in epsoide 18, used 99 iterations!\n","now epsilon is 0.09999999999999969, the reward is 12.0\n","Success in epsoide 19, used 99 iterations!\n","now epsilon is 0.049999999999999684, the reward is 6.0\n","Success in epsoide 20, used 99 iterations!\n","now epsilon is 0.01, the reward is -8.0\n","Success in epsoide 21, used 99 iterations!\n","now epsilon is 0.01, the reward is 10.0\n","Success in epsoide 22, used 99 iterations!\n","now epsilon is 0.01, the reward is -6.0\n","Success in epsoide 23, used 99 iterations!\n","now epsilon is 0.01, the reward is -22.0\n","Success in epsoide 24, used 99 iterations!\n","now epsilon is 0.01, the reward is 8.0\n","Success in epsoide 25, used 99 iterations!\n","now epsilon is 0.01, the reward is 8.0\n","Success in epsoide 26, used 99 iterations!\n","now epsilon is 0.01, the reward is -12.0\n","Success in epsoide 27, used 99 iterations!\n","now epsilon is 0.01, the reward is 10.0\n","Success in epsoide 28, used 99 iterations!\n","now epsilon is 0.01, the reward is -8.0\n","Success in epsoide 29, used 99 iterations!\n","now epsilon is 0.01, the reward is -6.0\n","Success in epsoide 30, used 99 iterations!\n","now epsilon is 0.01, the reward is -4.0\n","Success in epsoide 31, used 99 iterations!\n","now epsilon is 0.01, the reward is 0.0\n","Success in epsoide 32, used 99 iterations!\n","now epsilon is 0.01, the reward is -14.0\n","Success in epsoide 33, used 99 iterations!\n","now epsilon is 0.01, the reward is -10.0\n","Success in epsoide 34, used 99 iterations!\n","now epsilon is 0.01, the reward is -10.0\n","Success in epsoide 35, used 99 iterations!\n","now epsilon is 0.01, the reward is -16.0\n","Success in epsoide 36, used 99 iterations!\n","now epsilon is 0.01, the reward is 2.0\n","Success in epsoide 37, used 99 iterations!\n","now epsilon is 0.01, the reward is -8.0\n","Success in epsoide 38, used 99 iterations!\n","now epsilon is 0.01, the reward is -12.0\n","Success in epsoide 39, used 99 iterations!\n","now epsilon is 0.01, the reward is -2.0\n","Success in epsoide 40, used 99 iterations!\n","now epsilon is 0.01, the reward is -10.0\n","Success in epsoide 41, used 99 iterations!\n","now epsilon is 0.01, the reward is -4.0\n","Success in epsoide 42, used 99 iterations!\n","now epsilon is 0.01, the reward is 8.0\n","Success in epsoide 43, used 99 iterations!\n","now epsilon is 0.01, the reward is -4.0\n","Success in epsoide 44, used 99 iterations!\n","now epsilon is 0.01, the reward is 4.0\n","Success in epsoide 45, used 99 iterations!\n","now epsilon is 0.01, the reward is 0.0\n","Success in epsoide 46, used 99 iterations!\n","now epsilon is 0.01, the reward is -10.0\n","Success in epsoide 47, used 99 iterations!\n","now epsilon is 0.01, the reward is 18.0\n","Success in epsoide 48, used 99 iterations!\n","now epsilon is 0.01, the reward is 0.0\n","Success in epsoide 49, used 99 iterations!\n","now epsilon is 0.01, the reward is -8.0\n","Success in epsoide 50, used 99 iterations!\n","now epsilon is 0.01, the reward is 10.0\n","Success in epsoide 51, used 99 iterations!\n","now epsilon is 0.01, the reward is 0.0\n","Success in epsoide 52, used 99 iterations!\n","now epsilon is 0.01, the reward is 14.0\n","Success in epsoide 53, used 99 iterations!\n","now epsilon is 0.01, the reward is 2.0\n","Success in epsoide 54, used 99 iterations!\n","now epsilon is 0.01, the reward is -2.0\n","Success in epsoide 55, used 99 iterations!\n","now epsilon is 0.01, the reward is -10.0\n","Success in epsoide 56, used 99 iterations!\n","now epsilon is 0.01, the reward is -14.0\n","Success in epsoide 57, used 99 iterations!\n","now epsilon is 0.01, the reward is -8.0\n","Success in epsoide 58, used 99 iterations!\n","now epsilon is 0.01, the reward is -4.0\n","Success in epsoide 59, used 99 iterations!\n","now epsilon is 0.01, the reward is -4.0\n","Success in epsoide 60, used 99 iterations!\n","now epsilon is 0.01, the reward is 2.0\n","Success in epsoide 61, used 99 iterations!\n","now epsilon is 0.01, the reward is 0.0\n","Success in epsoide 62, used 99 iterations!\n","now epsilon is 0.01, the reward is -2.0\n","Success in epsoide 63, used 99 iterations!\n","now epsilon is 0.01, the reward is 6.0\n","Success in epsoide 64, used 99 iterations!\n","now epsilon is 0.01, the reward is 0.0\n","Success in epsoide 65, used 99 iterations!\n","now epsilon is 0.01, the reward is -18.0\n","Success in epsoide 66, used 99 iterations!\n","now epsilon is 0.01, the reward is -14.0\n","Success in epsoide 67, used 99 iterations!\n","now epsilon is 0.01, the reward is -20.0\n","Success in epsoide 68, used 99 iterations!\n","now epsilon is 0.01, the reward is 6.0\n","Success in epsoide 69, used 99 iterations!\n","now epsilon is 0.01, the reward is 8.0\n","Success in epsoide 70, used 99 iterations!\n","now epsilon is 0.01, the reward is -6.0\n","Success in epsoide 71, used 99 iterations!\n","now epsilon is 0.01, the reward is -16.0\n","Success in epsoide 72, used 99 iterations!\n","now epsilon is 0.01, the reward is -6.0\n","Success in epsoide 73, used 99 iterations!\n","now epsilon is 0.01, the reward is -10.0\n","Success in epsoide 74, used 99 iterations!\n","now epsilon is 0.01, the reward is 16.0\n","Success in epsoide 75, used 99 iterations!\n","now epsilon is 0.01, the reward is -6.0\n","Success in epsoide 76, used 99 iterations!\n","now epsilon is 0.01, the reward is -18.0\n","Success in epsoide 77, used 99 iterations!\n","now epsilon is 0.01, the reward is 8.0\n","Success in epsoide 78, used 99 iterations!\n","now epsilon is 0.01, the reward is 12.0\n","Success in epsoide 79, used 99 iterations!\n","now epsilon is 0.01, the reward is 14.0\n","Success in epsoide 80, used 99 iterations!\n","now epsilon is 0.01, the reward is -18.0\n","Success in epsoide 81, used 99 iterations!\n","now epsilon is 0.01, the reward is 2.0\n","Success in epsoide 82, used 99 iterations!\n","now epsilon is 0.01, the reward is -12.0\n","Success in epsoide 83, used 99 iterations!\n","now epsilon is 0.01, the reward is 4.0\n","Success in epsoide 84, used 99 iterations!\n","now epsilon is 0.01, the reward is -12.0\n","Success in epsoide 85, used 99 iterations!\n","now epsilon is 0.01, the reward is 10.0\n","Success in epsoide 86, used 99 iterations!\n","now epsilon is 0.01, the reward is -6.0\n","Success in epsoide 87, used 99 iterations!\n","now epsilon is 0.01, the reward is 20.0\n","Success in epsoide 88, used 99 iterations!\n","now epsilon is 0.01, the reward is -10.0\n","Success in epsoide 89, used 99 iterations!\n","now epsilon is 0.01, the reward is -12.0\n","Success in epsoide 90, used 99 iterations!\n","now epsilon is 0.01, the reward is -4.0\n","Success in epsoide 91, used 99 iterations!\n","now epsilon is 0.01, the reward is -2.0\n","Success in epsoide 92, used 99 iterations!\n","now epsilon is 0.01, the reward is 12.0\n","Success in epsoide 93, used 99 iterations!\n","now epsilon is 0.01, the reward is -14.0\n","Success in epsoide 94, used 99 iterations!\n","now epsilon is 0.01, the reward is 0.0\n","Success in epsoide 95, used 99 iterations!\n","now epsilon is 0.01, the reward is 14.0\n","Success in epsoide 96, used 99 iterations!\n","now epsilon is 0.01, the reward is 8.0\n","Success in epsoide 97, used 99 iterations!\n","now epsilon is 0.01, the reward is 2.0\n","Success in epsoide 98, used 99 iterations!\n","now epsilon is 0.01, the reward is 8.0\n","Success in epsoide 99, used 99 iterations!\n","now epsilon is 0.01, the reward is -4.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ntxo1aZAasHu","executionInfo":{"status":"ok","timestamp":1636978879602,"user_tz":-330,"elapsed":103396,"user":{"displayName":"Pritesh Sahani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64","userId":"17183347222361440423"}},"outputId":"c8dbaded-58c3-45a4-e61b-cc52fb6afe1b"},"source":["# After training it we save those models in which we now take the latest model to use.\n","\n","import gym\n","import numpy as np\n","from keras import models\n","\n","env = gym.make('Roulette-v0')\n","\n","#play 20 times\n","#load the network\n","model=models.load_model('trainNetworkInEPS99.h5')\n","\n","num_episodes = 20\n","totalReward = 0\n","\n","for i_episode in range(num_episodes):\n","\n","    a = env.reset()\n","    currentState=np.zeros((1,1),dtype=np.float64)\n","    currentState[0] = a\n","\n","    print(\"============================================\")\n","\n","    rewardSum=0\n","    done = False\n","    t = 0\n","    while not done:\n","        # env.render()\n","        action = np.argmax(model.predict(currentState)[0])\n","\n","        nw_state, reward, done, info = env.step(action)\n","\n","        new_state = np.zeros((1,1),dtype=np.float64)\n","        new_state[0] = nw_state\n","\n","        currentState=new_state\n","\n","        rewardSum+=reward\n","        \n","        t+=1\n","\n","        if done:\n","            totalReward += rewardSum\n","            print(\"Episode finished after {} timesteps reward is {}\".format(t,rewardSum))\n","            break\n","\n","\n","avg_rewards = int(totalReward/num_episodes)\n","print(\"Average reward points in {} episodes is {}\".format(num_episodes,avg_rewards))"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================\n","Episode finished after 100 timesteps reward is -22.0\n","============================================\n","Episode finished after 100 timesteps reward is -4.0\n","============================================\n","Episode finished after 100 timesteps reward is -8.0\n","============================================\n","Episode finished after 100 timesteps reward is -4.0\n","============================================\n","Episode finished after 100 timesteps reward is -2.0\n","============================================\n","Episode finished after 100 timesteps reward is 0.0\n","============================================\n","Episode finished after 100 timesteps reward is -14.0\n","============================================\n","Episode finished after 100 timesteps reward is 0.0\n","============================================\n","Episode finished after 100 timesteps reward is -16.0\n","============================================\n","Episode finished after 100 timesteps reward is -8.0\n","============================================\n","Episode finished after 100 timesteps reward is 10.0\n","============================================\n","Episode finished after 100 timesteps reward is -10.0\n","============================================\n","Episode finished after 100 timesteps reward is 4.0\n","============================================\n","Episode finished after 100 timesteps reward is -2.0\n","============================================\n","Episode finished after 100 timesteps reward is 4.0\n","============================================\n","Episode finished after 100 timesteps reward is -6.0\n","============================================\n","Episode finished after 100 timesteps reward is 2.0\n","============================================\n","Episode finished after 100 timesteps reward is -12.0\n","============================================\n","Episode finished after 100 timesteps reward is 4.0\n","============================================\n","Episode finished after 100 timesteps reward is 4.0\n","Average reward points in 20 episodes is -4\n"]}]},{"cell_type":"code","metadata":{"id":"0H6fQMqrbVOd"},"source":[""],"execution_count":null,"outputs":[]}]}